=IGN
********************************************************************************
usr031.doc: this file is part of the PPXpp system

Copyright (c) 2002 Lemma 1 Ltd.

See the file LICENSE for your rights to use and change this file.

Contact: Rob Arthan < rda@lemma-one.com >
********************************************************************************
=TEX
%
% This document includes some xfig diagrams usr032?.fig..
%
%%%%% YOU MAY WANT TO CHANGE POINT SIZE IN THE FOLLOWING:
\documentclass[a4paper,12pt]{article}

%%%%% YOU CAN ADD OTHER PACKAGES AS NEEDED BELOW:
\usepackage{A4}
\usepackage{Lemma1}
\usepackage{ProofPower}
\usepackage{epsf}
\def\SLRP{{\bf SLRP}}
\def\Slrp{{\tt slrp}}

\def\FigRef#1{\ref{#1} on page \pageref{#1}}
\def\Hide#1{\relax}

\vertbarfalse

\newenvironment{Fig}[3][htp]{%
\begin{figure}[#1]
\label{#3}
\def\Caption{\caption{#2}}
\begin{center}
\begin{tabular}{|c|}\hline
\begin{minipage}{.85\hsize}
}{%
\end{minipage}\\\hline
\end{tabular}
\end{center}
\Caption
\end{figure}}

%%%%% YOU WILL USUALLY WANT TO CHANGE THE FOLLOWING TO SUIT YOU AND YOUR DOCUMENT:

\def\Title{ {\SLRP} User Guide }

\def\Abstract{\begin{center}
{\bf Abstract}\par\parbox{0.7\hsize}
{\small This document is the user guide for {\SLRP} --- a simple parser generator for Standard ML.}
\end{center}}

\def\Reference{LEMMA1/XPP/USR031}

\def\Author{R.D. Arthan}

\def\EMail{{\tt rda@lemma-one.com}}

\def\Phone{+44 118 958 4409}

\def\Fax{+44 118 956 1920}

%%%%% YOU MAY WANT TO CHANGE THE FOLLOWING TO GET A NICE FRONT PAGE:
\def\FrontPageTitle{ {\huge ProofPower\\---\\{\SLRP} User Guide } }
\def\FrontPageHeader{\raisebox{16ex}{\begin{tabular}[t]{c}
\bf Copyright \copyright\ : Lemma 1 Ltd \number\year\\\strut\\
\end{tabular}}}
\begin{centering}



\end{centering}

%%%%% THE FOLLOWING DEFAULTS WILL GENERALLY BE RIGHT:

\def\Version{$Revision: 1.1 $%
}
\def\Date{\FormatDate{$Date: 2003/03/07 17:27:55 $%
}}

%%%%% NOW BEGIN THE DOCUMENT AND MAKE THE FRONT PAGE

\begin{document}
\headsep=0mm
\FrontPage
\headsep=10mm

%%%%% STANDARD RED-TAPE SECTIONS (MAY WANT TO INTERLEAVE SOME \newpage COMMANDS IN THESE)

%%%%% CONTENTS:

\subsection{Contents}

\tableofcontents
\newpage
\subsection{List of Figures}
\listoffigures
%%%%% REFERENCES:

\subsection{References}

\bibliographystyle{fmu}

%%%%% CHANGE THE FOLLOWING AS NECESSARY (E.G., TO PICK UP daz.bib):
{\raggedright
\bibliography{fmu}
}
%%%%% CHANGES HISTORY:
\subsection{Changes History}
\begin{description}
\item[Issues 1.1 -- 1.n] Author's initial drafts.
\end{description}


%%%%%  CHANGES FORECAST:

\subsection{Changes Forecast}

None at this release.

%%%%% DISTRIBUTION LIST

%\subsection{Distribution}
%\begin{center}
%\begin{tabular}{ll}
%Rob Arthan & Lemma 1\\
%Gill Prout & Home \\
%Roger Jones & Home
%\end{tabular}
%\end{center}


\newpage

%%%%% NOW THE CREATIVE BIT:

\section{INTRODUCTION}

{\SLRP} is a simple but powerful parser generator for Standard ML. The input to {\SLRP}
is a grammar written in a version of Backus-Naur Format (BNF), \cite{BS6154}.
The output from {\SLRP} is a file of Standard ML code that can be used to construct
a parser from the language specified by the grammar.
Grammar rules may include Standard ML action code to be executed when the rule is applied
during a parse.
{\SLRP} can also, optionally, output a listing of the grammar and details of its analysis
of the grammar to assist you in designing the language or the grammar that defines it.

{\SLRP} is similar in conception to the widely used parser generators like {\tt yacc} and {\tt bison}
for C and ML-Yacc for Standard ML. {\SLRP} differs from these in that the parser it generates
is table-driven rather than comprising a mixture of tables and decision-making code. The tables
are interpreted by a simple polymorphic parser-driver function that takes as its arguments
functions that you supply to carry out application-specific tasks such as reading the input stream
and reporting errors. The organisation of the parser code is easy to understand and could
easily be modified, e.g., to work with a different dialect of ML.

{\SLRP} does not include an automatic lexical analyser generator. It does support production
of a generic parser from a grammar. This means that {\SLRP}  can automatically
generate the action code and the supporting functions for you.  The result is a complete
working parser whose input is a sequence of terminal symbols in the same format as was
used in the grammar and whose output is a parse tree. This provides a framework which
you can readily adapt to provide the parsing functionality that your application requires.

{\SLRP} is currently available to run with the Poly/ML or Standard ML of New Jersey compilers.
The output from {\SLRP} is Standard ML code that should work with any Standard ML compiler.
{\SLRP} includes the {\Product} library of utility functions and the
code it generates does depend on these. However, substitutes for the small repertoire
of functions actually used (primarily concerned with table lookup) could easily be supplied
to work in other environments.

The {\SLRP} source code and documentation is packaged using. PPTex, the {\Product}
document preparation and literate programming system. You do not need to use
PPTex to use {\SLRP}, but it does provide a convenient way of packaging the various
source files and scripts you need to build a parser with {\SLRP}.

Like {\tt yacc} and {\tt bison}, {\SLRP} implements a version of the LALR(1)  algorithm. This
means that it is capable of generating parsers for a wide range of practical languages.
The {\SLRP} distribution includes example grammars for the programming languages
Ada 95,  Java 1.1 and Pascal and a complete working parser for C. {\SLRP} is also
used for the parsers for the object languages HOL and Z supported by {\Product}.

\section{GETTING STARTED WITH \SLRP}\label{STARTING}

The first task in using {\SLRP} to build a parser is to prepare a text file containing
a context-free grammar for the language you want to parse. The file should be given a name ending
in ``{\tt .txt}''.  The format of this file is specified in detail in appendix~\ref{INPUTFORMAT}.
Figure~\ref{usr032a.grm.txt} shows an example file containing a grammar for a language of arithmetic expressions:

\begin{Fig}[h]{A Grammar for Arithmetic Expressions}{usr032a.grm.txt}
=DUMP usr032a.grm.txt
Expression =	Sum;

Atom =		literal
		|	`(`, Expression, `)`;

Application =	Atom
		|	`-`, Application
		|	`+`, Application
		|	identifier, `(`, Expression, `)`;

Product =		Application
		|	Product, `*`, Application
		|	Product, `/`, Application;

Sum =		Product
		|	Sum, `+`, Product
		|	Sum, `-`, Product;
=TEX
\end{Fig}

=TEX
In this document, we assume that you are familiar with the basic concepts of context-free grammars.
This example shows the {\SLRP} conventions for writing a grammar: the grammar rules are
written as equations, which we call {\em productions}; the right-hand side of each
production comprises zero or more
{\em alternatives} separated by vertical bars and terminated by a semi-colon;
each alternative comprises zero or more
{\em grammar symbols} separated by commas.
A {\em nonterminal symbol} is a grammar symbol that appears on the left-hand side
of some production.
A {\em terminal symbol} is a grammar symbol that does not appear on the left-hand side
of any production.
The order of the productions in the file is not important except that the first production
must give the starting symbol for the grammar, in this case {\it Expression}.

Nonterminal symbols are written as identifiers, e.g., {\it Sum}, following the Standard ML rules for
forming identifiers (using letters, numbers, underscores and the prime character and
beginning with a letter).
Terminal symbols may be written either as identifiers, e.g., {\it literal}, or as arbitrary strings
enclosed in back-quote characters, e.g.,
=INLINEFT
`+`
=TEX
.

Once you have prepared your grammar file, you can run {\SLRP} to analyse the grammar
and generate the parser code. You use the shell script {\Slrp} to do this specifying the
name of your file using the {\it -f} option.. If you want to generate the generic parser, you specify
{\it -g}. While you are developing your grammar, it is generally also useful to specify the
listing option {-l 2}. For our example, the command would be as follows:

=SH
slrp -g -l 2 -f  usr032a.grm.txt >usr032a.grm.run 2>&1
=TEX
This will result in some messages on standard output.
It will also produce two output files:

\begin{description}
\item[{\tt usr032a.grm.sml}] containing the Standard ML code
of the generated parser
\item[{\tt usr032a.grm.log}] containing a listing of the grammar and various
additional information, for example, a sorted list of the terminal symbols (which is useful for reference
and to help you spot mistyped nonterminal names).
\end{description}

You can now compile and run the generic parser for your language
after first compiling the parser driver and supporting material using
the ML commands shown in figure~\ref{usr032a.grm.sml}.
The ML function {\it my\_parse\_file} that this defines takes the name of a file as its argument;
it parses the sequence of terminal symbols in the specified file and prints out the parse tree.
An example input file for it is shown in figure~\ref{usr032a.grm.tst}


\begin{Fig}{Compiling the Generated Parser}{usr032a.grm.sml}
=SML
map use [
	"dtd108.sml",	(* Portability infrastructure *)
	"imp108.sml",
	"dtd002.sml",	(* System control and error reporting *)
	"imp002.sml",
	"dtd001.sml",	(* Standard ML utilities *)
	"imp001.sml",
	"dtd018.sml",	(* SLRP parser driver *)
	"imp018.sml",
	"dtd118.sml",	(* Generic SLRP parser support *)
	"imp118.sml"
	];
open GenericSlrpParser;
use"usr032a.grm.sml";		(* The generated parser code *)
val my_parse_file : string -> unit =
	print_tree o parse_file slrp'gen_parser;
=TEX
\end{Fig}
=TEX


\begin{Fig}[ht]{Generic Parser Input}{usr032a.grm.tst}
=DUMP usr032a.grm.tst
	literal  `*`  `(` literal `-` literal
	`)` `+`  identifier `(`
		 literal `/`
		literal 
	`)`
=TEX
\end{Fig}

\Hide{
=SML
 my_parse_file "usr032a.grm.tst";
=TEX
}

If you now execute \verb!my_parse_file "usr032a.grm.tst"!, you will see the print-out of the parse tree shown
in figure~\ref{usr032a.grm.out} (in which the number in brackets after
each terminal symbol is the line number where that instance of the terminal symbol was found).

Of course the functionality of the generic parser as it stands is unlikely to be what you
want in your actual application. Both its ``front-end'', i.e., its lexical analyser, and
its ``back-end'', i.e., the generic reduction actions that build a generic parse tree, will
generally need to be modified to do what is really wanted.
Sections~\ref{LEXAN} and~\ref{ACTIONS} explain how you may go about
mutating the generic parser to meet your needs.


\newpage

\begin{Fig}[h]{An Example Parse Tree}{usr032a.grm.out}
=GFT
1.1.1.1.1.1.1: Atom = literal(1);
1.1.1.1.1.1: Application = Atom;
1.1.1.1.1: Product = Application;
1.1.1.1.3.1.2.1.1.1.1.1: Atom = literal(1);
1.1.1.1.3.1.2.1.1.1.1: Application = Atom;
1.1.1.1.3.1.2.1.1.1: Product = Application;
1.1.1.1.3.1.2.1.1: Sum = Product;
1.1.1.1.3.1.2.1.3.1.1: Atom = literal(1);
1.1.1.1.3.1.2.1.3.1: Application = Atom;
1.1.1.1.3.1.2.1.3: Product = Application;
1.1.1.1.3.1.2.1: Sum = Sum, `-`(1), Product;
1.1.1.1.3.1.2: Expression = Sum;
1.1.1.1.3.1: Atom = `(`(1), Expression, `)`(2);
1.1.1.1.3: Application = Atom;
1.1.1.1: Product = Product, `*`(1), Application;
1.1.1: Sum = Product;
1.1.3.1.3.1.1.1.1.1: Atom = literal(3);
1.1.3.1.3.1.1.1.1: Application = Atom;
1.1.3.1.3.1.1.1: Product = Application;
1.1.3.1.3.1.1.3.1: Atom = literal(4);
1.1.3.1.3.1.1.3: Application = Atom;
1.1.3.1.3.1.1: Product = Product, `/`(3), Application;
1.1.3.1.3.1: Sum = Product;
1.1.3.1.3: Expression = Sum;
1.1.3.1: Application = identifier(2), `(`(2), Expression, `)`(5);
1.1.3: Product = Application;
1.1: Sum = Sum, `+`(2), Product;
1: Expression = Sum;
=TEX
\end{Fig}

=TEX
\newpage
\section{ADDING A LEXICAL ANALYSER}\label{LEXAN}
In this section we show how to construct a real lexical analyser
for the arithmetic expression language defined by the grammar 
shown in figure~\FigRef{usr032a.grm.txt}. 

The structure {\it GenericSlrpParser} containing the generic parser support code
provides several tools to help you construct a real lexical analyser.
In this section we show how these may be used to construct a lexical analyser appropriate
for the anguage of arithmetic expressions defined by the grammar shown in figure~\FigRef{usr032a.grm.txt}. 
The tools will help you with things such as reading an input stream and keeping track of line numbers
leaving you to focus on the lexical matters that are specific to your language.

The structure {\it GenericSlrpParser}  defines a polymorphic type
=INLINEFT
'lc LEX_VALUE
=TEX
\ for communication between the lexical analyser and the parser proper. It is defined as follows:
=GFT
type 'lc LEX_VALUE = 'lc * (string * int);
=TEX

Here $'lc$ stands for the ML representation of the various terminal symbols (lexical classes)
in the grammar (together with a special end-of-sentence symbol). In the generic parser we
constructed in the previous section $'lc$ is instantiated to a data type
=INLINEFT
LEX_CLASS
=TEX
\ representing the identifiers and string quotations that make up the set of terminal
symbols in the {\SLRP} input format. For our language of arithmetic expressions, we
will continue to use this data type for the lexical classes which is defined as follows:

=GFT
datatype LEX_CLASS =
		LCIdentifier of string
	|	LCString of string
	|	LCEos;
=TEX

The listing file {\tt usr032a.grm.log} generated by {\SLRP} shows us that we have the following
lexical classes to deal with:
=INLINEFT
identifier,  literal, `(`, `)`, `*`, `+`, `-`, `/`
=TEX
.
Identifiers will be formed from  letters, numbers and underscores and will start with a letter or an underscore.
Literals will be decimal integers.
The punctuation symbols will be as given together with semicolon and the hash symbol
and our lexical analyser will warn about and skip
over other characters. We will take the input stream to comprise a sequence of
arithmetic expressions separated by semicolons (as might be appropriate in an interactive
program that read and processed arithmetic expressions).
Comments will be allowed and comprise any sequence of characters beginning
with a hash character and terminated by an end-of-line character.
The ML definitions given
in figure~\ref{lex.values} reflect  some of these design decisions.

\begin{Fig}{Constructing Lexical Values}{lex.values}
=SML
type AE_LEX_VALUE = LEX_CLASS LEX_VALUE;
type AE_LEX_STATE = LEX_CLASS LEX_STATE;
fun lv_identifier (s : string) : AE_LEX_VALUE = (
	(LCIdentifier "identifier", (s, get_line_number()))
);
fun lv_literal (s : string) : AE_LEX_VALUE = (
	(LCIdentifier "literal", (s, get_line_number()))
);
local
	fun lv_punctuation c = (LCString c, (c, get_line_number()));
in
val lv_left_bracket : AE_LEX_VALUE = lv_punctuation "(";
val lv_right_bracket : LEX_CLASS LEX_VALUE = lv_punctuation ")";
val lv_times : AE_LEX_VALUE = lv_punctuation "*";
val lv_plus : AE_LEX_VALUE = lv_punctuation "+";
val lv_minus : AE_LEX_VALUE = lv_punctuation "-";
val lv_over : AE_LEX_VALUE = lv_punctuation "/";
end;
val lv_semicolon : AE_LEX_VALUE = (LCEos, (";", get_line_number()));
val lv_end_of_input : AE_LEX_VALUE =
	(LCEos, ("<end-of-input>", get_line_number()));
=TEX
\end{Fig}

The tools in the structure {\it GenericSlrpParser} provide us a framework in which our lexical
analyser is defined. In this framework you write what we call recogniser functions for the various
lexical classes.  These are defined in terms of the following data types, a recognisr
function being a function from
=INLINEFT
'lc LEX_STATE
=TEX
\ to itself.

=GFT
datatype CONTINUATION_STATUS =
		InComment
	|	InString of string list;
datatype 'lc LEX_STATUS =
		Unknown
	|	Known of 'lc LEX_VALUE
	|	Comment
	|	Continuation of int * CONTINUATION_STATUS;
type 'lc LEX_STATE = (string list * 'lc LEX_STATUS);
=TEX


The idea is that a recogniser function is passed as the first component
of its argument a buffer comprising a list of strings representing the
unread input characters (one character per string) from the current
input line.  If it recognises what it finds, the function should consume the appropriate
number of characters from the buffer and return the update buffer together
with a status value indicating what has been found. The generic tools look after
issues such as skipping white space between tokens.

The data types above allow
for lexical values like comments strings that
are allowed  in some  languages to spread over multiple lines.
We will not use these features in this example,
although we will use comments to deal with invalid input characters.

Figure~\ref{lex.punctuation} shows our code for recognising
a punctuation symbol. Because we want to accept a sequence
of arithmetic expressions separated by semicolons, this code maps
semicolon to the end of sentence symbol.

TBS --- description of the rest of the lexical analyser.

\begin{Fig}{Recognising Punctuation Symbols}{lex.punctuation}
=SML
fun rec_punctuation (("(" :: more, _)  : AE_LEX_STATE)
	: AE_LEX_STATE
	= (more, Known  lv_left_bracket)
|   rec_punctuation ( ")" :: more, _ ) =
	(more, Known lv_right_bracket)
|   rec_punctuation ( "*" :: more, _ ) =
	(more, Known lv_times)
|   rec_punctuation ( "+" :: more, _ ) =
	(more, Known lv_plus)
|   rec_punctuation ( "-" :: more, _ ) =
	(more, Known lv_minus)
|   rec_punctuation ( "/" :: more, _ ) =
	(more, Known lv_over)
|   rec_punctuation ( ";" :: more, _ ) = 
	(more, Known lv_semicolon)
|   rec_punctuation ( "#" :: _, _ ) = 
	([], Comment)
|   rec_punctuation (chs, _) = (chs, Unknown);
=TEX
\end{Fig}


\begin{Fig}{Recognising an Identifier}{lex.identifier}
=SML
fun is_alph_or_us ch = (
		"a" <= ch andalso ch <= "z"
	orelse	"A" <= ch andalso ch <= "Z"
	orelse	ch = "_"
);
fun is_digit ch = "0" <= ch andalso ch <= "9";
val is_alnum = is_alph_or_us fun_or is_digit;
fun rec_identifier (([], _) : AE_LEX_STATE) : AE_LEX_STATE = (
	([], Unknown)
) | rec_identifier (chs as (ch :: more), _) = (
	let	fun aux acc [] = (implode (rev acc), [])
		|   aux acc (cs as (c::more)) = (
			if	is_alnum c
			then	aux (c::acc) more
			else	(implode(rev acc), cs)
		);
	in	if	is_alph_or_us ch
		then	let	val (name, rest) = aux [ch] more;
			in	(rest, Known (lv_identifier name))
			end
		else	(chs, Unknown)
	end
);
=TEX
\end{Fig}

\begin{Fig}{Recognising a Literal}{lex.literal}
=SML
fun rec_literal (([], _) : AE_LEX_STATE)
	: AE_LEX_STATE = (
	([], Unknown)
) | rec_literal (chs as (ch :: more), _) = (
	let	fun aux acc [] = (implode (rev acc), [])
		|   aux acc (cs as (c::more)) = (
			if	is_digit c
			then	aux (c::acc) more
			else	(implode(rev acc), cs)
		);
	in	if	is_digit ch
		then	let	val (digits, rest) = aux [ch] more;
			in	(rest, Known (lv_literal digits))
			end
		else	(chs, Unknown)
	end
);
=TEX
\end{Fig}

\begin{Fig}{Dealing with Lexical Errors}{lex.unknown}
=SML
fun rec_unknown (( ch :: more, _ ) : AE_LEX_STATE)
	: AE_LEX_STATE = (
	output(std_out, "Unrecognised input character \"" ^ ch ^ "\"\n");
	(more, Comment)
) | rec_unknown ([], _) = ([], Unknown);
=TEX
\end{Fig}

\begin{Fig}{Constructing the Reader}{lex.reader}
=SML
val rec_token : AE_LEX_STATE -> AE_LEX_STATE =
	rec_first[rec_punctuation, rec_identifier, rec_literal, rec_unknown];
val reader_state : (string list * bool) ref = ref ([], true);
fun reader (strm : IN_CHAR_STREAM) 
	: (AE_LEX_VALUE, string list * bool) READER = (
	let	val do_read = gen_reader LCEos rec_token strm
	in	fn state =>
		let	val (tok, state') = do_read state;
		in	reader_state := state';
			(tok, state')
		end
	end
);
=TEX
\end{Fig}

\begin{Fig}{Constructing the Parser}{lex.parser}
=SML
use"usr032a.grm.sml";
fun parse_string
	(s : string)  : unit -> LEX_CLASS GEN_PARSE_TREE = (
	let	val do_parse =
			slrp'gen_parser
			default_resolver
			classifier
			(default_error string_of_lex_value)
			(reader(in_char_stream_of_string s));
		val _ = reader_state := ([], true);
	in	fn () => do_parse (!reader_state)
	end
	
);
=TEX
\end{Fig}

=TEX

\newpage
\section{CUSTOMISING THE PARSER ACTIONS}\label{ACTIONS}
In this section, we will complete work on our running example by adding
parser action functions to the grammar of our language of arithmetic
expressions. The action functions will actually compute the value of
an expression, so that our parser becomes a simple calculator.

TBS --- description of action grammars.

\begin{Fig}[ht]{An Action Grammar for Arithmetic Expressions}{usr032b.grm.txt}
=DUMP usr032b.grm.txt
Expression =	Sum					(red_expression x1);

Atom =		literal				(red_atom1 x1)
		|	`(`, Expression, `)`		(red_atom2 x2);

Application =	Atom				(red_application1 x1)
		|	`-`, Application		(red_application2 x2)
		|	`+`, Application		(red_application3 x2)
		|	identifier, `(`, Expression, `)`
							(red_application4 x1 x3);

Product =		Application			(red_product1 x1)
		|	Product, `*`, Application	(red_product2 x1 x3)
		|	Product, `/`, Application	(red_product3 x1 x3);

Sum =		Product			(red_sum1 x1)
		|	Sum, `+`, Product		(red_sum2 x1 x3)
		|	Sum, `-`, Product		(red_sum3 x1 x3);
=TEX
\end{Fig}
=SH
slrp -g -l 2 -f  usr032b.grm.txt >usr032b.grm.run 2>&1
=TEX
\begin{Fig}{The Action  Functions}{actions.functions}
=SML
fun red_accept (Parsed i) = i;
val red_expression = red_accept;
fun red_atom1 (Token ((_, (s, _)), _)) = nat_of_string s; 
val red_atom2 = red_accept;
val red_application1 = red_accept;
fun red_application2 (Parsed i) =  ~i;
val red_application3 = red_accept;
fun red_application4 (Token((_, (s, _)), _)) (Parsed i) = (
	case s of
		"abs" => if i < 0 then ~i else i
	|	"sgn" => if i > 0 then 1 else if i = 0 then 0 else ~1
	|	_ => (
		output(std_out, "Unsupported function \"" ^ s ^ "\"\n");
		raise SYNTAX_ERROR
	)
);
val red_product1 = red_accept;
fun red_product2 (Parsed i) (Parsed j) = i * j;
fun red_product3 (Parsed i) (Parsed j) = i div j handle Div => (
	output(std_out, "Zero divisor\n");
	raise SYNTAX_ERROR
);
val red_sum1 = red_accept;
fun red_sum2 (Parsed i) (Parsed j) = i + j;
fun red_sum3 (Parsed i) (Parsed j) = i - j;
=TEX
\end{Fig}

\begin{Fig}{Constructing the Parser}{actions.parser}
=SML
use"usr032b.grm.sml";
fun parse_stream
	(s : instream)  : unit = (
	let	val do_parse =
			slrp'gen_parser
			default_resolver
			classifier
			(default_error string_of_lex_value)
			(reader(in_char_stream_of_instream s));
		val _ = reader_state := ([], true);
	in	while true do
			let	val res = do_parse (!reader_state);
			in	output(std_out, "Result = " ^ 
					string_of_int res  ^"\n")
			end	handle SYNTAX_ERROR =>  ()
	end
);
=IGN
parse_stream std_in;

=TEX
\end{Fig}

\newpage
\section{HOW THE PARSERS WORK}\label{HOWITWORKS}
\begin{Fig}[ht]{LR(0) Automaton}{lr0.automaton}
\epsffile{usr032a.eps}
\end{Fig}

\begin{Fig}[ht]{Example Grammar}{EG2}
=GFT
Decl		= UninitDecl, `;`
		|  InitDecl, `;`;

UninitDecl	= var, `:`, type;

InitDecl	= var, `:`, type, `:=`, expr;
=TEX
\end{Fig}

\section{DEALING WITH PARSING CONFLICTS}\label{CONFLICTS}

\section{ERROR HANDLING}\label{ERRORS}

\appendix

\section{COMMAND LINE INTERFACE}\label{COMMAND}

\section{SLRP INPUT FORMAT}\label{INPUTFORMAT}

\section{STANDARD ML  LIBRARY}\label{LIBRARY}

\section{PARSER DRIVER INTERFACE}\label{DRIVERINTERFACE}

\end{document}

