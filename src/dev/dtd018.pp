=IGN
********************************************************************************
dtd018.doc: this file is part of the PPDev system

Copyright (c) 2002 Lemma 1 Ltd.

See the file LICENSE for your rights to use and change this file.

Contact: Rob Arthan < rda@lemma-one.com >
********************************************************************************
=TEX
%%%%% YOU MAY WANT TO CHANGE POINT SIZE IN THE FOLLOWING:
\documentclass[a4paper,12pt]{article}

%%%%% YOU CAN ADD OTHER PACKAGES AS NEEDED BELOW:
\usepackage{A4}
\usepackage{Lemma1}
\usepackage{ProofPower}
\usepackage{epsf}
\ftlinepenalty=9999
\makeindex
%%%%% YOU WILL USUALLY WANT TO CHANGE THE FOLLOWING TO SUIT YOU AND YOUR DOCUMENT:

\def\SLRP{{\sf SLRP}}
\def\Slrp{{\tt slrp}}

\def\Title{ Detailed Design for SLRP Parser Driver }

\def\Abstract{\begin{center}
{\bf Abstract}\par\parbox{0.7\hsize}
{\small This document contains the detailed design for the
driver function and associated data types and functions that provide
run-time support for the parsers generated by the
SLRP parser generator defined in DS/FMU/IED/DTD017.}
\end{center}}

\def\Reference{DS/FMU/IED/DTD018}

\def\Author{R.D. Arthan}

\def\EMail{{\tt rda@lemma-one.com}}

\def\Phone{+44 118 958 4409}

\def\Fax{+44 118 956 1920}

%%%%% YOU MAY WANT TO CHANGE THE FOLLOWING TO GET A NICE FRONT PAGE:
\def\FrontPageTitle{ {\huge \Title } }
\def\FrontPageHeader{\raisebox{16ex}{\begin{tabular}[t]{c}
\bf Copyright \copyright\ : Lemma 1 Ltd \number\year\\\strut\\
\end{tabular}}}

%%%%% THE FOLLOWING DEFAULTS WILL GENERALLY BE RIGHT:

\def\Version{\VCVersion}
\def\Date{\FormatDate{\VCDate}}

%%%%% NOW BEGIN THE DOCUMENT AND MAKE THE FRONT PAGE

\begin{document}
\headsep=0mm
\FrontPage
\headsep=10mm

%%%%% STANDARD RED-TAPE SECTIONS (MAY WANT TO INTERLEAVE SOME \newpage COMMANDS IN THESE)

%%%%% CONTENTS:

\subsection{Contents}

\tableofcontents

%%%%% REFERENCES:

\subsection{References}

\bibliographystyle{fmu}

%%%%% CHANGE THE FOLLOWING AS NECESSARY (E.G., TO PICK UP daz.bib):
{\raggedright
\bibliography{fmu}
}
%%%%% CHANGES HISTORY:
\subsection{Changes History}
\begin{description}
\item[Issues 1.1 (1991/04/12) to 1.10 (1991/09/03) ] Initial drafts.

\item[Issue 2.1 (1991/09/03), 3 September 1991 ] First approved version.

\item[Issue 2.2 (1992/01/20), (20 January 1992)] Updated to use new fonts.

\item[Issue 2.3 (1992/02/04) (4 February 1992)]
Changed the signature of $ERROR\_ROUTINE$.
\item [Issue 2.4 (1992/04/09) (1st April 1992)]
Changes required by CR0016.
\item[Issues 2.5 (2000/08/01),2.6 (2000/09/06) (6th September 2000)] Reformatted for LaTeX2e etc.
\item[Issue 2.7 (2002/10/17)] Copyright and banner updates for open source release.
\item[Issue 2.8 (2002/10/17)] PPDev-specific updates for open source release
\item[Issue 2.9 (2002/10/30)] Corrected title (particularly relevant now it does LALR(1)).
\item[Issue 2.10 (2003/02/20)] TIdy-up: now uses SML'97 syntax to be explicit about the types exported.
\item[Issue 2.11 (2003/03/06)] Reduction table entries are now arrays (althought the table itself is
still a dictionary).
\item[Issue 2.12 (2003/03/20)] Changed type of error routines to allow for error recovery by unwinding
the stacks.
\item[Issues 2.13 (2003/04/14) -- 2.15 (2003/04/16)] Organisation and narrative updated to support extracts for USR032.
\item[2014/07/23]
Augmented old RCS version numbers in the changes history with dates.
Dates will be used in place of version numbers in future.
\item[2015/04/15]
Now uses new date and version macros from doctex
%%%% END OF CHANGES HISTORY %%%%
\end{description}

%%%%%  CHANGES FORECAST:

\subsection{Changes Forecast}

There is a possible case for making the reduction table an array rather than a dictionary.

%%%%% DISTRIBUTION LIST

\subsection{Distribution}
\begin{center}
\begin{tabular}{ll}
{\Product} Development Library & Lemma 1\\
\end{tabular}
\end{center}
\begin{centering}


\end{centering}

\pagebreak
\section{GENERAL}
\subsection{Scope}
This document contains a fragment of Standard ML source code which is intended
for inclusion in parsers generated by the SLRP parser generator
defined in \cite{DS/FMU/IED/DTD017}.
The document is called for in \cite{DS/FMU/IED/HLD008}.

The functions defined here
are not visible at the user interface in release 1 of ICL HOL.
\subsection{Introduction}
A companion document \cite{DS/FMU/IED/DTD017} contains a parser generator
program. The output of this program comprises a file containing
Standard ML definitions. A skeletal example of
the output is as follows:

=GFT Example
local
	....
val slrp'a2=[[(Eos,Reduce(("T",1),1)),(Plus,Reduce(("T",1),1)),
(Times,Reduce(("T",1),1)),(Rbrack,Reduce(("T",1),1))]]@slrp'a3;
val slrp'a1=[[(Eos,Reduce(("T",0),3)),(Plus,Reduce(("T",0),3)),
(Times,Reduce(("T",0),3)),(Rbrack,Reduce(("T",0),3))]]@slrp'a2;
in
val slrp'actions=PPArray.arrayoflist slrp'a1;
end;
local
	....
val slrp'g2=[[]]@slrp'g3;
val slrp'g1=[[]]@slrp'g2;
in
val slrp'gotos=PPArray.arrayoflist slrp'g1;
end;
val slrp'reducers = list_e_merge initial_E_DICT[
("F",[(fn(x3::x2::x1::_)=>(fetch x2)|_=>raise PARSER_ERROR"invalid reduction"),
...
];
local
	...
fun slrp'r2()=[("E",[
(fn(x3::x2::x1::stk)=>(add x1 x3)|_=>raise PARSER_ERROR"invalid reduction"),
(fn(x1::stk)=>(fetch x1)|_=>raise PARSER_ERROR"invalid reduction")])]@slrp'r3();
fun slrp'r1()=[("F",[
(fn(x3::x2::x1::stk)=>(fetch x2)|_=>raise PARSER_ERROR"invalid reduction"),
(fn(x1::stk)=>(conv x1)|_=>raise PARSER_ERROR"invalid reduction")])]@slrp'r2();
in
fun slrp'reducers () = list_e_merge initial_e_dict (slrp'r1());
end;
fun slrp'gen_parser x = slrp'parse 10 slrp'actions slrp'gotos (slrp'reducers()) x;
=TEX
The purpose of this document is to define the
function $slrp'parse$ which is used in the last of these definitions.
This function is a generic implementation of the LR parsing algorithm described
in section 6.1 of \cite{Aho77}.

The introduction of \cite{DS/FMU/IED/DTD017} should be consulted before
a first reading of this document.

\subsection{Purpose and Background}
This document supplies material for inclusion in the parser for ICL HOL.

\subsection{Dependencies}
The code depends on the functional toolkit described
in \cite{DS/FMU/IED/DTD002}.
\subsection{Possible Enhancements}
The default error function supplied here only prints unreduced tokens.
It would probably be better to supply a default in which a user-supplied
function was used to print the reduced text.
\subsection{Deficiencies}
None known.
\subsection{PREAMBLE}
=DOC
signature ⦏SlrpDriver⦎ = sig
=DESCRIBE
This is the signature of the structure {\it SlrpDriver} which provides the parser driver
function and associated data types and utility functions.
=ENDDOC
\section{DATA TYPES FOR THE DRIVER}
\subsection{Parsing Stacks}
We differ slightly from \cite{Aho77} in that we work with two stacks, one
for states and one for partially parsed input.

=DOC
type ⦏STATE⦎ = int;

type ⦏STATE_STACK⦎ = STATE list;

datatype ('tok, 'lc, 'pp) ⦏INPUT_STACK_ITEM⦎
					=	⦏Token⦎ of 'tok * 'lc
					|	⦏Parsed⦎ of 'pp;
type('tok, 'lc, 'pp) ⦏INPUT_STACK⦎
	= ('tok, 'lc, 'pp) INPUT_STACK_ITEM list;
=DESCRIBE
Parser states are represented as integers, although user code should generally not
need to be aware of that. The parsing stack is represented in two parts: a state stack
and a stack of partially parsed input. These represent (respectively) the nodes and
edges making up the path from the root of LR(0) graph that has led to the current state
(in reverse order).

The partially parsed input stack contains items of two sorts: {\em(a)}
unreduced tokens, given by a pair consisting of a $'tok'$ and a $'lc$,
$'tok$ being the type of the items in the input token stream,
$'lc$ being the type of the lexical classes used, and {\em(b)},
reduced phrases represented by a value of type $'pp$.
=ENDDOC
\pagebreak
\subsection{Actions}
As in \cite{Aho77}, an action\footnote{%
The term $action$ in this document is used, as in \cite{Aho77}, to
refer to the four sorts of parsing actions made by the SLR parser driver.
These are not the same as the actions in the action grammars described
in \cite{DS/FMU/IED/DTD017}, which correspond to the reduction code
here. This  somewhat confusing terminology is, alas, traditional.
}%
takes one of the following four options:

\begin{enumerate}
\item
Shift into a given state, $s$
\item
Reduce by some alternative, $\beta$, for the nonterminal $A$. This means
that the top most $n$ items, where $n$ is the length of the alternative $\beta$
have been recognised as an $A$. In our case this means that $n$ items
are popped from the input stack and some user-defined
code is invoked to compute a $'pp$, say $A$, from them, which is then
pushed (as $Parsed\,A$) back on the stack.
\item
Accept. I.e., parsing has finished.
The input stack now contains a single $'pp$ which is the desired result.
\item
Error. The input to be parsed is invalid.
\end{enumerate}
Note that as in \cite{Aho77} the parts of the goto tables concerned
with terminal symbols (i.e., lexical classes) are held in the shift
actions.

=DOC
datatype ⦏ACTION⦎	=
				⦏Shift⦎ of STATE
			|	⦏Reduce⦎ of ((string * int) * int)
			|	⦏Dynamic⦎ of STATE * ((string * int) * int)
			|	⦏Accept⦎
			|	⦏Error⦎;
=DESCRIBE
Actions are encoded in the datatype {\it ACTION}. These represent the transitions that can
be made by the parser driver function.

{\it Shift(s)} means shift into state $s$, i.e., push $s$ and the current input token onto the parsing stacks.

{\it Reduce((N, a), m)} means reduce
to non-terminal named $N$ using the $a$-th alternative for that non-terminal and popping
$m$ entries from the parsing stacks.
Before popping the entries off the stacks, the function stored in the reduction table for the specified
alternative is called passing the input stack as the parameter.
In the tables generated by {\SLRP}, this function will be an expression of the form
{\it fn (xm::\ldots::x1::stk) ${=}{>}$ e}, where $e$ is the action for the alternative.
Thus when the action $e$ is evaluated, each
=INLINEFT
⦏xJ⦎
=TEX
\ will be bounded to the $J$-th symbol in the
alternative and
=INLINEFT
⦏stk⦎
=TEX
\ will be bound to the portion of the input stack that represents the
left context of the non-terminal that is being reduced (e.g., for use in formatting diagnostic
reports).

The {\it Dynamic} option is for a shift/reduce conflict which is to be
resolved during parsing by a user-defined routine. It combines the information required for the shift
and the reduce action. The parser driver calls a user-supplied RESOLVER function to decide
which action to take.

{\it Accept} means that a sentence in the language has been successfully parsed. The parser driver
returns the partially parsed input that makes up the single entry left on the input stack.

{\it Error} means that the input is not a sentence in the language. The parser driver calls a user-supplied
error which can either raise an exception or attempt to recover from the error. See the
description of the data type {\it ERROR\_ROUTINE} below.
=ENDDOC
\subsection{Parsing Tables}
=DOC
type ('lc)⦏ACTION_TABLE⦎
	=  ('lc * ACTION) list Array.array;
type ⦏GOTO_TABLE⦎
	= (string * STATE) list Array.array;
type ('tok, 'lc, 'pp)⦏REDUCTION_TABLE⦎
	= (('tok, 'lc, 'pp)INPUT_STACK -> 'pp) Array.array E_DICT;
=DESCRIBE

The action tables are two-dimensional arrays
indexed by states and lexical classes.
The action tables with which we work are held as one-dimensional
arrays of lists of lexical class-(action-state pair) pairs.
If the state index for these tables is out of range then the
table has been generated incorrectly
and the exception $PARSER\_ERROR$ is raised if this occurs.
User error entries correspond to valid state indices for which the
lexical class in question is not represented.

Similarly the goto tables (for the non-terminal symbols) are held
in a one-dimensional array of pairs each comprising a non-terminal name and a
state.

Finally, the user-defined reduction code (indexed by non-terminal
names and alternative indices) is held in string-indexed
dictionaries of lists of functions from (slices of) partially parsed input stacks
to $'pp$.

Indexing errors with either the goto tables or the reduction tables indicate
that the table is incorrect and cause the exception $PARSER\_ERROR$ to be
raised.

=ENDDOC
Arrays could be used if we represented non-terminals as
numbers rather than by their names, however there are advantages
for the user in using the names, since the parameterisation of the
resolver function defined later is more straightforward.
No significant performance problems have been encountered with the
present formulation.

\subsection{Conflict Resolution}
=DOC
datatype ⦏RESOLUTION⦎	=	⦏DoShift⦎
				|	⦏DoReduce⦎
				|	⦏DoError⦎;
type ('tok, 'lc, 'pp)⦏RESOLVER⦎
	= ('tok * 'lc) * ('tok, 'lc, 'pp)⦏INPUT_STACK⦎ * ((string * int) * int)
		-> RESOLUTION;
=DESCRIBE
The user-defined dynamic conflict RESOLVER function takes an input stack and the
reduction information
contained in the dynamic action and returns a value
indicating whether the parser should shift, reduce or report an error:
=ENDDOC
\subsection{Lexical Classification}
=DOC
type ('tok, 'lc)⦏CLASSIFIER⦎		 = 'tok -> 'lc;
=DESCRIBE
The CLASSIFIER function that gives the lexical class of an input token is passed to the parser driver function
as a value of this type.
=ENDDOC
\subsection{Error Handling}

=DOC
type ('tok, 'lc, 'pp, 'st)⦏ERROR_ROUTINE⦎
 	= 'tok * ('tok, 'lc, 'pp)INPUT_STACK * STATE_STACK * 'st
		-> 'tok * 'st * int;
=DESCRIBE
The ERROR ROUTINE that can either report errors or attempt to recover from them (or both)
is passed to the parser driver function as a value of this type.

The ERROR routine must either raise an exception or return a value, $(tok, st, n)$. The
latter case instructs the driver to continue as if the current input token is $tok$, the
current READER state is $st$ after popping $n$ entries from its parsing stacks.

=ENDDOC
\subsection{Input Stream}
A function of the following type is assumed to be available
to generate the input stream to be parsed. Typically $'st$ and might be
instantiated to $('tok)list$ for a parser which was to be used in a context
where all the input is to be available before parsing begins --- in this
case the reader would be a function which returns the head and tail of the argument
if the list was not empty and returns the end-of-sentence symbol and an empty list
otherwise. Alternatively, for a reader which read text from a file, $'st$ would
be instantiated to $unit$.

=DOC
type ('tok, 'st)⦏READER⦎
 			= 'st -> ('tok * 'st);
=DESCRIBE
The READER function that is used to generate the input stream to be parsed
is passed to the parser driver function as a value of this type.

The type parameter $'st$ represents some kind of internal state of the input stream.
For example, $'st$ might be
instantiated to $('tok)list$ for a parser which was to be used in a context
where all the input is to be available before parsing begins --- in this
case the reader would be a function which returns the head and tail of the argument
if the list was not empty and returns the end-of-sentence symbol and an empty list
otherwise. Alternatively, for a reader which read text from a file, $'st$ might
be instantiated to $instream$ or $unit$.

=ENDDOC

\section{THE DRIVER FUNCTION}
The driver function has the following type. The significance of its parameters
should be clear from the discussion of their
types in the previous section.
=DOC
val ⦏slrp'parse⦎:
	STATE ->
	''lc ACTION_TABLE ->
	GOTO_TABLE ->
	('tok, ''lc, 'pp) REDUCTION_TABLE ->
	('tok, ''lc, 'pp) RESOLVER ->
	('tok, ''lc) CLASSIFIER ->
	('tok, ''lc, 'pp, 'st) ERROR_ROUTINE ->
	('tok, 'st) READER -> 'st -> 'pp;
=DESCRIBE
This is the type of the parser driver function. The first parameter is the initial parser state.
The meaning of the other parameters is given in
the description of the corresponding data types above.

This function is not normally called directly from user code. Instead,
the {\tt slrp} parser generator is used to generate a file of ML code which
first binds the ML variables {\it slrp'initial\_state}, {\it slrp'actions},
{\it slrp'gotos}, and {\it slrp'reducers} to appropriate values and then
binds the ML variable {\it slrp'gen\_parser} as follows:
=GFT
fun slrp'gen_parser x =
	slrp'parse slrp'initial_state slrp'actions slrp'gotos (slrp'reducers()) x;
=TEX
The user code then applies {\it slrp'gen\_parser} to a RESOLVER, a CLASSIFIER,
an ERROR ROUTINE and a READER to give a parser for the language defined by
the grammar supplied as the input to {\tt slrp}.

Note: the bindings generated for {\it slrp'reducers} and {\it slrp'gen\_parser}
are {\it fun} bindings rather than {\it val} bindings to circumvent the limitations
imposed by the value binding restriction introduced in Standard ML '97.
=ENDDOC
\section{ERROR REPORTING}
=DOC
exception ⦏SYNTAX_ERROR⦎;
exception ⦏PARSER_ERROR⦎ of string;
=DESCRIBE
These two exceptions may be raised by the parser driver function
and associated functions.

$SYNTAX\_ERROR$ is raised by {\it default\_error}.
It is intended to signal a syntax error in the input to the parser.

$PARSER\_ERROR$ ``should not happen'': it indicates an error in the parser driver function logic
or its tables. It is also raised by the {\it default\_resolver} function (since that is intended for
use in situations where there are no shift/reduce conflicts, so that it is a design error if the
parser driver function encounters a dynamic action requiring it to call the RESOLVER function).
=ENDDOC
\section{UTILITIES FOR USER CODE}

In this section we describe functions which support the user in defining
error handling and conflict resolution functions.

\subsection{Error Handling}

=DOC
val ⦏format_stack⦎ : ('tok -> string) -> ('tok, 'lc, 'pp)INPUT_STACK -> string;
=DESCRIBE
This utility function is for use in formatting diagnostic messages.
It formats the parsing stack in reverse order (i.e., in the
same order as the input stream) as a string.
It formats the reduced entries as three dots and uses the supplied
token printer to format the unreduced entries.
=ENDDOC
=DOC
val ⦏default_error⦎:
	('tok -> string) -> ('tok, 'lc, 'pp, 'st)ERROR_ROUTINE;
=DESCRIBE
Many applications of the parser generator will be served by the
following $default\_error$ function which is parameterised by a function
to print input tokens. It writes an error message on the standard output
and then raises $SYNTAX\_ERROR$.
The messages it produces have one of the following  forms:
=GFT
*** ERROR Syntax error ***
<token> not expected after: <stack print out>
=TEX
=GFT
*** ERROR Syntax error ***
<token> not expected here
=TEX
Here ``$<token>$'' and ``$<stack print out>$'' are the result of printing
the offending input token and the parsing stack using the supplied
input token printer (and $format\_stack$).
The second form is produced if there is nothing on the stack to print out
(i.e., the error has occurred on the first token read, or the stack contains
only reduced entries).
=ENDDOC
\subsection{Conflict Resolution}
=DOC
val ⦏default_resolver⦎: ('tok, 'lc, 'pp) RESOLVER;
=DESCRIBE
The default resolver is one which raises $PARSER\_ERROR$ if it is called.
It is intended for use when there are no conflicts.
=ENDDOC
=DOC
val ⦏simple_resolver⦎:
	(('tok * 'lc) * ('tok * 'lc) -> RESOLUTION) -> ('tok, 'lc, 'pp) RESOLVER;
=DESCRIBE
For grammars which do contain shift/reduce conflicts, one of the commonest forms of
conflict resolution simply compares the latest input token with the topmost
token on the stack. $simple\_resolver$ helps you such a
resolver. Its argument is a function which compares two tokens (which
are given as a pair in input order, i.e., the latest input token comes second).
The resulting resolver will report a syntax error if there are no tokens
on the stack, a situation which corresponds, for example, to an input whose
first symbol is an infix operator.

=ENDDOC
=DOC
end; (* of signature SlrpDriver *)
=ENDDOC
\section{TEST POLICY}
Module testing for the parser driver is covered by the module testing for
the parser generator as specified in \cite{DS/FMU/IED/DTD017}.

\twocolumn[\section{INDEX}]
\small
\printindex

\end{document}



