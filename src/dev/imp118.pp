=IGN
********************************************************************************
dtd118.doc: this file is part of the PPDev system

Copyright (c) 2002 Lemma 1 Ltd.

See the file LICENSE for your rights to use and change this file.

Contact: Rob Arthan < rda@lemma-one.com >
********************************************************************************
=TEX
%%%%% YOU MAY WANT TO CHANGE POINT SIZE IN THE FOLLOWING:
\documentclass[a4paper,12pt]{article}

%%%%% YOU CAN ADD OTHER PACKAGES AS NEEDED BELOW:
\usepackage{A4}
\usepackage{Lemma1}
\usepackage{ProofPower}
\usepackage{epsf}
\makeindex
\def\Slrp{{\bf SLRP}}
\def\Hide#1{\relax}

%%%%% YOU WILL USUALLY WANT TO CHANGE THE FOLLOWING TO SUIT YOU AND YOUR DOCUMENT:

\def\Title{ Generic SLRP Parser: Implementation }

\def\Abstract{\begin{center}
{\bf Abstract}\par
{The implementation of a generic SLRP parser.}
\end{center}}

\def\Reference{DS/FMU/IED/IMP118}

\def\Author{R.D. Arthan}

\def\EMail{{\tt rda@lemma-one.com}}

\def\Phone{+44 118 958 4409}

\def\Fax{+44 118 956 1920}

%%%%% YOU MAY WANT TO CHANGE THE FOLLOWING TO GET A NICE FRONT PAGE:
\def\FrontPageTitle{ {\huge \Title } }
\def\FrontPageHeader{\raisebox{16ex}{\begin{tabular}[t]{c}
\bf Copyright \copyright\ : Lemma 1 Ltd \number\year\\\strut\\
\end{tabular}}}

%%%%% THE FOLLOWING DEFAULTS WILL GENERALLY BE RIGHT:

\def\Version{$Revision: 1.8 $%
}
\def\Date{\FormatDate{$Date: 2003/03/07 15:48:32 $%
}}

%%%%% NOW BEGIN THE DOCUMENT AND MAKE THE FRONT PAGE

\begin{document}
\headsep=0mm
\FrontPage
\headsep=10mm

%%%%% STANDARD RED-TAPE SECTIONS (MAY WANT TO INTERLEAVE SOME \newpage COMMANDS IN THESE)

%%%%% CONTENTS:

\subsection{Contents}

\tableofcontents

%%%%% REFERENCES:

\subsection{References}

\bibliographystyle{fmu}

%%%%% CHANGE THE FOLLOWING AS NECESSARY (E.G., TO PICK UP daz.bib):
{\raggedright
\bibliography{fmu}
}
%%%%% CHANGES HISTORY:
\subsection{Changes History}
\begin{description}

\item[Issues 1.1 (2003/02/26) to 1.5 (2003/03/05) ] First drafts.
\item[ Issue 1.6 (2003/03/07) ] Improved representation of {\it LEX\_VALUE}.
\item[ Issues 1.7 (2003/03/07), 1.8 (2003/03/07) ] Better interface and format for tree printing.
\item[ Issue 1.9 (2003/03/20) ] More polymorphic generic  parser interface.
\item[2014/07/23]
Augmented old RCS version numbers in the changes history with dates.
Dates will be used in place of version numbers in future.

%%%% END OF CHANGES HISTORY %%%%
\end{description}

%%%%%  CHANGES FORECAST:

\subsection{Changes Forecast}

None.

%%%%% DISTRIBUTION LIST

\subsection{Distribution}
\begin{center}
\begin{tabular}{ll}
{\Product} Development Library & Lemma 1\\
\end{tabular}
\end{center}
\newpage
\section{GENERAL}
\subsection{Scope}
This document contains the detailed design for a generic framework for a parser generated
by \Slrp. This is useful both for testing {\Slrp} and as a service to {\Slrp} users.

\subsection{Introduction}



\subsection{Purpose and Background}
%See \cite{DS/FMU/IED/IMP118}.

\subsection{Dependencies}
The design is be dependent on \cite{DS/FMU/IED/DTD017} for the data types
used.  The ML code from \cite{DS/FMU/IED/DTD017} is included when this document
is processed.

\subsection{Possible Enhancements}


\subsection{Deficiencies}

\section{PREAMBLE}
We begin the structure that contains the generic parser.
=SML
structure ⦏GenericSlrpParser⦎  : GenericSlrpParser = struct
=TEX
We open the \Slrp\ driver structure to make the datatypes and functions it exports directly
available.
=SML
open SlrpDriver;
=TEX

\pagebreak
\section{LEXICAL ANALYSIS}\label{LEXAN}

Most of this section would be highly customised for a specific SLRP application.
We have attempted to make what is given re-usable where possible and at least
illustrative where specific code is going to have to be provided.


In this subsection, we give the main material that could readily be re-used in most
applications. This covers reading the input file and the data types that represent lexical
classes. We also give the data types for our specific lexical values to illustrate the
interface that the lexical analyser should offer. This shows how the {\it CLASSIFIER}
argument of the function generated by \Slrp\ is constructed.
=TEX
\subsection{Lexical Classes and Lexical Values}

Lexical classes are the values that instantiate the type variable $'lc$ in
the parser driver structure (see \cite{DS/FMU/IED/DTD018}) while
lexical values instantiate $'tok$.


A lexical class in the generic SLRP parser is an SLRP terminal symbol.
These have the following type in the generic parser, which would also
serve in a specific application. However, one might prefer a more application-specific
representation for better type-security and performance.
=SML
datatype ⦏LEX_CLASS⦎ =
		⦏LCIdentifier⦎ of string
	|	⦏LCString⦎ of string
	|	⦏LCEos⦎;
=TEX
For us, lexical values and lexical classes are much the same thing except that the lexical
value includes the actual string that made up the value in the input and the line number
on which it occurred.
=SML
type 'lc ⦏LEX_VALUE⦎ = 'lc * (string * int);
=TEX
Now we give the classifier function, which is the {\it CLASSIFIER} argument of the function
{\it slrp'gen\_parser} defined by the ML code that \Slrp\ generates.
=SML
val ⦏classifier⦎ : ('lc LEX_VALUE,  'lc) CLASSIFIER = fst;
=TEX
The default ERROR ROUTINE needs a function to format a lexical value as a string:
=SML
fun ⦏string_of_lex_value⦎ ((LCIdentifier _, (s, _)) : LEX_CLASS LEX_VALUE) : string = s
|   string_of_lex_value (LCString _, (s, _))  = "`" ^ s ^ "`"
|  string_of_lex_value (LCEos, _) = "<end-of-input>";
=TEX
It is also useful sometimes to be able to format a lexical class:
=SML
fun ⦏string_of_lex_class⦎ ((LCIdentifier s) : LEX_CLASS) : string = s
|   string_of_lex_class (LCString s)  = "`" ^ s ^ "`"
|  string_of_lex_class LCEos = "<end-of-input>";
=TEX
t is also useful to have a function to extract the line number.
=SML
fun ⦏line_number_of_lex_value⦎ ((_, (_, ln)) : 'lc LEX_VALUE) : int = ln;
=TEX
\subsection{Tokenising an Input Line}
In this section we give the specific example of a lexical analyser that is needed for the
generic \Slrp\ parser. This illustrates how the {\it READER} argument of the \Slrp\ parsing
function might be constructed.
=TEX
During lexical analysis some kinds of token may spread over several lines.
To support these we define a continuation status data type that gives
the information needed to continue the analysis when the next line is processed.
The following data type covers comments and quoted strings which are the
two kinds of token which the generic parser lexis allows to spread over several lines.
=SML
datatype ⦏CONTINUATION_STATUS⦎ =
		⦏InComment⦎
	|	⦏InString⦎ of string list;
=TEX
The following datatype is used to record what we know about the current
token: we either don't know what it is, or we do know what it is and it has a lexical value, or we've found a comment or we're continuing something from an earlier line (whose number is recorded for use in error messages).
=SML
datatype 'lc ⦏LEX_STATUS⦎ =
		⦏Unknown⦎
	|	⦏Known⦎ of 'lc LEX_VALUE
	|	⦏Comment⦎
	|	⦏Continuation⦎ of int * CONTINUATION_STATUS;
=TEX
A state of the lexical analyser comprises a list giving the unread characters in the current line
together with our current status:
=SML
type 'lc ⦏LEX_STATE⦎ = (string list * 'lc LEX_STATUS);
=TEX
The tokens for the generic lexical analyser are the same as the tokens that denote
terminal symbols in \Slrp. These are either alpanumeric identifiers starting with
a letter or strings in back-quotes. The underscore and prime characters
are treated as letters. We also allow Standard ML style comments. We define
functions to identify each of the kinds of character of interest. It is caller's responsibility
to supply these functions with non-empty strings.
=SML
local
	open PPArray;
	val ⦏is_alpha_tab⦎ : bool array = array(256, false);
	val ⦏is_alnum_tab⦎ : bool array = array(256, false);
	val _ = map (fn i =>
		if	(i >= ord "a" andalso i <= ord "z")
		orelse	(i >= ord "A" andalso i <= ord "Z")
		orelse	i = ord "_"
		orelse	i = ord "'"
		then	(update(is_alpha_tab, i, true);
			 update(is_alnum_tab, i, true))
		else	())  (interval 0 255);
	val _ = map (fn i => update(is_alnum_tab, ord "0" + i, true))
		(interval 0 9);
	val ⦏is_space_tab⦎ : bool array = array(256, false);
	val _ = (
		update(is_space_tab, ord " ", true);
		update(is_space_tab, ord "\t", true);
		update(is_space_tab, ord "\n", true)
	);
in
	fun ⦏is_alpha⦎ (ch : string) : bool = sub(is_alpha_tab, ord ch);
	fun ⦏is_alnum⦎ (ch : string) : bool = sub(is_alnum_tab, ord ch);
	fun ⦏is_space⦎ (ch : string) : bool = sub(is_space_tab, ord ch);
	fun ⦏is_quote⦎ ("`" : string) : bool = true
	|   ⦏is_quote⦎ _ = false;
	fun ⦏is_backslash⦎ ("\\" : string) : bool = true
	|   ⦏is_backslash⦎ _ = false;
	fun ⦏is_lbracket⦎ ("(" : string) : bool = true
	|   ⦏is_lbracket⦎ _ = false;
	fun ⦏is_rbracket⦎ (")" : string) : bool = true
	|   ⦏is_rbracket⦎ _ = false;
	fun ⦏is_star⦎ ("*" : string) : bool = true
	|   ⦏is_star⦎ _ = false;
	fun ⦏is_newline⦎ ("\n" : string) : bool = true
	|   ⦏is_newline⦎ _ = false;
	fun ⦏check_next⦎ (is_x : string -> bool) (ch::more) = is_x ch
	|   check_next _ [] = false;
end (* of local ... in ... end *);
=TEX
We keep track of the line number in the text we are lexing using the following functions:
=SML
local
	val ⦏current_line⦎ : int ref = ref 0;
in	fun ⦏reset_line_number⦎  (():unit) : unit = current_line := 0;
	fun ⦏get_line_number⦎ (():unit) : int = !current_line;
	fun ⦏step_line_number⦎ (():unit) : unit = current_line := !current_line + 1;
end (* of local ... in ... end *);
=TEX
We now define functions which recognise the various kinds of token.
These recogniser functions can raise the following exception, in which
the number is the line number and the string is an error message.
=SML
exception ⦏LexFail⦎ of int * string;
fun ⦏lex_fail⦎ (msg : string) : 'a = raise LexFail(get_line_number(), msg);
=TEX
We will need a function to skip space.
=SML
fun ⦏skip_space⦎ ((chs, status) :  'lc LEX_STATE)  : 'lc LEX_STATE = (
	if	check_next is_space chs
	then	skip_space(tl chs, status)
	else	(chs, status)
);
=TEX
Comments are introduced by ``(*'' and closed by ``*)'' and they nest and so to handle
multi-line comments, we need to keep the nesting level in a ref:
=TEX
When we are recognising a comment, we have to allow for the possibility that the line
may end while we're still in the comment.
=SML
local
	val ⦏comment_nesting⦎ : int ref = ref 0;
	fun ⦏check_next_is_lcomment⦎ (ch1::ch2::more : string list) : bool = (
		is_lbracket ch1 andalso is_star ch2
	) | check_next_is_lcomment _ = false;
	fun ⦏check_next_is_rcomment⦎ (ch1::ch2::more : string list) : bool = (
		is_star ch1 andalso is_rbracket ch2
	) | check_next_is_rcomment _ = false;
in
fun ⦏rec_comment⦎ (([], status as (Continuation (_, InComment))) : 'lc LEX_STATE)
	: 'lc LEX_STATE = ([], status)
|  rec_comment (chs, status as Continuation (_, InString _)) = (chs, Unknown)
|   rec_comment (chs, status) = (
	if	check_next_is_lcomment chs
	then	(comment_nesting := !comment_nesting + 1;
		 rec_comment(tl (tl chs), Continuation(get_line_number(), InComment)))
	else if	check_next_is_rcomment chs
	then	if	!comment_nesting = 1
		then	(comment_nesting := 0;
			 (tl (tl chs), Comment))
		else if	!comment_nesting > 1
		then	(comment_nesting := !comment_nesting - 1;
			 (tl(tl chs), status))
		else	lex_fail "unmatched end-of-comment"
	else	case status of
			Continuation (_, InComment) => rec_comment (tl chs, status)
		|	_ => (chs, status)
);
fun ⦏reset_comment_nesting⦎ (():unit) : unit = comment_nesting := 0;
end (* of local ... in ... end *);
=TEX
=SML
fun ⦏rec_identifier⦎ ((chs, status) : LEX_CLASS LEX_STATE) : LEX_CLASS LEX_STATE = (
	let	fun aux acc chs = (
			if	check_next is_alnum chs
			then	aux (hd chs::acc) (tl chs)
			else	let val ident = implode (rev acc);
				in	(chs,
					 Known
					(LCIdentifier ident, (ident, get_line_number())))
				end
		);
	in	if	check_next is_alpha chs
		then	aux [hd chs] (tl chs)
		else	(chs, status)
	end
);
=TEX
=SML
fun ⦏rec_quoted⦎ ((chs, Continuation(_, InComment)) : LEX_CLASS LEX_STATE)
	: LEX_CLASS LEX_STATE =
	(chs, Unknown)
|   rec_quoted ((chs, status) ) = (
	let	fun aux ln acc chs = (
			if	check_next is_backslash chs
			then	case tl chs of
					(chs' as (ch :: more)) => aux ln (ch::acc) more
				|	[] => lex_fail "misplaced escape character"
			else if	check_next is_quote chs
			then	let	val str = implode (rev acc);
				in	(tl chs,
					Known(LCString str,
						(str, get_line_number())))
				end
			else	case chs of
					(ch :: more) => aux ln (ch :: acc) more
				|	[] => ([], Continuation(ln, InString acc))
		);
	in	case status of
			Continuation(ln, InString acc) => aux ln acc chs
		|	_ => (
			if	check_next is_quote chs
			then	aux (get_line_number()) [] (tl chs)
			else	(chs, status)
		)
	end
);
=TEX
=SML
fun ⦏rec_first⦎  (recs : ('lc LEX_STATE -> 'lc LEX_STATE) list)
	(cs : 'lc LEX_STATE) : 'lc LEX_STATE = (
	let	fun aux [] ([], status) = ([], status)
		|   aux [] (ch::more, status) =
			lex_fail
			("unrecognised character \""^ ch ^"\"")
		|   aux (r::rs) cs = (
			case r cs of
				(_, Unknown) => aux rs cs
			|	cs' => cs'
		);
	in	aux recs (skip_space cs)
	end
);
=TEX
In the following the order is important.
=SML
val rec_token : LEX_CLASS LEX_STATE ->  LEX_CLASS LEX_STATE =
	rec_first [rec_comment, rec_quoted, rec_identifier];
=TEX
The rest of the material in this section is re-usable boiler plate code that takes the
above function for lexing a single line of input and turns it into a multi-line reader that is
suitable for use as the READER in a \Slrp\ parser and that can take input from
a file or a string.

\subsection{Tokenising an Input Stream}
In this sectiion we give the code that transforms the line-at-a-time lexical analysis functions
of the previous section into a full-scale lexical analyser that can deal with a complete input
stream. All of this code is reusable boiler-plate for dealing with the input stream.

An input character stream is given as an item of the following type. We allow for general
putting back of characters on the stream although we only use one character of putback in
practice (to deal with MS-DOS and Macintosh style line terminators). We expect input
character streams to close themselves when end-of-input is read, but
will close them explicitly when errors are detected. They should be resilient against multiple closes.

=SML
type ⦏IN_CHAR_STREAM⦎ = {
	get : unit ->  string,
	close : unit -> unit,
	putback : string -> unit
};
=TEX
We provide functions to fashion an input character stream
out of a input file name (which could raise an i/o exception) \ldots.
=SML
fun ⦏in_char_stream_of_instream⦎ (strm : instream) : IN_CHAR_STREAM= (
	let	val is_open : bool ref = ref true;
		val buf : string list ref = ref [];
		fun close () = (
			if	!is_open
			then	(close_in strm; is_open := false)
			else	()
		);
		fun  get () = (
			case !buf of
				ch :: more => (buf := more; ch)
			|	[] => (
				if	!is_open
				then	case input(strm, 1) of
						"" => (
						close();
						""
					) |	ch =>  ch
				else	""
			)
		);
		fun putback ch = buf := ch :: !buf;
	in	{get = get, close = close, putback = putback}
	end
);
=TEX
=SML
val ⦏in_char_stream_of_file⦎ : string -> IN_CHAR_STREAM =
	in_char_stream_of_instream o open_in;
=TEX
\ldots or out of a string:
=SML
fun ⦏in_char_stream_of_string⦎ (str : string) : IN_CHAR_STREAM =  (
	let	val chs : string list ref = ref (explode str);
		fun close () = chs := [];
		fun get () = case !chs of ch::more => (chs := more; ch) | _ => "";
		fun putback ch = chs := ch :: !chs;
	in	{get = get, close = close, putback = putback}
	end
);
=TEX
Note that we do not expect the results of applying an input character stream more than once
to the same internal state to deliver predictable results,  except in the case when
end-of-input has been signalled, in which case we expect to get the empty string on any future call.
=TEX
GIven an input character stream the following function collects a line of input returning the input
line always including its terminating newline and an indicator of whether there is more to come.
It converts MS-DOS and Macintosh style line terminators into UNIX ones.
=SML
fun ⦏read_line⦎ ({get, putback, ...} : IN_CHAR_STREAM)   : string list * bool = (
	let	fun aux acc = (
			case get() of
				"" => ((rev ("\n"::acc), false)
			) |	"\n" => ((rev ("\n"::acc),  true)
			) |	"\r" => (
				case get() of
					"" => (rev ("\n"::acc), false)
				|	"\n" => (rev ("\n"::acc),  true)
				|	c => (putback c; (rev ("\n"::acc),  true))
			) |	ch => aux (ch::acc)
		);
	in	aux []
	end
);
=TEX
=SML
fun ⦏eof_in_continuation⦎ ((ln, InComment) : int * CONTINUATION_STATUS) : 'a = (
	lex_fail ("unmatched comment symbol on line " ^ string_of_int ln)
) | eof_in_continuation (ln, InString _) = (
	lex_fail ("unmatched quote symbol on line " ^ string_of_int ln)
);
=TEX	
In the following, the state of the READER function is a buffer containing any unprocessed characters
from the current line and a flag which is true if we have not reached the end of the stream yet.
=TEX
\ftlinepenalty=999
=SML
fun ⦏gen_reader⦎ (eos : 'lc) (rec_xxx : 'lc LEX_STATE -> 'lc  LEX_STATE) (strm : IN_CHAR_STREAM)
	: ( 'lc LEX_VALUE, string list * bool) READER = (
	let	val _ = (reset_line_number(); reset_comment_nesting());
		fun get_next (chs as (_::_), flag) = (chs, flag)
		|   get_next  ([], true) = (
			step_line_number();
			read_line strm
		)  |  get_next  eof = eof;
		fun aux st (chs,  status) = (
			case status of
				Known x => (x, (chs, st))
			|	cont as Continuation ln_status => (
				case (chs, st) of
					eof as ([], false) =>
					eof_in_continuation ln_status
				|	_ =>
				let	val sb' as (chs', st') = get_next (chs, st);
				in	aux st' (rec_xxx(chs', cont))
				end
			) |	_ => (
				case (chs, st) of
					eof as ([], false) => (
					((eos, ("", get_line_number())), eof)
				) |	_ =>
				let	val sb' as (chs', st') = get_next (chs, st);
					val (chs'', status) = rec_xxx (chs', Unknown);
				in	case status of
						Known lv => (lv, (chs'', st'))
					|	_ => aux st' (chs'', status)
				end
			)
		);
	in	fn (chs, st) => aux st (chs, Unknown)
	end	handle ex as LexFail _ => (
			#close strm ();
			raise ex
		)	
);
val ⦏reader⦎  : IN_CHAR_STREAM ->
	 (LEX_CLASS LEX_VALUE, string list * bool) READER = gen_reader LCEos rec_token;
=TEX
\section{THE GENERIC SLRP PARSER}
The generic SLRP parser produces parse trees which have the following type,
in which the string and number in a node give
the name of a non-terminal in the grammar and the number of the alternative
that gave rise to this node (counting from 1).
To help with printing, for assign unique numbers for each leaf and node
=SML
datatype 'lc ⦏GEN_PARSE_TREE⦎ =
		⦏Leaf⦎ of 'lc LEX_VALUE
	|	⦏Node⦎ of (string * int) * 'lc GEN_PARSE_TREE list;
=TEX
The type of the generic reduction function is then based on the appropriate instantiation
of the type {\it INPUT\_STACK\_ITEM}. Note that it does not use the {\it stk} argument (which
provides full information about the left context of the parser that is not relevant here)
=SML
fun ⦏generic_reducer⦎ (nti  : string * int)
	(xs : ('lc LEX_VALUE, 'lc, 'lc GEN_PARSE_TREE)
		INPUT_STACK_ITEM list)
	(stk : ('lc LEX_VALUE, 'lc, 'lc GEN_PARSE_TREE)
		INPUT_STACK_ITEM list)
	: 'lc GEN_PARSE_TREE = (
	let	fun aux (Token (lv, _)) = Leaf lv
		|   aux (Parsed tree) = tree;
	in	Node(nti, map aux xs)
	end
);
=TEX
We also provide a function for printing the tree. We present the tree as a kind of deduction
using node addresses to label the instances of the rules.
=SML
fun ⦏output_tree⦎ (f : 'lc LEX_VALUE -> string)
	(p : string -> unit) (t : 'lc GEN_PARSE_TREE) : unit = (
	let	fun print_address addr = (
			p(format_list (fn i => string_of_int i) (rev addr) ".")
		);
		fun symbol_of (Leaf lv) = (
			f lv ^
			"(" ^ string_of_int (line_number_of_lex_value lv) ^ ")"
		) | symbol_of (Node((nt, i), _)) = (
			nt
		);
		fun rule_of ((nt, i), children) = (
			nt ^  " = " ^
			format_list symbol_of children ", " ^ ";\n"
		);
		fun walk (addr, (Leaf _)) = ()
		|   walk (addr, (Node (ntic as (_, children)))) = (
			let	val addrs = map
				(fn i => i::addr)
				(interval 1 (length children));
			in	map walk (combine addrs children);
				print_address addr; p ": ";
				p(rule_of ntic)
			end

		);
	in	walk ([1], t)
	end
);
=TEX
=SML
val  ⦏print_tree⦎ : LEX_CLASS GEN_PARSE_TREE -> unit =
	output_tree string_of_lex_value (curry output std_out);
=TEX
=SML
type 'lc SLRP_GEN_PARSER =
   ('lc LEX_VALUE, 'lc, 'lc GEN_PARSE_TREE) SlrpDriver.RESOLVER ->
   ('lc LEX_VALUE, 'lc) SlrpDriver.CLASSIFIER ->
   ('lc LEX_VALUE, 'lc, 'lc GEN_PARSE_TREE, string list * bool)
	SlrpDriver.ERROR_ROUTINE ->
   ('lc LEX_VALUE, string list * bool) SlrpDriver.READER -> string list * bool -> 'lc GEN_PARSE_TREE;

=TEX
To complete the generic parser we have only to provide the remaining arguments.
The CLASSIFIER and the READER we already have and the \Slrp\ driver structure
provides suitable defaults for the RESOLVER and ERROR ROUTINE.

We construct two parsers: one for files and one for strings:
=SML
fun ⦏parse_file⦎ (slrp_gen_parser : LEX_CLASS SLRP_GEN_PARSER) (name : string)
	: LEX_CLASS GEN_PARSE_TREE = (
	slrp_gen_parser
	default_resolver
	classifier
	(default_error string_of_lex_value)
	(reader(in_char_stream_of_file name))
	([], true)
);
=TEX
=SML
fun ⦏parse_string⦎ (slrp_gen_parser : LEX_CLASS SLRP_GEN_PARSER) (text : string)
	: LEX_CLASS GEN_PARSE_TREE = (
	slrp_gen_parser
	default_resolver
	classifier
	(default_error string_of_lex_value)
	(reader(in_char_stream_of_string text))
	([], true)
);
=IGN
GenericSlrpParser.output_tree (curry output std_out) (GenericSlrpParser.parse_file slrp'gen_parse "eg.c");
=TEX
=SML
end (* of structure GenericSlrpParser *);
=TEX
\section{INDEX}
\small
\printindex
\end{document}

