=TEX
% TQtemplate.tex
\documentstyle[hol,11pt,TQ]{article}
\ftlinepenalty=9999
\def\Hide#1{}
\def\Bool{``$\it{:}bool\,$''}
\makeindex
\TPPproject{TECHNOLOGY PROJECTS}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{HOL Formalised: Language and Overview}  %% Mandatory field
\TPPref{DS/FMU/IED/SPC001}  %% Mandatory field
\def\SCCSversion{$Revision$
}
\TPPissue{\SCCSversion}  %% Mandatory field
%\TPPdate{}  %% Mandatory field (with sensible default)
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{Specification}
\TPPkeywords{HOL}
\TPPauthor{R.D.~Arthan & WIN01}  %% Mandatory field
%\TPPauthors{Name 1&location 1\\Name 2&location 2\\Name 3&location 3}
\TPPauthorisation{R.D.~Arthan & FST Team Leader}
\TPPabstract{
This document is the first in a suite of documents
which give a formal specification of HOL. It acts as an overview
to the formal treatment and includes the detailed treatment
of the HOL language.}
%\TPPabstractB{}
%\TPPabstractC{}
%\TPPabstractD{}
%\TPPabstractE{}
%\TPPabstractF{}
\TPPdistribution{\parbox[t]{4.0in}{%
      Library}}

%\TPPclass{CLASSIFICATION}
%\def\TPPheadlhs{}
%\def\TPPheadcentre{}
%def\TPPheadrhs{}
%\def\TPPfootlhs{}
%\def\TPPfootcentre{}
%\def\TPPfootrhs{}

\begin{document}
\TPPsetsizes
\makeTPPfrontpage

\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}

\newpage
\section{DOCUMENT CONTROL}
\subsection{Contents list}
\tableofcontents
\subsection{Document cross references}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes history}  % to get section number `0.3'
\begin{description}
\item[Issue 1.7 (19/10/89)]
First draft for comment.
\item[Issue 1.11 (6/11/89)]
The second draft. A number of errors have been corrected
(mainly in the definitions of substitution and type
instantiation). Comments on the first draft have been
taken into account. The initial theory $INIT$ containing
the standard axioms is defined together with the set of
theories which are extensions of it via the conservative
extension mechanisms $new\_definition$ etc.
\item[Issue 1.14 (21/11/89)]
A number of errors have been corrected as a result
of work done on the Z translation.
The document reference and theory name have been changed for IED library structure.
The appendix discussing reformulations of the logic
has been removed. It will probably
be used as a starting point for a supplementary document.
\item[Issue 1.16 (20/4/90)] Further corrections.
\item[Issue 1.17 (17/7/90)] Adapted for prototype ICL HOL. For the
time being this requires the support theories defined
in \cite{DS/FMU/IED/SML027}.
\item[Issue \SCCSversion (\FormatDate{$Date$%
})] Result of major revision. Material on inference rules
etc. has been shipped out to \cite{DS/FMU/IED/SPC003}.
Introduction now gives an overview of the documents which
make up the formalisation of HOL. The
representation of types and terms is now constructed
rather than axiomatised.
\end{description}
\subsection{Changes forecast}
The specification will be ported to the new ICL HOL when
that is available.
If the necessary support for recursive types is provided
then it will probably be used instead of the constructions
currently made here to define the types of types and terms.
\newpage
\section{GENERAL}
\subsection{Scope}
This document is part of a formal specification of the
HOL logic.
The formal specification is a formal treatment
of the description of the HOL logic and proof development
system given in chapters 9 and 10 of \cite{SRI89a}.

This document contains a brief overview of the specification
and also defines the syntax of the HOL language
as used throughout the specification.

\section{OVERVIEW OF THE SPECIFICATION}\label{OVERVIEW}
\subsection{Theoretical Background}\label{TheoreticalBackground}
It may be helpful to discuss some generalities about
the definition of logics, in order to set in context the
specific constructions we will make to specify the HOL
deductive system.
Readers who know what to expect are invited to skip this
section.
If we apply Occam's Razor fairly viciously to the
sort of definition found in, e.g., Mendelson's
textbook on logic \cite{mendelson87},
one finds that
a deductive system\footnote{
Mendelson calls it a {\it formal theory}. The term
{\it formal system} and others are also used.}
is
given by a set, $S$, whose elements we will call sentences
in this section, and a subset
$I$ of $\bigcup_{n=1}^{\infty}S^n$.
One says that $x \in S$ is {\em directly derivable} from
$X \subseteq S$ if for some $n$,
$(X^{n-1} \times \{x\}) \cap S \not= ¤$. One then says that
$x \in S$ is {\em derivable} from $X \subseteq S$,
if for some sequence $x_1,x_2, \ldots, x_k$ of elements
of $S$, $x_k = x$ and, for each $i$, $x_i$ is
either in $X$ or is directly derivable from
$\{x_1,x_2, \ldots, x_{i-1}\}$.
One says that $x \in S$ is a {\em theorem} if it
is derivable from $¤$.

In practice, $S$ is usually defined by a decidable
``well-formedness'' predicate on the free algebra, $F(\Omega)$,
over some signature, $\Omega$, and
$I$ is given as the union of a set of decidable
$n$-ary relations (the rules of inference).

The above ideas, while of theoretical value, are not
sufficient for a practical proof development system like
HOL, since, in such a system, the user can introduce
new constructs into the language $S$ by modifying
the signature $\Omega$, and can assert that certain
sentences in the extended language,
$S(\Omega)$, are axioms. For example, when a new constant
is defined in HOL, the language is extended to include
the new constant and an axiom that the constant
is equal to the value given in its definition is asserted.

Let us assume that the well-formedness predicates
and inference rules are defined so as to apply to
sentences over any signature the user can define.
This may be achieved by restricting the signatures
to be subsignatures of a signature $\Sigma_{max}$.
A predicate over $F(\Sigma_{max})$ 
then restricts to a predicate over $F(\Omega)$ for
any subsignature, $\Omega$, of $\Sigma_{max}$, and,
similarly, any set of rules of inference over
$L(\Sigma_{max})$ restricts to a set of rules of inference
over $S(\Sigma_{max})$.
Let us assume that a well-formedness predicate and
a set of rules of inference have been defined for
some signature $\Sigma_{max}$.

Let us define a  {\it theory} to be a
pair $(\Omega, X)$, where $\Omega$ is a subsignature
of $\Sigma_{max}$ as above,
and $X \subseteq S(\Omega)$. X is the set of axioms
of the theory.
A {\it theorem} in a theory, $(\Omega, X)$, is a
sentence in $S(\Omega)$ which is derivable from $X$
(with respect to the rules of inference restricted
to $S(\Omega)$).
Thus the axioms, $X$, act as additional unary rules of
inference.
Theories form a partially ordered set with respect to
inclusion. We will actually use {\it extension}: the relation
inverse to inclusion.

(The signature part of a theory can in many cases of
interest be omitted. For example, treatments of first-order
logic commonly offer an infinite supply of constant
letters and predicate letters for use in constructing
sentences. This corresponds to insisting
that each signature $\Omega$ is equal to $\Sigma_{max}$
in the above formulation. The more general
treatment discussed here seems more appropriate to HOL.)


The rules of inference over $S(\Sigma_{max})$
induce rules of inference on the sentences in the
language of a given theory. The theorems of the theory
$(\Omega, X)$ are then precisely the sentences in
$S(\Omega)$ which are derivable from $X$ using the
induced inference rules. 

A theory is {\em consistent} if
not every sentence in its language is a theorem.
Of particular interest in a practical proof development
system are mechanisms for extending a theory which
preserve consistency.
A theory $T_1$ is a {\it conservative
extension} of a theory $T$ if $T_1$ extends $T$
and all sentences in $L(T)$ which are theorems
in $T_1$ are also theorems in $T$. Clearly conservative
extensions preserve consistency. 

A {\it semantics} for a theory $(\Omega, X)$ gives meaning
to the sentences of the language $S(\Omega)$ by assigning values
to them. This is most readily done by selecting
on the basis of intuitive or theoretical considerations, some
$\Omega$-algebra, $V$ and considering the restriction to
$S(\Omega)$ of the mapping from $F(\Omega)$ given by
the universal property of a free algebra.
Such a mapping is called an $interpretation$ of the theory.
If $V$ has sufficient structure for us to view
the sentences of $S(\Omega)$ as propositions, we may
use an interpretation to reason about the rules of inference
and the axioms $X$. In particular, given a {\it a model} ---
an interpretation which maps the axioms to true propositions  ---
we may ask whether the inference rules are {\it valid}, i.e.
whether they preserve truth.
 
\subsection{Structure of the Specification}
The previous section identifies three main topics we
have to consider for HOL: its language, its deductive
system and its semantics.
We also wish to specify, at an abstract level, the critical
properties of a program purporting to support the development
of proofs in the logic.
We devote a document to each of these four topics.
In addition \cite{DS/FMU/IED/SML027} supplies some
support material.
Each document in the specification contributes an HOL theory.
The theories are briefly described in the following table:

\begin{center}
\begin{tabular}{|c|c|p{4in}|}\hline
Name&Parents & Description\\\hline
spc001&sml027\footnotemark
& This contains our definition of the
HOL language. The main definitions are types
$TYPE$, $TERM$ and $THEORY$ representing the
types, terms and theories described in \cite{SRI89a}.
\\\hline
spc002&spc001&
This specifies the semantics of the HOL language.
The main definitions are of a predicate $is\_set\_theory$
which specifies the sorts of universe
in which the semantics can be given and a predicate
$is\_model$ which specifies what it means to be a model
of a $THEORY$ in some such universe.
\\\hline
spc003&spc001&
This specifies the HOL deductive system. That is to say
it defines the notion of derivability (with respect
to a formalisation of the primitive inference rules
of HOL as described in \cite{SRI89a}).
\\\hline
spc004&\begin{tabular}{c}spc002\\spc003\end{tabular}&
This gives an abstract model of an HOL proof development
system and gives semantic and syntactic formulations
of the critical properties of such a system.
\\\hline
\end{tabular}


\footnotetext{%
This is a support theory for this document containing
definitions of operations on sets, lists, strings etc.
It is defined in \cite{DS/FMU/IED/SML027}.}%

\end{center}

Each document contains a listing of the theory which
it defines.

\subsection{Approach}
Initially we had hoped to present something which
could specify
both the deductive system
(i.e. the formal theory
in the sense of a mathematical structure with sentences,
inference rules etc.) and the
system (i.e. the program which enable one
to calculate theorems).
However, in defining the deductive system
we frequently  found that attempts to
make the specification ``constructive'' tended to
obscure some issues.
We have consequently erred on the
side of abstraction in most cases. For example, many
of the functions we need are partial functions: we
represent these as binary relations, rather than
approximate them with total functions.
This approach was felt to lead to a clearer
specification than would be obtained by using approximating
total functions together with checks on the arguments
supplied in each application.

In formalising the system we have, on occasion, felt
that certain changes would be desirable for one reason
or another. We have resisted all such urges ---
what is presented here is meant to be a rigorous
formulation of the logic as described in \cite{SRI89a}.
Where \cite{SRI89a} has proved a little too loose for our
purposes (e.g. in the details of type instantiation),
we have tried to follow the spirit of the HOL system.

There are occasionally differences in terminology
between our usage and \cite{SRI89a}. We have attempted
to indicate these as they arise.
This is most evident in the semantics since our treatment
is in HOL rather than ZF set theory as used in \cite{SRI89a}.

\subsection{Notation}
The specification is written to be processed
by the ICL prototype HOL system and makes heavy use
of the Z-like specification features it provides.
These features are briefly explained here.

Constants are intoduced using constant definition
boxes which have the form:
 È
	c1 : ty1,
	c2 : ty2,
	...
É
	P
Ë
The intention of this is to introduce new constants, $c1$, $c2$, \ldots, satisfying the property $P$ using
$new\_specification$,
and, if the consistency proposition required
be $new\_specification$ can be proved automatically
by one of a range of heuristics, then the effect is
exactly that. If the consistency proposition cannot be
proved automatically the constants are still introduced
but with a defining property which is consistent and which
is equivalent to $P$ if $P$ is consistent.
A metalanguage function ``$specification$'', analagous
to ``$definition$'' may be used to extract the defining
property from the theory database.

Some use is made of a function $subtype\_def$ which
is an analogue of the constant definition box for defining
types and deferring any proof obligations. It has two
arguments the first giving the name of the new type and
the second giving the desired defining predicate.

Other significant
differences from Cambridge HOL are that object
language terms are quoted using Strachey brackets,
``»'' and ``¼'', and that type abbreviations with arguments
are supported (any type variables in the definition
of the the abbreviation become arguments).
\pagebreak
\section{PREAMBLE}
\Hide{
extend_theory"SPC001";
}
We introduce the new theory. Its parent is a
library theory containing various definitions we need.
å
close_theory();
load_theory"sml027";
new_theory"âspc001á";
æ
\section{THE SYNTAX OF TYPES AND TERMS} \label{TYPESANDTERMS}

We now embark on defining the language of HOL. The treatment
will follow the lines discussed in section \ref{TheoreticalBackground} above.
However, since we are only interested in a particular
language we do not do any general universal
algebra.
Thus, apart from a minor complication
dealt with in section \ref{SEQUENTS} below, defining our
version of
$F(\Sigma_{max})$ and $L(\Sigma_{max})$
amounts
to specifying the language of HOL types and terms.

The language is defined informally in \cite{SRI89a}
by a grammar essentially the same as the following
(in which the terminal symbols, $tyvar$,
$tyop$ etc., stand for names of various sorts of
objects).


óBNF
	type	=	tyvar					(* Type Variable *)
		|	`(`, type, {`,`, type}, `)`, tyop;		(* Compound Type *)

	term	=	var, `:`, type				(* Variable *)
		|	con, `:`, type				(* Constant *)
		|	term, term				(* Application *)
		|	``, var, `:`, type, ``, term;
	(* -abstraction *)
æ

Here the atomic types and function
types of \cite{SRI89a} are subsumed by the compound types
(an atomic type being a compound type with no parameters
and a function type being one with exactly two parameters
and with the type operator `$$').


The type and term languages are subject to
well-formedness rules of two sorts: 
context-sensitive rules governing
conformance of the type of a
constant or the arity of a type
with a definition of the constant or type contained
in a theory;
and the ``local'' rule that the operator of
a combination be of an appropriate type to apply
to its operand.
To avoid a mutual recursion between the types
$TYPE$, $TERM$ and $THEORY$ which we are going to define,
we will not impose the context-sensitive rules as part
of the definitions of $TYPE$ and $TERM$. Instead, when
we define the type $THEORY$, we insist that any types
or terms which appear in a theory satisfy appropriate
conditions.
In the following subsections we therefore only consider
the local well-typing rule. 

If machinery were available to define the recursive
types we need automatically, we would probably use it
(to define the free algebra of types and a free algebra
which would have the type of terms as a subset).
Unfortunately, the type $TYPE$ involves a recursion
through the $list$ type constructor and this is not
currently supported by T. Melham's system for defining
recursive types (and no analogue is currently available
for the ICL HOL). Consequently we work here with an
explicit concrete
representation of types and terms using strings.

\subsection{Names}
We could, in priniciple, take the names which appear
in types and terms from some arbitrary type. However the
extra generality would add complexity and does not seem to
offer any benefit over
the natural representation of names as strings.

It is, however, technically convenient to allow arbitrary strings
to be used as names (since this lets us formulate and
use the constructor functions for types and terms in a natural way).
To enable this we use
an encoding of names in the concrete representation which
allows an arbitrary string to be viewed as a name.
To do this we use an escape character to
protect any occurrences of the characters which act
as delimiters in the concrete representation of types
or terms.

We use `$\$$' as the escape character (in fact any
character other than `(', `)', `,', `:', `' or `' would
do). 
The encoding is then given by the following function:
È
	âencodeá : string  string
É
	encode `` = ``
	ch s
	encode (ch ++ s) =
		(string_of_char ch Å[`$`; `(`; `)`; `,`; `:`; ``; ``]
		=>  `$` & (ch ++ encode s)
		| ch ++ encode s)
Ë

The range of the function $encode$ will comprise the
strings produced by the following grammar:
óBNF
	name	=	``
		|	(char - (`$` | `(` | `)` | `,` | `:` | `` | ``)), name
		|	`$`, char, name;
æ
\subsection{Types}
Our concrete representations for types are the strings which
satisfy a predicate, $is\_type,$ defined below.
This is satisfied only by the strings produced
by the following grammar:
óBNF
	type	=	name
		|	`(`, [type, {`,`, type}], `)`, name;
æ

The following utility function is used to construct
the argument lists of compound types.
È
	âcomma_listá : string list  string
É
	comma_list [] = ``
	x t  comma_list (CONS x t) = (t = [] => x | x & `,` & comma_list t)
Ë
The operations on strings which will
represent the constructor functions of the type $TYPE$
are the following:
È
	âmk_vartype_repá: string  string

É
	smk_vartype_rep s = encode s
Ë
È
	âmk_type_repá: string  string list   string
É
	s tlmk_type_rep(s, tl) = `(` & comma_list tl & `)` & (encode s)
Ë
We may now define $is\_type$ as the smallest set
which is closed under the constructors $mk\_vartype\_rep$
and $mk\_type\_rep$.
È
	âis_typeá : string  bool
É
	is_type = ¢(X:stringbool
	(s(mk_vartype_rep s)  X)
	(pars tycon
		(parpar Å pars  par  X)
		(mk_type_rep(tycon, pars))  X))
Ë
We prove that $is\_type$ is non-empty and use
the result to define a new type, $TYPE$.
å
val thm1 = save_thm "âthm1á" (TAC_PROOF( ([], »sencode s  is_type¼),
	EVERY[	REWRITE_TAC[specification"-" "is_type",
			specification"sml027""¢",
			specification"-""mk_vartype_rep"],
		CONV_TAC(DEPTH_CONV SET_BETA_CONV) THEN REPEAT STRIP_TAC,
		ASM_REWRITE_TAC[]]));
æ
The definition of the new type follows the usual pattern:  
å
val TYPE_DEF = new_type_definition "âTYPE_DEFá" "âTYPEá" []
	(TAC_PROOF( ([], »tyis_type ty¼),
		(EXISTS_TAC »encode s¼ THEN
		REWRITE_TAC[PURE_ONCE_REWRITE_RULE[specification"sml027"""]thm1])))
	NORMAL;
æ
å
val TYPE_lemmas = show(
	define_new_type_isomorphisms TYPE_DEF "âTYPE_lemmasá"
	("ABS_TYPE", NORMAL) ("REP_TYPE", NORMAL) );
æ
The constructor functions for the new type are:
È
	âmk_vartypeá: string  TYPE

É
	smk_vartype s = ABS_TYPE (mk_vartype_rep s)
Ë
\ldots and:
È
	âmk_typeá: string  TYPE list   TYPE
É
	s tlmk_type(s, tl) = ABS_TYPE(mk_type_rep(s, map REP_TYPE tl))
Ë
We will also need a destructor function for
types:
È
	âdest_typeá: TYPE  string  (TYPE list)
É
	s tyldest_type(mk_type(s, tyl)) = (s, tyl)
Ë
\ldots and the constant type \Bool:
È
	âBoolá : TYPE
É
	Bool = mk_type(`bool`, [])
Ë
\subsection{Terms}
The representation type for the well-formed terms will
be $stringTYPE$. The $string$ component gives the
concrete representation of the term according to
the following grammar:
óBNF
	term	=	`V`, name, `:`, type
		|	`C`, name, `:`, type
		|	`(`, term, `)(`, term, `)`
		|	`V`, name, `:`, type, ``, term;
æ
The $TYPE$ component gives the type
of the term.  This representation is analogous to the terms
subscripted with their types one finds in \cite{SRI89a}.
(Note that the types which appear in the $string$ components
are not redundant. Without them it would not in general
be possible to recover the types of the constituents of
a combination, so that the constructor, $mk\_comb$
for combinations would not be injective.)
 
The constructor functions for the type of terms will be
represented by the following operations on strings.

È
	âmk_var_repá : string  TYPE  string
É
	s ty  mk_var_rep (s, ty) = 
		`V` & encode s & `:` & REP_TYPE ty
Ë
È
	âmk_const_repá : string  TYPE  string
É
		s ty  mk_const_rep (s, ty) = 
		`C` & encode s & `:` & REP_TYPE ty
Ë
È
	âmk_comb_repá : string  string  string
É
	tm1 tm2  mk_comb_rep (tm1, tm2) = 
		`(` & tm1 & `)(` & tm2 &`)`
Ë
È
	âmk_abs_repá : string  TYPE  string  string
É
	s ty tm  mk_abs_rep (s, ty, tm) =
		 `V` & s & `:` & REP_TYPE ty & `` & tm
Ë
The following utility for forming function types is useful:
È
	âFuná : TYPE  TYPE  TYPE
É
	 ty1 ty2Fun ty1 ty2 = mk_type(``, [ty1; ty2])
Ë
The following predicate picks out the well-formed
terms, by imposing the appropriate typing rules.
È
	âis_wf_termá : (string  TYPE)  bool
É
	is_wf_term = ¢(X:(string  TYPE)  bool
	(s ty(mk_var_rep(s, ty), ty)  X)
	(s ty(mk_const_rep(s, ty), ty)  X)
	(f a tya ty((f, Fun tya ty)  X  (a, tya)  X)  (mk_comb_rep(f, a), ty)  X)
	(s b tys tyb (b, tyb)  X  (mk_abs_rep(s, tys, b), Fun tys tyb)  X))
Ë
We prove that variables are indeed well-formed according
to the above condition: 
å
val thm2 = save_thm "âthm2á" (TAC_PROOF( ([], »s ty(mk_var_rep(s, ty), ty)  is_wf_term¼),
	EVERY[REWRITE_TAC[specification"-" "is_wf_term", specification"sml027""¢"],
	CONV_TAC(DEPTH_CONV SET_BETA_CONV) THEN REPEAT STRIP_TAC,
	ASM_REWRITE_TAC[]]));
æ
The definition of the new type follows the usual pattern:  
å
val TERM_DEF = new_type_definition "âTERM_DEFá" "âTERMá" []
	(TAC_PROOF( ([], »tmis_wf_term tm¼),
		(EXISTS_TAC »(mk_var_rep(s, ty), ty)¼ THEN
		REWRITE_TAC[PURE_ONCE_REWRITE_RULE[specification"sml027"""]thm2])))
	NORMAL;
æ
å
val TERM_lemmas = show(
	define_new_type_isomorphisms TERM_DEF "âTERM_lemmasá"
	("ABS_TERM", NORMAL) ("REP_TERM", NORMAL) );
æ
We can now define a function which assigns to any term
its type:
È
	âtype_of_termá : TERM  TYPE
É
	 tm   type_of_term tm = SND(REP_TERM tm)
Ë
The constructor functions for the type $TERM$, namely
$mk\_var$, $mk\_const$, $mk\_comb$ and $mk\_abs$,
could be defined as composites of
$mk\_cand\_var$ etc. and
the abstraction and representation functions for $TERM$.
Unfortunately the resulting functions
$mk\_comb$ and $mk\_abs$ are not total functions\footnote{%
$mk\_abs$ could be reparameterised to be total quite simply,
but we prefer to follow the treatment of \cite{SRI89a}.
$mk\_comb$, however, is of necessity partial}.
Attempts to use an approximating total function turn out
to lead to difficulties when we wish to define functions
on terms by cases.
Thus we must use relations to represent these constructors.
Implementations exploit the fact
that the relations corresponds to a partial function.

In our informal discussions below we will often use the
name $mk\_comb$ and $mk\_abs$
to refer to these relations viewed as partial functions
(i.e. with applicative notation).

The names chosen for the relations are intended to be
suggestive of phrases like: {\it(`x:num', ``1'') has mk\_abs 
``x:num1''}.
È
	âmk_vará : (string  TYPE)  TERM
É
	 s ty  mk_var (s, ty) = ABS_TERM (mk_var_rep(s, ty), ty)
Ë
È
	âmk_constá : (string  TYPE)  TERM
É
	 s ty mk_const (s, ty) = ABS_TERM (mk_const_rep(s, ty), ty)
Ë
È
	âhas_mk_combá : (TERM  TERM)  TERM  bool
É
	 f a tm 
	has_mk_comb (f, a) tm 
	ty	REP_TERM tm = (mk_comb_rep(FST(REP_TERM f), FST(REP_TERM a)), ty)
		type_of_term f = Fun (type_of_term a) ty
	
Ë
È
	âhas_mk_absá : (TERM  TERM)  TERM  bool
É
	v b tm  has_mk_abs (v, b) tm 
	( s tys mk_var(s, tys) = v
		REP_TERM tm =
		(mk_abs_rep(s, tys, FST(REP_TERM b)), Fun tys (type_of_term b)))

Ë

\subsection{Instantiation of Types}
When we define the type of HOL theories
we will need the following
function to formulate some of context-sensitive conditions
that we will wish to impose.
È
	âinst_typeá : (string  TYPE)  TYPE  TYPE
É
	(f: string  TYPE) 
		(s  inst_type f (mk_vartype s) = f s)
		(s tlinst_type f (mk_type(s, tl)) =
			mk_type(s, map (inst_type f) tl))
Ë


\section{SYNTAX OF SEQUENTS} \label{SEQUENTS}
The minor complication mentioned in the previous
section is that HOL is defined as a sequent calculus.
Sequents are defined in section \ref{SEQUENTS}.
It is the sequents which make up our $L(\Sigma_{max})$.

A sequent is simply a set of assumptions
and a conclusion. Assumptions
and conclusion alike are just terms.
The following definition allows infinite
assumption sets, since they are easier for us to define.
However the axioms with which we shall work all have
finite sets of assumptions and the inference rules
will preserve this property.
Another pleasant property of sequents is for their
constituent terms to have type \Bool. This property,
too, holds of our axioms and is preserved by our inference
rules and we define theories we insist that the
sequents in them have it.

å
TypeInference.new_type_abbrev"âSEQá" »:(TERM  bool)  TERM¼;
æ

The following functions on sequents are useful for reasons
of clarity. Their names are as in the HOL system. 
È
	âconclá : SEQ  TERM
É
	concl = SND 
Ë

È
	âhypá : SEQ  (TERM  bool)
É
	hyp = FST 
Ë


\section{THEORIES} \label{THEORIES}
In this section we define a type $THEORY$ whose
elements are what we shall think
of as the well-formed HOL theories.
In our case, the signature part of a theory amounts to 
two ``environments'', one giving the arity of the type
constructors in the theory and the other giving
the types of the constants\footnote{
These correspond to the {\it type structures} and
{\it signatures} respectively in \cite{SRI89a}.}.


The following type abbreviations help us to
formalise the context-sensitive aspects of the
well-formedness of terms, which we have avoided until
now. Once this is done we can define the type of all
well-formed HOL theories.

å
TypeInference.new_type_abbrev "âTY_ENVá" »:string  num  bool¼;

TypeInference.new_type_abbrev "âCON_ENVá" »:string  TYPE  bool¼;

TypeInference.new_type_abbrev "âSEQSá" »:SEQ  bool¼;
æ


We can now define the well-formedness of types and terms with
respect to a type environment. We assume that
the names for type variables and type constructors
are in distinct lexical classes, and so all we
check is the arity of constructors.
(HOL implementations may impose additional lexical
constraints on the names.)
 
È
	âwf_typeá : TY_ENV  TYPE  bool
É
	 tyenv 
	wf_type tyenv = ¢(tyset
	(s  mk_vartype s  tyset)
	
	s tyl  (tyenv s (length tyl)   t  (t Å tyl)  t  tyset)  mk_type(s, tyl)  tyset)
Ë
For terms we place no restrictions on the names of
variables. (The HOL system tries to prevent constant
names being used as variable names but does not
always succeed, e.g, if the constant is declared after
a theorem using a variable with the same name has been
saved on a theory).
The polymorphic nature of constants in HOL becomes
apparent here in that we may instantiate type variables
appearing in the constant environment.

È
	âwf_termá: TY_ENV  CON_ENV  TERM  bool
É
	 tyenv conenv 
	wf_term tyenv conenv = ¢(tmset
	(s tyty  wf_type tyenv  mk_var(s, ty)  tmset)
	
	(s ty	(ty  wf_type tyenv  ty' tysubsty'  conenv s  inst_type tysubs ty' = ty) 
		 mk_const(s, ty)  tmset)
	
	(f a tm(has_mk_comb(f, a) tm  f  tmset  a  tmset)  tm  tmset)
	
	(v b tm(has_mk_abs(v, b) tm  v  tmset  b  tmset)  tm  tmset))
Ë
The well-formedness of terms extends straightforwardly
to sequents and to sets thereof. We impose an
additional constraint for sequents: they must be
made up from terms of type \Bool.

È
	âwf_seqá: TY_ENV  CON_ENV  SEQ  bool
É
	 seq tyenv conenv
	seq  wf_seq tyenv conenv 
	let ok = tm (tm  wf_term tyenv conenv)  (type_of_term tm = Bool)
	in 
	(ok (concl seq)  (tm tm  (hyp seq)  ok tm))
Ë

È
	âwf_seqsá: TY_ENV  CON_ENV  SEQS  bool
É
	 seqs tyenv conenv
	seqs  wf_seqs tyenv conenv   seq  (seq  seqs)  (seq  wf_seq tyenv conenv)
Ë

For the constant environments, we insist that the
type associated with each name be well-formed and
that at most one type is associated with each name.
Overloaded constant names could, in principle, be allowed,
as an extension to the system. This function would then be
modified to impose some weaker condition.

È
	âwf_con_envá: TY_ENV  CON_ENV  bool
É
	 conenv tyenv
	conenv  wf_con_env tyenv 
	( con ty (ty  conenv con)  (ty  wf_type tyenv)) 
	( con ty1 ty2  (ty1  conenv con)  (ty2  conenv con)  (ty1 = ty2))
Ë

We insist that at most one arity be associated with
each name in a well-formed type environment:

È
	âwf_ty_envá: TY_ENV  bool
É
	 tyenv
	tyenv  wf_ty_env 
	 ty n1 n2  (tyenv ty n1)  (tyenv ty n2)  (n1 = n2)
Ë

We will consider a triple consisting of a type
environment, a constant environment and a set of
sequents to be a well-formed theory if each constituent
is well-formed with respect to its predecessors:
È
	âis_theoryá: TY_ENV  CON_ENV  SEQS  bool
É
	ty_env con_env axiomsis_theory(ty_env, con_env, axioms) 
		ty_env  wf_ty_env 
		con_env  wf_con_env ty_env 
		axioms  wf_seqs ty_env con_env
Ë

Note that a theory can contain infinitely many
types, constants, or axioms. This possibility
occurs in practice, at least for constants and axioms.
The theory  of natural numbers is an example, since
it contains an axiom defining the decimal representation
of each positive number. 

å
val thm3 = save_thm "âthm3á" (TAC_PROOF(
	([] ,  »is_theory((t nF), (c tF), (sF))¼),
	EVERY[
		REWRITE_TAC[specification"-""is_theory",
			specification"-""wf_ty_env",
			specification"-""wf_con_env",
			specification"-""wf_seqs"],
		CONV_TAC(DEPTH_CONV SET_BETA_CONV),
		REWRITE_TAC[]]));
æ
å
val THEORY_DEF = new_type_definition "âTHEORY_DEFá" "âTHEORYá" []
	(TAC_PROOF( ([], »thyis_theory thy¼),
		(EXISTS_TAC »((t nF), (c tF), (sF)):TY_ENV  CON_ENV  SEQS¼ THEN
		ACCEPT_TAC thm3)))
	NORMAL;
æ
å
val THEORY_lemmas = show(
	define_new_type_isomorphisms THEORY_DEF "âTHEORY_lemmasá"
	("ABS_THEORY", NORMAL) ("REP_THEORY", NORMAL) );
æ

We will use the following functions to extract the components
of theories:
È
	âaxiomsá : THEORY  SEQS
É
	 thy  axioms thy = SND(SND(REP_THEORY thy))
Ë
È
	âtypesá : THEORY  TY_ENV
É
	 thy  types thy = FST(REP_THEORY thy)
Ë
È
	âconstantsá : THEORY  CON_ENV
É
	 thy  constants thy = FST(SND(REP_THEORY thy))
Ë
The following function which reuturns the set of sequents
which are in the language associated with a theory
is also useful:
È
	âsequentsá : THEORY  SEQS
É
	 seq thy 
		(seq  sequents thy) 
		(seq  wf_seq (types thy) (constants thy))
Ë

\pagebreak
\section{THEORY LISTING}
{\catcode`\_=\active
\gdef\underscoreoff{% make _ a normal char
        \catcode`\_=\active \let_=\_}}
{\underscoreoff
\def\Xref#1#2{\hbox to \hsize{$#1$\leaders\hbox to1em{\hss.\hss}\hfill $#2$}}
\input{\jobname.thp}}

\twocolumn[\section{INDEX OF DEFINED TERMS}]
\printindex
\end{document}

=IGN

fun const_refs (thy : string) (what : TERM) : (string * SEQ) list = (
	let	val (s, _) = dest_const what;
		val tc = map fst o term_constants;
		fun aux (_, seq) = (
			not(s mem tc(snd seq) orelse
			any (fst seq) (fn tm => s mem tc tm))
		);
	in	(axioms thy drop aux) @ (definitions thy drop aux) @ (theorems thy drop aux)
	end handle msg => divert msg "dest_const" "const_refs"
	"term argument must be a constant"
);
e(CONV_TAC(DEPTH_CONV SET_BETA_CONV));
The following theorem is needed to help justify a type definition
in \cite{DS/FMU/IED/SPC003}:


val thm3 = save_thm "thm3"(TAC_PROOF(([], »tyenv smk_vartype s  wf_type tyenv¼),
	REWRITE_TAC[specification"-""wf_type", specification"sml027""¢"] THEN
	CONV_TAC(DEPTH_CONV SET_BETA_CONV) THEN REPEAT STRIP_TAC THEN ASM_REWRITE_TAC[]));


The following theorem is needed in \cite{DS/FMU/IED/SPC003}:

val thm4 = save_thm "thm4"(TAC_PROOF(([], »tyenv conenv s tmk_var(s, mk_vartype t)  wf_term tyenv conenv¼),
	EVERY[
		REWRITE_TAC[specification"-""wf_term", specification"sml027""¢"] THEN
			CONV_TAC(DEPTH_CONV SET_BETA_CONV) THEN REPEAT STRIP_TAC,
		ASSUME_TAC (SPECL[»tyenv:TY_ENV¼, »t:string¼]thm3),
		RES_TAC,
		ASM_REWRITE_TAC[]]));


