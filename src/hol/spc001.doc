% TQtemplate.tex
\documentstyle[hol,11pt,TQ]{article}
\ftlinepenalty=9999
\def\Hide#1{}
\def\Bool{``$\it{:}bool\,$''}
\makeindex
\TPPproject{TECHNOLOGY PROJECTS}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{A Formal Specification of HOL}  %% Mandatory field
\TPPref{DS/FMU/IED/SPC001}  %% Mandatory field
\def\SCCSversion{$Revision$
}
\TPPissue{\SCCSversion}  %% Mandatory field
%\TPPdate{}  %% Mandatory field (with sensible default)
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{Specification}
\TPPkeywords{HOL}
\TPPauthor{R.D.~Arthan & WIN01}  %% Mandatory field
%\TPPauthors{Name 1&location 1\\Name 2&location 2\\Name 3&location 3}
\TPPauthorisation{R.B.~Jones & FMU Manager}
\TPPabstract{
A formal specification, in HOL, of the HOL logic is presented.
Some high level aspects of the HOL proof development system
are also formalised.}
%\TPPabstractB{}
%\TPPabstractC{}
%\TPPabstractD{}
%\TPPabstractE{}
%\TPPabstractF{}
\TPPdistribution{\parbox[t]{4.0in}{%
      R.D. Arthan \\ M.J.C. Gordon (Cambridge) \\ R.B.Jones \\ K. Blackburn \\ G.M. Prout
}}

%\TPPclass{CLASSIFICATION}
%\def\TPPheadlhs{}
%\def\TPPheadcentre{}
%def\TPPheadrhs{}
%\def\TPPfootlhs{}
%\def\TPPfootcentre{}
%\def\TPPfootrhs{}

\begin{document}
\TPPsetsizes
\makeTPPfrontpage

\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}

\newpage
\section{Document control}
\subsection{Contents list}
\tableofcontents
\subsection{Document cross references}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes history}  % to get section number `0.3'
\begin{description}
\item[Issue 1.7 (19/10/89)]
First draft for comment.
\item[Issue 1.11 (6/11/89)]
The second draft. A number of errors have been corrected
(mainly in the definitions of substitution and type
instantiation). Comments on the first draft have been
taken into account. The initial theory $INIT$ containing
the standard axioms is defined together with the set of
theories which are extensions of it via the conservative
extension mechanisms $new\_definition$ etc.
\item[Issue \SCCSversion (21/11/89)]
A number of errors have been corrected as a result
of work done on the Z translation.
The document reference and theory name have been changed for IED library structure.
The appendix discussing reformulations of the logic
has been removed. It will probably
be used as a starting point for a supplementary document.
\end{description}
\subsection{Changes forecast}
Some brief description of the Z-like notations used may
be added for the benefit of readers who are not familiar with it.
\newpage
\section{GENERAL}
\subsection{Scope}
This document is an attempt to specify the
syntactic aspects of the
HOL logic using the HOL system.
The document should be viewed as a formal treatment
of chapters 3, 4 and 5 of Mike Gordon's
description (\cite{gordon87}) of the HOL logic and proof development system.
The bulk of the document is concerned with defining the
logic. Some high level aspects of the implementation
of the proof development system are also discussed.
\subsection{Introduction}
Initially we had hoped to present the
specification to serve
both as a specification of the logic
(i.e. the formal theory
in the sense of a mathematical structure with terms,
well-formed terms, inference rules etc.) and the
system (i.e. the program which enable one
to calculate theorems).
However, in defining the logic
we frequently  found that attempts to
make the specification ``constructive'' tended to
obscure some issues. We have consequently erred on the
side of abstraction in most cases. For example, many
of the functions we need are partial functions: we
represent these as binary relations, rather than
approximate them with total functions.
This approach was felt to lead to a clearer
specification than would be obtained by using approximating
total functions together with checks on the arguments
supplied in each application.

In formalising the system we have, on occasion, felt
that certain changes would be desirable for one reason
or another. We have resisted all such urges ---
what is presented here is meant to be a rigorous
formulation of the logic as described in \cite{gordon87}.
Where \cite{gordon87} has proved a little too loose for our
purposes (e.g. in the details of type instantiation),
we have tried to follow the spirit of the HOL system.

During preparation of the specification we received
a draft of relevant chapters of the new HOL manual which
is currently being prepared at Cambridge. 
There are some differences of terminology
between the new manual and our treatment.
However, we have tried to adopt the treatment of the basic
theories given in the new manual.

\subsection{Defining Logics}
It may be helpful to discuss some generalities about
the definition of logics, in order to set in context the
specific constructions we will make to specify HOL.
Readers who know what to expect are invited to skip this
section.

If we apply Occam's Razor fairly viciously to the
sort of definition one finds in, e.g., Mendelson's
textbook on logic \cite{mendelson87},
one finds that
a logic\footnote{
Mendelson calls it a {\it formal theory}. The terms
{\it deductive system}, {\it formal system} and others are also used.}
is
given by a set, $S$, whose elements we will call sentences
in this section, and a subset
$I$ of $\bigcup_{n=1}^{\infty}S^n$.
One says that $x \in S$ is {\em directly derivable} from
$X \subseteq S$ if for some $n$,
$(X^{n-1} \times \{x\}) \cap S \not= ¤$. One then says that
$x \in S$ is {\em derivable} from $X \subseteq S$,
if for some sequence $x_1,x_2, \ldots, x_k$ of elements
of $S$, $x_k = x$ and, for each $i$, $x_i$ is
either in $X$ or is directly derivable from
$\{x_1,x_2, \ldots, x_{i-1}\}$.
One says that $x \in S$ is a {\em theorem} if it
is derivable from $¤$.

In practice, $S$ is usually defined by a decidable
``well-formedness'' predicate on the free algebra, $F(\Omega)$,
over some signature, $\Omega$, and
$I$ is given as the union of a set of decidable
$n$-ary relations (the rules of inference).

The above ideas, while of theoretical value, are not
sufficient for a practical proof development system like
HOL, since, in such a system, the user can introduce
new constructs into the language $S$ by modifying
the signature $\Omega$, and can assert that certain
sentences in the extended language,
$S(\Omega)$, are axioms. For example, when a new constant
is defined in HOL, the language is extended to include
the new constant and an axiom that the constant
is equal to the value given in its definition is asserted.

Let us assume that the well-formedness predicates
and inference rules are defined so as to apply to
sentences over any signature the user can define.
This may be achieved by restricting the signatures
to be subsignatures of a signature $\Sigma_{max}$.
A predicate over $F(\Sigma_{max})$ 
then restricts to a predicate over $F(\Omega)$ for
any subsignature, $\Omega$, of $\Sigma_{max}$, and,
similarly, any set of rules of inference over
$L(\Sigma_{max})$ restricts to a set of rules of inference
over $S(\Sigma_{max})$.
Let us assume that a well-formedness predicate and
a set of rules of inference have been defined for
some signature $\Sigma_{max}$.

Let us define a  {\it theory}. to be a
pair $(\Omega, X)$, where $\Omega$ is a subsignature
of $\Sigma_{max}$ as above,
and $X \subseteq S(\Omega)$. X is the set of axioms
of the theory.
A {\it theorem} in a theory, $(\Omega, X)$, is a
sentence in $S(\Omega)$ which is derivable from $X$
(with respect to the rules of inference restricted
to $S(\Omega)$).
Thus the axioms, $X$, act as additional unary rules of
inference.
Theories form a partially ordered set with respect to
inclusion. We will actually use {\it extension}: the relation
inverse to inclusion.

(The signature part of a theory can in many cases of
interest be omitted. For example, treatments of first-order
logic commonly offer an infinite supply of constant
letters and predicate letters for use in constructing
sentences. This corresponds to insisting
that each signature $\Omega$ is equal to $\Sigma_{max}$
in the above formulation. The more general
treatment discussed here seems more appropriate to HOL.)


The rules of inference over $S(\Sigma_{max})$
induce rules of inference on the sentences in the
language of a given theory. The theorems of the theory
$(\Omega, X)$ are then precisely the sentences in
$S(\Omega)$ which are derivable from $X$ using the
induced inference rules. 

A theory is {\em consistent} if
not every sentence in its language is a theorem.
Of particular interest in a practical proof development
system are mechanisms for extending a theory which
preserve consistency.
A theory $T_1$ is a {\it conservative
extension} of a theory $T$ if $T_1$ extends $T$
and all sentences in $L(T)$ which are theorems
in $T_1$ are also theorems in $T$. Clearly conservative
extensions preserve consistency. 

\subsection{Overview of the Specification}
\subsubsection{The Logic}
Our treatment of the HOL logic follows approximately
the pattern discussed in the previous section.
However, since we are only interested in a particular
class of languages we do not do any general universal
algebra.
Thus, apart from a minor complication, defining our
version of
$F(\Sigma_{max})$ and $L(\Sigma_{max})$
amounts
to specifying the abstract syntax for HOL terms and
the subset of terms which are well-typed (ignoring
context-sensitive constraints such as the agreement
of the arity of a type with that given in some definition). This is done in section \ref{TYPESANDTERMS}.

The minor complication is that
HOL is defined as a sequent calculus.
Sequents are defined in section \ref{SEQUENTS}.
It is the sequents which make up our $L(\Sigma_{max})$.

In our general discussion above we have not
prohibited unary rules of inference, i.e. axioms by
another name. Such rules are a convenient home
for those axioms which we wish to have in every theory.
The HOL logic has three axiom schemata which are naturally
given as unary rules. These
are defined in section \ref{AXIOMSCHEMATA}.
The other rules of inference are defined in section
\ref{RULESOFINFERENCE}.

With the rules of inference over $L(\Sigma_{max})$
in hand, we define derivability in section
\ref{DERIVABILITY} and then move on to consider
theories in section \ref{THEORIES}.
In our case, the signature part of a theory amounts to 
two ``environments'', one giving the arity of the type
constructors in the theory and the other giving
the types of the constants\footnote{
These correspond to the {\it type structures} and
{\it signatures} respectively in the new manual.}.
In addition to the environments and the axioms, our
theories also contain a set of theorems of the theory.
This enables the same notion of theory to be used in
describing the proof development system: the theorems
in the sets represent the theorems that the user has proved in that theory.
We then define the type of theorems of HOL as those pairs
$(s, T)$ where $T$ is a theory and $s$ is a sequent in the
language of $T$ derivable from the axioms of $T$.

Section \ref{CONSISTENCY},
defines the type of all theorems and
specifies the notions of consistency and conservative
extension.

Mechanisms for extending theories by
making definitions are of great practical
importance, particularly those which preserve consistency.
Section \ref{DEFINITIONS} discusses
the means by which theories may be extended in the HOL
system. Of particular importance are certain mechanisms
for introducing new constants and types.

In section \ref{INIT} we define the individual axioms
of the HOL logic.
The resulting theory is of special
interest, as are what we call its standard extensions,
which we define in section \ref{STANDARD}:
they are all consistent and have
a common standard set-theoretic model;
their theorems comprise what are normally taken to
be the theorems of HOL by those who shun axiomatic
extensions.

\subsubsection{The HOL System}

In sections \ref{RULESOFINFERENCEREVISITED}
and \ref{THEORYHIERARCHIES}
we turn to specifying some high level aspects of
the HOL proof development system.
Many of the types and functions used to specify
the logic may already be viewed as specifying
corresponding parts of the implementation.
We now wish to specify a generic type representing
the state of the HOL system together with some
useful operations for modifying that state.


The designer of a proof development system
is interested in ensuring
that the theorems which the users compute are indeed
derivable from the axioms of the theory involved.
The LCF approach to this problem is to use
a programming language supporting the
abstract data type concept. Theorems are represented
as elements of an abstract
data type whose constructor functions consist
precisely of the rules of inference (suitably parameterised
so that they are partial functions rather than arbitrary
relations).
In this way, the type system of the programming
language helps to ensure that only valid theorems may be
derived. In section \ref{RULESOFINFERENCEREVISITED} we
define the action of the rules of inference on
our type of theorems. These definitions can be viewed as a high level
specification of the constructor functions of the
abstract data type.
Such functions are used to
extend the set of theorems stored within a theory.


Finally, section \ref{THEORYHIERARCHIES} discusses
an abstraction of the database side of the proof development
system.
The concept of a named hierarchy of theories
is introduced and an abstraction of the state of
an HOL proof development system is presented.
Given this, we can define the generic type of an HOL
system and so define general predicates on such systems,
e.g., {\it safety:} the property of those HOL systems
which only allow consistent extensions.
In producing a very high assurance implementation
of HOL, this would give the starting point for some
meaningful proof work: one might attempt to prove 
the safety of a design which was founded on
the theorem proving mechanisms of section
\ref{RULESOFINFERENCEREVISITED} and the (conservative)
definitional mechanisms of section \ref{DEFINITIONS}.

\subsection{Introducing the new theory}

\Hide{
extend_theory`spc001`;;
map loadf [`TAUT`;`infra`];;
lemmas_on := false;;
garbage_collection_diags false;;
}
We introduce the new theory. Its parents are
library theories which we will use later.
We set some controls for the infrastructure which
supports the Z-like definition mechanism and for the
ML system. We 
å
new_theory`spc001`;;
map new_parent [`string`; `infra`; `set`];;
map loadf [`infra`];;
lemmas_on := false;;
garbage_collection_diags false;;
æ
The following ML detects what was a common source of
error in earlier versions of this document.
It adds an extra check to the handling of constant and schema
definition boxes.
å
let standard_const_def = const_def;;
let standard_schema_def = schema_def;;
let check_def tm = 
	let msg1 =`check_def: free variable `
	in let msg2 = ` found in predicate of definition`
	in let (names, def_frees) = ((frees # frees) o dest_pair) tm
	in (map (xmem x names => () | prt_string (msg1^(fst(dest_var x))^msg2)) def_frees; ());; 
let const_def tm = (check_def tm; standard_const_def tm);;
let schema_def name abb tm = (check_def tm; standard_schema_def name abb tm);;
æ
The generalised union operation and the function $card$,
which assigns to a finite set the number of its elements,
are currently not available in the particular version of
the HOL infrastructure used here. We specify them here
for completeness. The definitions will be removed when
a more up-to-date version of the infrastructure is
available for use here.
È
	£ : ((*  bool)  bool)  (*  bool)
É
	 sets x  x  £ sets = setx  set  set  sets
Ë

È
	card : (*  bool)  
É
		(card ¤ = 0)
		 x  (card(singleton_set x) = 1)
		 set x card(set Ä singleton_set x) = card set - card (set   singleton_set x)
Ë

\section{THE SYNTAX OF TYPES AND TERMS} \label{TYPESANDTERMS}

In this section we define the abstract syntax of HOL terms
and of the types which they contain.
The terms will be given as a subtype of a type of ``free
terms''. The subtype will comprise the terms which
are well-typed in a sense we will define shortly.

The well-formedness check does not consider
context-sensitive issues such as
conformance of the type of a
constant or the arity of a type
with the definition of the constant or type ---
such considerations are deferred until we have defined the
notion of a theory.
To some extent this approach is forced on us
since we wish to define a type of well-formed terms.
Since the system does not permit dependent types the
well-formedness predicate cannot be parameterised by
any form of context.

To define types for the various syntactic classes,
we use {\tt new\_type}. To populate them, we use
{\tt new\_constant} to define constructor functions.
To lend verisimilitude to our
account, we formulate an axiom for each new type which
characterises its constructor functions. The axiom
gives a principle of definition by structural recursion,
which might be used to justify the functions which we
will later specify on the types.
The consistency of the specification
could, we hope, be demonstrated using T.~Melham's
system for defining recursive types.
As things stand the rigour of our specification is on a
par with that of a VDM or Z specification.

\subsection{Types}
As a consequence of our approach,
the syntactic class of HOL types is a free algebra.
It is only in the context of the type definitions within
a theory that a type can be ill-formed.

å
new_type 0 `TYPE`;;

new_constant (`âmk_vartypeá`,":string  TYPE");;

new_constant (`âmk_typeá`,":string  TYPE list  TYPE");;

let âTYPE_axiomá = new_axiom(`TYPE_axiom`,"
	(f0:string  *) (f1: string  TYPE list  * list  *)
        À (fn:TYPE  *)
         (s fn(mk_vartype s) = f0 s) 
         (s tl fn(mk_type (s,tl)) = f1 (s, tl) (map fn tl))
");;
æ

We have need of the following destructor
function for composite types

È
	âdest_typeá: TYPE  string  (TYPE list)
É
		dest_type o mk_type = I
Ë

\subsection{Free Terms}

The type {\it FTERM} is the syntactic class 
for the free algebra comprising
``HOL terms which are well-formed enough to parse, but
which are not necessarily well-typed''.
The syntactic class of HOL terms will be defined
as  a subset of {\it FTERM}.

å
new_type 0 `FTERM`;;

new_constant (`âmk_fvará`,":string  TYPE  FTERM");;

new_constant (`âmk_fconstá`,":string  TYPE  FTERM");;

new_constant (`âmk_fcombá`,":FTERM  FTERM   FTERM");;

new_constant (`âmk_fabsá`,":string  TYPE  FTERM   FTERM");;

let âFTERM_axiomá = new_axiom(`FTERM_axiom`,"
	
	(f0:string  TYPE  *)
	(f1:string  TYPE  *)
	(f2: FTERM  FTERM  *  *  *)
	(f3: string  TYPE  FTERM  *  *)
        À (fn:FTERM  *)
         (s ty	fn (mk_fvar (s, ty))
			= f0 (s, ty))
	  (s ty	fn(mk_fconst (s, ty))
			= f1 (s, ty))
	  (f a	fn(mk_fcomb (f, a))
			= f2 (f, a) (fn f, fn a))
	  (v ty b	fn(mk_fabs (v, ty, b))
			= f3 (v, ty, b) (fn b))
");;
æ

\subsection{Free Variables}
To illustrate how the principle of definition
by structural recursion for the type {\it FTERM}
might be used, we specify some simple functions
which are useful later and whose specifications could
be proved consistent using it.

{\it freevars\_fset} returns the set of free variables
of a term.
We use it in cases where the order of appearance
of the free variables in the term is immaterial.

È
	âfreevars_fsetá: FTERM  (string  TYPE  bool)
É
	(s : string) (t : TYPE) (f : FTERM)
	(a : FTERM) (v : string) (b : FTERM) 
	(freevars_fset (mk_fvar(s,t)) = x x = (s,t))
	(freevars_fset (mk_fconst(s,t)) = x F)
	(freevars_fset (mk_fcomb(f, a)) =
			(freevars_fset f) ¡ (freevars_fset a))
	(freevars_fset (mk_fabs(v, t, b)) =
			(freevars_fset b) Ä x x = (v,t))
Ë

{\it freevars\_flist} returns the free variables of a term
listed in order of first appearance (from left to
right in the usual concrete syntax).

È
	âfreevars_flistá: FTERM  ((string  TYPE)list)
É
	(s : string) (t : TYPE) (f : FTERM)
	(a : FTERM) (v : string) (b : FTERM) 
	(freevars_flist (mk_fvar(s,t)) = [(s,t)])
	(freevars_flist (mk_fconst(s,t)) = [])
	(freevars_flist (mk_fcomb(f, a)) =
			freevars_flist f µ
			(freevars_flist a Á xx Æ freevars_flist f))
	(freevars_flist (mk_fabs(v, t, b)) =
			freevars_flist b Á x x  (v,t))
Ë

\subsection{Typing Terms}

We now give the relation which relates a free term
to its type, if it has one.

Note that two variables
with the same name but different types are simply
considered as different. This agrees with both
the HOL logic and the HOL system (in which, while a term
containing two such names in the same scope cannot
be entered directly  via the parser, the constructor functions 
may be used to achieve the effect).

We do not check here that the type assigned to
a constant is an instance of the type with which it
is declared. Indeed, the mechanisms needed to do
this involve the notion of a theory, which is defined
in a later section.

A function returning object language\footnote{
The observant reader will notice at least
four languages in this document: English as a
metametametalanguage, ML as a metametalanguage,
HOL as a metalanguage and the HOL language we are defining.
We will use the term {\it object language} exclusively
for the last of these.} function types is useful:

È
	âFuná : TYPE  TYPE  TYPE
É
	 ty1 ty2Fun ty1 ty2 = mk_type(``, [ty1; ty2])
Ë
Note that, since we think if $type\_of\_fterm$ as a binary
relation rather than a set valued function, we use a slightly
different style for its definition from that used for, say,
$freevars\_fset$.
È
	âtype_of_ftermá: FTERM  TYPE  bool
É
	(s : string) (t : TYPE) (ty: TYPE)
	 (f : FTERM) (a : FTERM) (v : string)
	 (b : FTERM) 
	(type_of_fterm (mk_fvar(s,t)) ty = (t = ty))
	(type_of_fterm (mk_fconst(s,t)) ty = (t = ty))
	(type_of_fterm (mk_fcomb(f, a)) ty = 
		t1(type_of_fterm f (Fun t1 ty))  (type_of_fterm a t1))
	(type_of_fterm (mk_fabs(v, t, b)) ty = 
		t1(type_of_fterm b t1)  (Fun t t1 = ty))
Ë

\subsection{Well-Formedness and the Type of Well-Formed Terms}

A term is well-formed if it has a type:

È
	âis_wf_termá : FTERM  bool
É
	term:FTERM
	is_wf_term term = type:TYPE type_of_fterm term type
Ë

We now define the type {\it TERM} of well-formed terms
as a subtype of the type {\it FTERM} of free terms.

å
	sim_type_def `âTERMá` ("x:FTERM, is_wf_term x");;
æ

Constructor functions for the type $TERM$
could be defined as composites in terms of
the constructor functions for $FTERM$ and
the abstraction and representation functions for
$TERM$. E.g., $\it mk\_comb\,\,=\,\,ABS\_TERM\,o\,mk\_fcomb$
Unfortunately the resulting function
$mk\_comb$ is not a total function.
Attempts to use an approximating total function turn out
to lead to difficulties when we wish to define functions
on terms by cases.
Thus we must use relations, at least for $\it mk\_comb$.
For uniformity we do this in all four cases.
The implementations will exploit the fact
that these relations correspond to partial functions.

In our informal discussions below we will often use the
names $mk\_var$, $mk\_const$, $mk\_comb$ and $mk\_abs$
to refer to these relations viewed as partial functions
(i.e. with applicative notation). We actually define
total functions which approximate the partial functions
when we need, later on, to define a number of particular
terms.

The names chosen for the relations are intended to be
suggestive of phrases like: {\it(`1', ``:num'') has mk\_var 
``1''}.
È
	âhas_mk_vará : string  TYPE  TERM  bool
É
	 s ty tm  has_mk_var (s, ty) tm = tm = ABS_TERM (mk_fvar(s, ty))
Ë
È
	âhas_mk_constá : string  TYPE  TERM  bool
É
	 s ty tm  has_mk_const (s, ty) tm = tm = ABS_TERM (mk_fconst(s, ty))
Ë
È
	âhas_mk_combá : (TERM  TERM)  TERM  bool
É
	 f a tm 
	has_mk_comb (f, a) tm =
	let rep = mk_fcomb(REP_TERM f, REP_TERM tm)
	in
	(is_wf_term rep  (tm = ABS_TERM rep))
	
Ë
È
	âhas_mk_absá : (TERM  TERM)  TERM  bool
É
	v b tm  has_mk_abs (v, b) tm =
	( s ty  has_mk_var (s, ty) v  (tm = ABS_TERM(mk_fabs(s, ty, REP_TERM b))))
Ë

We also define functions for typing terms and extracting
free variables using the ones we have already defined
for free terms:

È
	âtype_of_termá : TERM  TYPE
É
	 tm   type_of_fterm (REP_TERM tm) (type_of_term tm)
Ë
È
	âfreevars_setá : TERM  (string  TYPE  bool)
É
	freevars_set = freevars_fset o REP_TERM 
Ë
È
	âfreevars_listá : TERM  ((string  TYPE) list)
É
	freevars_list = freevars_flist o REP_TERM 
Ë

\section{SYNTAX OF SEQUENTS} \label{SEQUENTS}
A sequent is simply a set of assumptions
and a conclusion. Assumptions
and conclusion alike are just terms.
The following definition allows infinite
assumption sets, since they are easier for us to define.
However the axioms with which we shall work all have
finite sets of assumptions and the inference rules
will preserve this property.
Another pleasant property of sequents is for their
constituent terms to have type \Bool. This property,
too, holds of our axioms and is preserved by our inference
rules. When we define theories we insist that the
sequents in them have the latter property.

å
new_type_abbrev(`âSEQá`, ":(TERM  bool)  TERM");;
æ

The following functions on sequents are useful for reasons
of clarity. Their names are as in the HOL system. 
È
	âconclá : SEQ  TERM
É
	concl = SND 
Ë

È
	âhypá : SEQ  (TERM  bool)
É
	hyp = FST 
Ë


\section{THE RULES OF INFERENCE} \label{RULESOFINFERENCE}

In this section we treat the syntax manipulating
functions required to define the various rules of
inference. We consider each inference rule in turn.
In the HOL system the inference rules are functions
which take theorems (and other things) as arguments
and return theorems. Since we cannot define
the type of theorems until we have defined the inference
rules we define the rules as functions taking
sequents (and other things) as arguments and returning
sequents.

\subsection{Object Language Constructs}

To define the rules of inference we need to form
certain object language types and terms.
We have already defined the function space type
constructor.
The other definitions needed are given in this
section.

We need the constant type \Bool:
È
	âBoolá : TYPE
É
	Bool = mk_type(`bool`, [])
Ë

We need to form instances of the polymorphic constant
``='':

È
	âEqualityá : TYPE  TERM
É
	 ty  Equality ty = thas_mk_const(`=`, Fun ty (Fun ty Bool)) t
Ë

The following is our analogue of the derived
constructor function for equations in the HOL system.

È
	âhas_mk_eqá : (TERM  TERM)  TERM  bool
É
	 lhs rhs tm  has_mk_eq(lhs, rhs) tm =
	( tm2 
		has_mk_comb(Equality(type_of_term lhs), lhs) tm2
		has_mk_comb(tm2, rhs) tm)
Ë

We also need to form implications. The following functions
are analogous to those treating equality above.
È
	âImplicationá : TERM
É
	Implication = thas_mk_const(``, Fun Bool (Fun Bool Bool))t
Ë

È
	âhas_mk_impá : (TERM  TERM)  TERM  bool
É
	 lhs rhs tm  has_mk_imp(lhs, rhs) tm =
	( tm2 
		has_mk_comb(Implication, lhs) tm2
		has_mk_comb(tm2, rhs) tm)
Ë


\subsection{Substitution of Equals: SUBST}

In this section we define the inference rule {\it SUBST}.

In essence, {\it SUBST} says that given a
theorem whose conclusion is an equation, ${\cal A} = {\cal B}$, where
$\cal A$ and $\cal B$ are arbitrary terms of the same
type, and given any other theorem with conclusion
$\cal C$, we may obtain a new theorem by substituting
$\cal B$ for 
any subterm of $\cal C$ which is identical with $\cal A$. This is subject to the proviso that no variable
capture problems arise, i.e. no
free variables of $\cal B$ should become bound in the
conclusion of the new theorem. (The assumption set of the
consequent theorem is the union of the assumption sets of
the antecedent theorems.)

The inference rule is, in fact, slightly more
general. It allows one to use a whole set of theorems
whose conclusions are equations to perform (simultaneous)
substitutions for many subterms of $\cal C$. Moreover,
it is implemented as a functional relation, effectively by
renaming any bound variables of $\cal C$ which would
give rise to the capture problem.

The inference rule is parametrised by a template term
and a set of some of its free variables, one for each equation.
The actual statement of the rule is, essentially, that, 
if the result of substituting the left hand sides
of the equations for the corresponding variables
in the template term
is equal to $\cal C$ ({\it modulo} renaming bound
variables), then we may infer the result of substituting
the right hand sides of the equations for the
corresponding template variables in the template term
(providing we rename bound variables to avoid the capture
problem).


The notions we must formalise are therefore: (i) renaming a variable in a term; (ii) testing equivalence of
terms {\it modulo} renaming of bound variables (aka.
$\alpha$-conversion); (iii) substituting terms for
free variables in a term according to a given mapping
of variables to terms avoiding variable capture.


\subsubsection{Renaming}
We will need to choose new names for variables.
More precisely,
given a variable and a set of same we will
wish to rename the variable, when necessary,
to ensure that the result
does not lie in the set.
In practice in an implementation we would insist that the new name
be derived from the old one in a specified way.

È
	âvariantá : (string  TYPE  bool)  (string  TYPE)  string
É
	 vs v ty  ((v, ty)  vs) => (variant vs (v, ty) = v) | (variant vs (v, ty), ty)  vs
Ë

$rename (v, ty) w\, e$ is the result of changing
the name in every free occurrence of the
variable with name $v$, and type $ty$, in the
term $e$, to $w$, renaming any bound variables
as necessary.

È
	ârenameá : (string  TYPE)  string  TERM  TERM
É
	
	(v : string) (ty : TYPE) (w: string) (tm : TERM)
	(s :string) (tty : TYPE)
	(f : TERM) (a : TERM) (vty : TERM) (bb : TERM)
	
	(has_mk_var (s, tty) tm 
	(rename (v, ty) w tm =
			((v = s)  (ty = tty)) =>
			(thas_mk_var(w, ty)t) | tm))
	
	(has_mk_const(s, tty) tm  (rename (v, ty) w tm = tm))
	
	(has_mk_comb(f, a) tm 
	(rename (v, ty) w tm = thas_mk_comb(rename(v, ty) w f, rename(v, ty) w a)t))
	
	((has_mk_abs (vty, bb) tm  has_mk_var(s, tty) vty) 
	(rename (v, ty) w tm =
		((v = s)  (ty = tty)) =>
			tm |
		((w = s)  (ty = tty)  ((v, ty)  freevars_set bb)) =>
			(let s' = variant (freevars_set bb Ä singleton_set (v, ty) ¡
							singleton_set (s, ty)) (s, ty)
			in let vty' = rename (s, ty)s' vty
			in let bb' = rename (s, ty)s' bb
			in
			(thas_mk_abs(vty', rename (v, ty) w bb')t)) |
			(thas_mk_abs(vty, rename (v, ty) w bb)t)))

Ë


\subsubsection{$\alpha$-conversion}

È
	âaconvá : TERM  TERM  bool
É
	(t1 : TERM) (t2 : TERM)
	aconv t1 t2 =
		(t1 = t2)
		(t1f t1a t2f t2a
			has_mk_comb(t1f, t1a)t1
			has_mk_comb(t2f, t2a)t2
			aconv t1f t2f  aconv t1a t2a)
		(v1 v2 ty v1ty v2ty b1 b2
			has_mk_abs(v1ty, b1)t1		has_mk_abs(v2ty, b2)t2
			has_mk_var(v1, ty)v1ty		has_mk_var(v2, ty)v2ty
			aconv b1 (rename (v2, ty) v1 b2)
			((v1 = v2)  ((v1, ty)  freevars_set b2)))
Ë

\subsubsection{Substitution}

The following function is useful in {\it subst} and
elsewhere. It sends a function to the function it induces
on the powersets of its domain and codomain.

È
Ý	âimageá :  (*  **)  (*  bool)  (**  bool)
É
Ý	function set image function set = 
Ý		x:** y:* (x = function y)  y  set
Ë

Now we can define $subst$. $subst F t1$ gives the
term resulting from replacing every free variable
$mk\_var(s, t)$
in {\it t1} by $\it F(mk\_var(s, t))$ with bound
variables renamed as necessary to avoid capture.
Variables which are not to be changed correspond
to pairs $(s, t)$ with $F (s, t) =  mk\_var (s, t)$.
Note that we rely on $variant$
not to change bound variable names unnecessarily.

È
	âsubstá : (string  TYPE  TERM)  TERM  TERM
É
	 (R :string  TYPE  TERM) (tm : TERM)
	(s : string) (ty : TYPE) (vty : TERM)
	(f : TERM) (a : TERM) (b : TERM)
	
	 
	(has_mk_var(s, ty)tm  (subst R tm = R(s,ty)))
	
	(has_mk_const(s, ty)tm  (subst R tm = tm))
	
	(has_mk_comb(f, a) tm 
	(subst R tm = thas_mk_comb(subst R f, subst R a)t))
	
	((has_mk_abs(vty, b) tm  has_mk_var(s, ty) vty) 
	(subst R tm =
		let new_frees = £(image (freevars_set o R) (freevars_set b Ä singleton_set (s, ty)))
		in  let s' = variant new_frees (s, ty)
		in let RR = x (x = (s', ty)) => (thas_mk_var x t) | R x
		in
			t
			has_mk_abs
			((vvttyhas_mk_var(s', ty)vvtty), subst RR (rename (s, ty) s' b))t
	))
Ë

We can now define the inference rule.
Its first argument gives the correspondence between the
template variables and equation theorems.
We could take this argument to 
behave as {\it REFL\_axiom o mk\_var} on variables which
are not template variables . 
Note that, to allow implementation as a partial function,
we test up to $\alpha$-convertibility on the first
sequent argument only.

È
	âSUBST_ruleá : ((string  TYPE)  SEQ) 
			TERM  SEQ  SEQ  bool
É
	 eqs tm old_asms old_conc new_asms  new_conc
	SUBST_rule eqs tm (old_asms, old_conc) (new_asms, new_conc) = 
	(v ty  
		lhs rhs
		has_mk_eq(lhs, rhs)(concl(eqs(v, ty))) 
		(type_of_term lhs = ty))
	
	(aconv old_conc (subst((v,ty)lhsrhshas_mk_eq(lhs, rhs)(concl(eqs(v,ty))))tm))
	
	(new_conc = subst ((v,ty)rhslhshas_mk_eq(lhs, rhs)(concl(eqs(v,ty))))tm)
	
	(new_asms = old_asms ¡ £ (asmsvtyasms = (hyp (eqs vty))))
Ë



\subsection{Abstraction: ABS}

Again {\it ABS} is a partial function which we
specify as a relation:

È
	âABS_ruleá : (string  TYPE)  SEQ  SEQ  bool
É
	 vty old_asms old_conc new_asms new_conc 
	ABS_rule vty (old_asms, old_conc) (new_asms, new_conc) =
	( old_lhs old_rhs new_lhs new_rhs v
		has_mk_eq(old_lhs, old_rhs)old_conc 
		has_mk_eq(new_lhs, new_rhs)new_conc 
		has_mk_var vty v 
		has_mk_abs(v, old_lhs) new_lhs 
		has_mk_abs(v, old_rhs) new_rhs)
	
	(vty  £(image freevars_set old_asms))
	
	(new_asms = old_asms)
Ë



\subsection{Type Instantiation: INST\_TYPE}

The ability to prove and use general (polymorphic)
theorems  is one of the great strengths of the HOL
system. The feature in the inference system which
gives this strength is the inference rule {\it INST\_TYPE}
which allows us to instantiate the type variables
in the conclusion of a polymorphic theorem.

In essence, the inference rule says that, given a theorem
with conclusion $\cal A$ say we may infer the theorem
which has the same assumption set and whose conclusion
results from instantiating every type in $\cal A$
according to a given mapping of type variables to types.
This is subject to two provisos: (i) no type variable may
be changed which appears in the assumption set for the
theorem; (ii) no two variables in the assumptions or
conclusion of the antecedent theorem, which are
different, by virtue of their type,  should become
identified in the consequent theorem as a result of
the transformation.

The first proviso is, we believe, only enforced to preserve
a convention of natural deduction systems,
whereby inference rules
involve only simple set operations on the assumption
sets. It would seem to be quite in order for the first
proviso to be dropped provided we insisted that the
type instantiation be applied to every term in the sequent
(we have, of course, not done this).

The second proviso cannot be avoided. Consider for
example: $(x:**)(x:*)(x:**)$. If the types in this were
instantiated according to $\{:**  :*, :*  :*\}$,
then from:
$$ (y:**)(z:*)((x:**)(x:*)(x:**))y z = y$$
we could infer that:
$$ (y:*)(z:*)((x:*)(x:*)(x:*))y z = y$$
whence, by $\beta$-conversions:
$$ (y:*)(z:*)z = y.$$
This leads to a contradiction whenever $:*$ is instantiated
to a type with more than one inhabitant.

To permit an implementation which is convenient to use,
the inference rule is actually formulated without the
second proviso. Instead, variables (both free and bound,
in general) in the conclusion of the consequent theorem,
which would violate the rule are renamed to
avoid the problem. It is valid to rename free variables
in these circumstances, given the first proviso, since
the variables in question cannot occur free in the
assumption set. Note that it would be invalid to
rename free variables in $\cal A$
which are not changed by the type instantiation
(since these may appear free in the assumption set).

Formalising these notions is a little tricky. We present
here a highly unconstructive specification, reminiscent
of $\alpha$-conversion.
The two notions to be formalised are: (i) the type
instantiation of a type given by a mapping of
type variables to types and (ii) the predicate on
pairs of terms which says that one is a type instance
of another according to a given mapping of type
variables to types and with respect to a set of
variables with which clashes must not occur (this
will be the set of free variables of the assumptions
in practice).

It is entertaining and instructive to consider
algorithms meeting these specifications.


\subsubsection{Instantiation of Types}
This is straightforward:
È
	âinst_typeá : (string  TYPE)  TYPE  TYPE
É
	(f: string  TYPE) 
		(s  inst_type f (mk_vartype s) = f s)
		(s tlinst_type f (mk_type(s, tl)) =
			mk_type(s, map (inst_type f) tl))
Ë

\subsubsection{Instantiation of Terms}

Instantiation of terms is a little tricky.
The following two functions should be viewed as
local to the function {\it inst}.
{\it inst\_loc1} is very similar to an
$\alpha$-convertibility test. Indeed {\it aconv} could
have been defined as $\it inst\_loc1\,I$.
The first {\it TERM} argument of {\it inst\_loc1}
and {\it inst\_loc2}
gives the terms whose types are being instantiated (i.e.
it is the ``more polymorphic'' term).

$inst\_loc1$ checks that one term, $tm2$, is a type
instance of $tm1$, according to a mapping from
type variable names to types given by $tysubs$,
under the assumption that the free variable names
agree, i.e. that the first occurrence of each variable which
may need renaming will be its binding occurrence in
a $-abstraction$.
È
	âinst_loc1á : (string  TYPE)  TERM  TERM  bool
É
	
	(tysubs : string  TYPE)
	(tm1 : TERM) (tm2 : TERM)
	inst_loc1 tysubs tm1 tm2 =
		(tm1s tm1t tm2s tm2t has_X
			((has_X = has_mk_var)  (has_X = has_mk_const))
			has_X(tm1s, tm1t)tm1  has_X(tm2s, tm2t)tm2
			(tm1s = tm2s)  (tm2t = inst_type tysubs tm1t))
		(tm1f tm1a tm2f tm2a
			has_mk_comb(tm1f, tm1a)tm1  has_mk_comb(tm2f, tm2a)tm2
			inst_loc1 tysubs tm1f tm2f  inst_loc1 tysubs tm1a tm2a)
		(v1 v2 ty1 ty2 b1 b2 v1ty1 v2ty2 
			has_mk_var(v1, ty1) v1ty1  has_mk_abs(v1ty1, b1)tm1
			has_mk_var(v2, ty2) v2ty2  has_mk_abs(v2ty2, b2)tm2
			inst_loc1 tysubs (rename (v1, ty1) v2 b1) b2
			(ty2 = inst_type tysubs ty1)
			 ty3 v2ty3 
				has_mk_var(v2, ty3) v2ty3
				(v2, ty3)  freevars_set b1
				(ty2 = inst_type tysubs ty3)
				(v2ty3  v1ty1) )
Ë

$inst\_loc2$ uses $inst\_loc1$ to check that a term $tm2$
is a type instance of the result of renaming free
variables of a term $tm2$ according to a mapping
given by a list of pairs. It also checks that
the type of the second variable in each pair in the list
is a type instance of the type of the first variable
in the pair,
and that the second variable in each pair
is not in the set, $avoid$, unless both names and types
agree for that pair.
In the application of $inst\_loc2$ in $inst$ the list
of pairs is obtained by combining the free variable lists
of the two terms side by side.
The set $avoid$ is a set of variables (coming from
the assumptions of a sequent) whose free occurrences
must not change as a result of the type instantiation.
È
	âinst_loc2á : ((string  TYPE)  bool)  
		(string  TYPE) 
		(((string  TYPE)  (string  TYPE)) list) 
		TERM  TERM  bool
É
	(avoid : (string  TYPE)  bool)
	(tysubs :string  TYPE)
	(v1 : string) (ty1 : TYPE)
	(v2 : string) (ty2 : TYPE)
	(rest : ((string  TYPE)  (string  TYPE)) list)
	(tm1 : TERM) (tm2 : TERM)
	(inst_loc2 avoid tysubs [] tm1 tm2 =
		inst_loc1 tysubs tm1 tm2)
	
	(inst_loc2 avoid tysubs (CONS ((v1, ty1),(v2, ty2)) rest) tm1 tm2 =
		((v2, ty2)  avoid  ((v1, ty1) = (v2, ty2)))
		(ty2 = inst_type tysubs ty1)
		inst_loc2 avoid tysubs rest
		(rename (v1, ty1) v2 tm1) tm2)
Ë

The following simple list processing function is
needed:

È
	âcombineá : (* list)  (** list)  ((*  **) list)
É
	 hd1 hd2 tl1 tl2
	(combine [] [] = [])
	
	(combine (CONS hd1 tl1) (CONS hd2 tl2) =
			CONS (hd1, hd2) (combine tl1 tl2))
Ë

With the above preliminaries we can now define {\it inst}.
Note that the condition that the free variable lists of
the two terms have the same length is required to ensure
that $inst\_loc2$ examines each free variable of each
term.

È
	âinstá : ((string  TYPE)  bool) 
		(string  TYPE)  TERM  TERM
É
	((avoid : (string  TYPE)  bool))
	(tysubs :string  TYPE) (tm1 : TERM)
	let tm2 = inst avoid tysubs tm1
	in let fl1 = freevars_list tm1
	in let fl2 = freevars_list tm2
	in
		((length fl1 = length fl2)
		inst_loc2 avoid tysubs (combine fl1 fl2) tm1 tm2)
Ë

We need to detect the type variables in a term.
We use some auxiliary functions to
do this: $type\_tyvars$ detects the type variables in
a type.

È
	âtype_tyvarsá :  TYPE  (string  bool)
É
		(s:string  type_tyvars (mk_vartype s) = singleton_set s)
		(s tl type_tyvars (mk_type(s, tl)) =
			£ x x Å (map type_tyvars tl))
Ë
$term\_types$ detects the types in a term.
È
	âterm_typesá :  TERM  (TYPE  bool)
É
	 (tm : TERM) (s: string) (ty : TYPE)
	(f : TERM) (a : TERM) (v: TERM) (b: TERM)
	(has_mk_var(s, ty)tm  (term_types tm = singleton_set ty))
	
	(has_mk_const(s, ty)tm  (term_types tm = singleton_set ty))
	
	(has_mk_comb(f, a) tm  (term_types tm = term_types f ¡ term_types a))
	
	(has_mk_abs(v, b) tm  (term_types tm = term_types v ¡ term_types b))
Ë
$term\_tyvars$ detects all the type variables
in a term using the previous two functions.
È
	âterm_tyvarsá :  TERM  (string  bool)
É
	tm  term_tyvars tm = £(image type_tyvars (term_types tm))
Ë
$INST\_TYPE\_rule$ is now readily defined:
È
	âINST_TYPE_ruleá : (string  TYPE)  SEQ  SEQ  bool
É
	 tysubs old_asms old_conc new_seq
	INST_TYPE_rule tysubs (old_asms, old_conc) new_seq =
	( (tyv : string) 
		tyv  £ (image term_tyvars old_asms) 
		(tysubs tyv = mk_vartype tyv))
	
	(let asms_frees = £ (image freevars_set old_asms)
	in
		(new_seq = (old_asms, inst asms_frees tysubs old_conc)))
Ë


\subsection{Discharging an Assumption: DISCH}

{\it DISCH} is, in essence,
the usual rule of natural deduction
which allows one to infer from a proof of $\cal B$
on the assumption $\cal A$, that
${\cal A}  \cal B$ on no assumption.
The actual rule is suitably generalised to cover
sequents and their assumption sets. It is not
required that $\cal A$ be in the assumption set,
and the logic would probably not be complete
otherwise.

È
	âDISCH_ruleá : TERM  SEQ  SEQ  bool
É
	 tm old_asms old_conc new_seq 
	DISCH_rule tm (old_asms, old_conc) new_seq =
	(type_of_term tm = Bool) 
	(new_seq = (old_asms Ä singleton_set tm, thas_mk_imp(tm, old_conc)t))
Ë

\subsection{Modus Ponens: MP}

This is the usual rule: from ${\cal A}  {\cal B}$
and ${\cal A}$, infer ${\cal B}$.
This generalises to sequents by taking the union
of the assumption sets.
 
È
	âMP_ruleá : SEQ  SEQ  SEQ  bool
É
	 imp_asms imp_conc ant_asms ant_conc new_asms new_conc 
	MP_rule (imp_asms, imp_conc) (ant_asms, ant_conc) (new_asms, new_conc) =
	(has_mk_imp(ant_conc, new_conc)imp_conc) 
	(new_asms = imp_asms ¡ ant_asms)
Ë


\section{THE AXIOM SCHEMATA} \label{AXIOMSCHEMATA}


\subsection{The Axiom Schema ASSUME}

{\it ASSUME} allows us to infer
for any boolean term $\cal A$, that $\cal A$
holds on the assumptions $\{{\cal A}\}$.
This is straightforward to formalise. We must check
that the term being assumed is of the right type.
È
	âASSUME_axiomá : TERM  SEQ  bool
É
	 tm seq  ASSUME_axiom tm seq =
	(type_of_term tm = Bool)  
	(seq = (singleton_set tm, tm))
Ë

\subsection{The Axiom Schema REFL}
{\it REFL} says that for any term $\cal A$,
we may infer that ${\cal A} = {\cal A}$ without
assumptions.

È
	âREFL_axiomá : TERM  SEQ
É
	 tm  REFL_axiom tm = (¤, thas_mk_eq(tm, tm)t)
Ë

\subsection{The Axiom Schema BETA\_CONV}

{\it BETA\_CONV} says that, without any assumptions,
any $\beta$-redex is
equal to its $\beta$-reduction.
This is straightforward
to define, given the apparatus we used to define
{\it SUBST}.

È
	âBETA_CONV_axiomá : TERM  SEQ  bool
É
	 tm new_seq
	BETA_CONV_axiom tm new_seq =
	 v ty vty b abs a 
	has_mk_var(v, ty) vty 
	has_mk_abs(vty, b)abs 
	has_mk_comb(abs, a)tm 
	(new_seq = 
	let subs: ((string  TYPE)  TERM) =
		((vx, tyx)((vx = v)  (tyx = ty)) => a | thas_mk_var(vx, tyx)t)
	in
		(¤, (thas_mk_eq(tm, subst subs b)t)))
Ë


\section{DERIVABILITY} \label{DERIVABILITY}


In this section we will define derivability.
This is a relation between sets of sequents
and sequents. As usual, we first define direct
derivability.
We include instances of the axiom schemata as valid
direct derivations from no premisses. This is merely
for convenience, we could equally well include all
instances of the axiom schemata as axioms in every theory
when theories are defined.

È
	âdirectly_derivable_fromá : SEQ  (SEQ  bool)  bool
É
	 seq seqs 
	directly_derivable_from seq seqs = 
	( eqs tm old_seq 
	(image eqs (xT) ¥ seqs)  (old_seq  seqs)  SUBST_rule eqs tm old_seq seq)
	
	( vty old_seq  (old_seq  seqs)  ABS_rule vty old_seq seq)
	
	( tysubs old_seq  (old_seq  seqs)  INST_TYPE_rule tysubs old_seq seq)
	
	( tm old_seq  (old_seq  seqs)  DISCH_rule tm old_seq seq)
	
	( imp_seq ant_seq  (imp_seq  seqs)  (ant_seq  seqs)  MP_rule imp_seq ant_seq seq)
	
	( tm  ASSUME_axiom tm seq)
	
	( tm  seq = REFL_axiom tm)
	
	( tm  BETA_CONV_axiom tm seq)
Ë
We need the following utility:

È
	âelemsá :  (* list)  (*  bool)
É
	 e s  e  elems s  e Å s
Ë

Proofs will just be lists of sequents. Any non-empty
list is a valid proof (of the sequent at its
head) on the premisses given by those elements
of the list which are not directly derivable
from elements later in the list.
There is little point in making the relevant type
definition for a syntactic class of proofs in this sense,
since they contain so little information.
We simply define the function which extracts the set
of premisses.

È
	âpremissesá :  (SEQ list)  (SEQ  bool)
É
	 seq rest 
	(premisses [] = ¤)
	
	(premisses (CONS seq rest) =
		(directly_derivable_from seq (elems rest) => ¤ | singleton_set seq) ¡ premisses rest)
Ë


È
	âderivable_fromá : SEQ  (SEQ  bool)  bool
É
	 seq seqs 
	derivable_from seq seqs =
	 seql  premisses (CONS seq seql) ¥ seqs
Ë

\section{THEORIES} \label{THEORIES}

The following type definitions help us to
formalise the context-sensitive aspects of the
well-formedness of terms, which we have avoided until
now. Once this is done we can define the type of all
well-formed HOL theories.

å
new_type_abbrev(`âTY_ENVá`, ":string  num  bool");;

new_type_abbrev(`âCON_ENVá`, ":string  TYPE  bool");;

new_type_abbrev(`âSEQSá`, ":SEQ  bool");;
æ


We can now define the well-formedness of types and terms with
respect to a type environment. We assume that
the names for type variables and type constructors
are in distinct lexical classes, and so all we
check is the arity of constructors.
(This agrees with the HOL system, except that the HOL
system imposes additional lexical constraints on the
names).
 
È
	âwf_typeá : TYPE  TY_ENV  bool
É
	 ty tyenv 
	wf_type ty tyenv = 
	(s  ty = mk_vartype s)
	
	(s tyl  (tyenv s (length tyl))   t  t Å tyl  wf_type t tyenv)
Ë

For terms we place no restrictions on the names of
variables. (The HOL system tries to prevent constant
names being used as variable names but does not
always succeed, e.g, if the constant is declared after
a theorem using a variable with the same name has been
saved on a theory).

È
	âwf_termá: TERM  TY_ENV  CON_ENV  bool
É
	 s ty f a v b  tyenv conenv 
	let ok = tm wf_term tm tyenv conenv
	in
	 tm s ty f a v b 
	(has_mk_var(s, ty) tm  (ok tm = (wf_type ty tyenv)   t  (conenv s t)))
	(has_mk_const(s, ty) tm  (ok tm = 
		(wf_type ty tyenv) 
		( ty' tysubs (conenv s ty')  (inst_type tysubs ty' = ty))))
	(has_mk_comb(f, a) tm  (ok tm = (ok f)  (ok a)))
	(has_mk_abs(v, b) tm  (ok tm  = (ok v)  (ok b)))
Ë

The well-formedness of terms extends straightforwardly
to sequents and to sets thereof. We impose an
additional constraint for sequents: they must be
made up from terms of type \Bool.

È
	âwf_seqá: SEQ  TY_ENV  CON_ENV  bool
É
	 seq tyenv conenv
	let ok = tm (wf_term tm tyenv conenv)  (type_of_term tm = Bool)
	in 
	(wf_seq seq tyenv conenv =
	((ok (concl seq))  (tm (tm  (hyp seq))  (ok tm))))
Ë

È
	âwf_seqsá: SEQS  TY_ENV  CON_ENV  bool
É
	 seqs tyenv conenv
	wf_seqs seqs tyenv conenv =  seq  (seq  seqs)  (wf_seq seq tyenv conenv)
Ë

For the constant environments, we insist that the
type associated with each name be well-formed and
that at most one type is associated with each name.
Overloaded constant names could, in principle, be allowed,
as an extension to the system. This function would then be
modified to impose some weaker condition.

È
	âwf_con_envá: CON_ENV  TY_ENV  bool
É
	 conenv tyenv
	wf_con_env conenv tyenv =
	( con ty (conenv con ty)  (wf_type ty tyenv)) 
	( con ty1 ty2  (conenv con ty1)  (conenv con ty2)  (ty1 = ty2))
Ë

We insist that at most one arity be associated with
each name in a well-formed type environment:

È
	âwf_ty_envá: TY_ENV  bool
É
	 tyenv
	wf_ty_env tyenv =
	 ty n1 n2  (tyenv ty n1)  (tyenv ty n2)  (n1 = n2)
Ë

We can now define the type of all theories whose
components are well-formed. We will then take the subtype
of this consisting of all theories which extend the
minimal one (with just the constants for equality
and implication and the type of propositions).

Note that a theory can contain infinitely many
types, constants, axioms or theorems. This possibility
occurs in practice, at least for constants and axioms.
The theory  of natural numbers is an example, since
it contains an axiom defining the decimal representation
of each positive number. 

ÇÍ`âFTHEORYá``T`ÍÍÍÍÍÍÍÍÍÍß
	ty_env		:TY_ENV,
	con_env	:CON_ENV,
	axioms		:SEQS,
	theorems	:SEQS
ÉÍÍÍÍÍÍÍÍÍÍÍÍ
	(wf_ty_env ty_env) 
	(wf_con_env con_env ty_env) 
	(wf_seqs axioms ty_env con_env) 
	(wf_seqs theorems ty_env con_env) 
	(theorems ¥ seqderivable_from seq axioms)
ÊÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍà

The above introduces a new type S which may be
viewed as the labelled product of the types
$TY\_ENV$, $CON\_ENV$ etc.
New constants $T\_ty\_env$, $T\_con\_env$ are
also introduced. These are the projection functions
for the produce.

È
	âStará : TYPE
É
	Star = mk_vartype `*`
Ë

$MIN$ will be the minimal theory. It contains only
what is needed to define the inference rules.
Its representative in $FTHEORY$ is called
$FMIN$.
È
	âFMINá : FTHEORY
É
	(	FMIN.T_ty_env = ty n 
		(	(ty = FST(dest_type Bool)) 
			(n  = length(SND(dest_type Bool)))
		)  (	(ty = FST(dest_type(Fun Bool Bool))) 
			(n  = length(SND(dest_type(Fun Bool Bool))))
		)
	)  (	FMIN.T_con_env = s ty
			(has_mk_const(s, ty)(Equality Star)) 
			(has_mk_const(s, ty)Implication)
	)  (	FMIN.T_axioms = ¤
	)  (	FMIN.T_theorems = ¤
	)
Ë

Extension for objects of type {\it FTHEORY} is
the following binary relation:

ç
	fextends : FTHEORY  FTHEORY  bool
É
	 thy1 thy2
	fextends thy1 thy2 =
	(UNCURRY(thy2.T_ty_env) ¥ UNCURRY(thy1.T_ty_env)) 
	(UNCURRY(thy2.T_con_env) ¥ UNCURRY(thy1.T_con_env)) 
	((thy2.T_axioms) ¥ (thy1.T_axioms))  
	((thy2.T_theorems) ¥ (thy1.T_theorems))
Ë

We restrict attention to theories which extend the
minimal theory {\it MIN}. Note that we do not
exclude inconsistent theories here. (This corresponds
to the possibility of introducing inconsistent axioms
in the HOL system).

å
	sim_type_def `âTHEORYá`
	"(fthy : FTHEORY), (fthy fextends FMIN)";;
æ

The definitions for the theory {\it MIN} and extension
of theories are derived from the
corresponding definitions for the representation type
{\it FTHEORY}.

È
	âMINá : THEORY
É
	MIN = ABS_THEORY FMIN
Ë
ç
	âextendsá : THEORY  THEORY  bool
É
	 thy1 thy2
	extends (ABS_THEORY thy1) (ABS_THEORY thy2) =
	thy1 fextends thy2
Ë
The following functions on theories are useful in 
later definitions.
Note that {\it theorems} just gives the theorems
component of a theory. It does not return all the
consequences of the axioms of a theory.

È
	âaxiomsá : THEORY  SEQS
É
	 thy  axioms (ABS_THEORY thy) = (thy.T_axioms)
Ë
È
	âtypesá : THEORY  TY_ENV
É
	 thy  types (ABS_THEORY thy) = (thy.T_ty_env)
Ë
È
	âconstantsá : THEORY  CON_ENV
É
	 thy  constants (ABS_THEORY thy) = (thy.T_con_env)
Ë
È
	âtheoremsá : THEORY  SEQS
É
	 thy  theorems (ABS_THEORY thy) = (thy.T_theorems)
Ë

È
	âsequentsá : THEORY  SEQS
É
	 seq fthy 
		(seq  sequents (ABS_THEORY fthy)) 
		(wf_seq seq (fthy.T_ty_env) (fthy.T_con_env))
	
Ë

\section{THEOREMS, CONSISTENCY AND CONSERVATIVE EXTENSIONS}
\label{CONSISTENCY}

We can, at last, define the type of all HOL theorems.
A theorem will consist of a sequent and a theory.
The type is the subtype of the type of all such  pairs
in which the sequent is well-formed with respect to the
type and constant environments of the theory and in which
the sequent may be derived from the axioms of the theory.

ÇÍ`âTHMá``thm`ÍÍÍÍÍÍÍÍÍÍß
	seq	: SEQ,
	thy	: THEORY
ÉÍÍÍÍÍÍÍÍÍÍÍÍ
	(seq  sequents thy)
	
	(derivable_from seq ((REP_THEORY thy).T_axioms))
ÊÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍà

(The projection functions for the above
type are called $thm\_seq$ and $thm\_thy$.)


A theory is consistent if not every sequent which
is well-formed in it can be derived from the axioms:

È
	âconsistent_theoryá : THEORY  bool
É
	 thy 
	consistent_theory thy =
	 seq 
	(seq  sequents thy)
	
	(derivable_from seq (axioms thy))
Ë
An extension of a theory is conservative if no sequent
of the smaller theory is provable in the larger but not
in the smaller.
ç
	âconservatively_extendsá : THEORY  THEORY  bool
É
	 thy1 thy2
	conservatively_extends thy1 thy2 =
	(thy1 extends thy2) 
	( seq 
	(seq  sequents thy2) 
	(derivable_from seq (axioms thy1)) 
	(derivable_from seq (axioms thy2)))
	
Ë


\section{THE RULES OF INFERENCE REVISITED} \label{RULESOFINFERENCEREVISITED}

Given our type of theorems, we can now define
the inference rules as relations between theorems, rather
than sequences.  Essentially, we say that
if, by rule {\bf X}{\it\_rule}, we may infer the sequent $S$
from $S_1, S_2, \ldots$, then, by {\bf X}, we
may infer $(S, T)$ from
$(S_1, T_1), (S_2, T_2), \ldots$ provided
the theory $T$ is an extension of each $T_i$.

Proof theoretically this is no different from
a rule which insists that $T_i = T$ for all $i$.
The more general formulation is meant to accord a 
little better with the thinking of the user of the
proof development system and may allow more freedom
in an implementation. An implementation need
not exploit the full generality.
For example, in the current HOL proof development system
all proofs are, I believe, conducted in the context
of a particular theory called the {\it current} theory.
Thus the abstract data type representing theorems
does not need a theory component and the current theory
is, effectively, an implicit and unused parameter to
the constructor functions of the abstract data type.

The definitions of the inference rules for theorems
are derived directly and tediously from the corresponding
rules for sequences. In each case, we simply change
the sequent arguments to theorem arguments, and check
that the corresponding rule for sequents holds for
the sequent components of the theorems and that the
theory component of the theorem inferred extends that
of all the other theorem arguments.

È
	âSUBSTá : ((string  TYPE)  THM) 
			TERM  THM  THM  bool
É
	 eqs tm old_thm new_thm 
	SUBST eqs tm old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(SUBST_rule (thm_seq o eqs) tm old_seq new_seq
	
	(new_thy extends old_thy) 
	(image (thm_thy o eqs)(xT) ¥ $extends new_thy))
Ë
È
	âABSá : (string  TYPE)  THM  THM  bool
É
	 vty old_thm new_thm 
	ABS vty old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(ABS_rule vty old_seq new_seq 
	(new_thy extends old_thy)) 
Ë
È
	âINST_TYPEá : (string  TYPE)  THM  THM  bool
É
	 tysubs old_thm new_thm 
	INST_TYPE tysubs old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(INST_TYPE_rule tysubs old_seq new_seq 
	(new_thy extends old_thy)) 
Ë
È
	âDISCHá : TERM  THM  THM  bool
É
	 tm old_thm new_thm 
	DISCH tm old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(DISCH_rule tm old_seq new_seq 
	(new_thy extends old_thy))
Ë
È
	âMPá : THM  THM  THM  bool
É
	 imp_thm ant_thm new_thm 
	MP imp_thm ant_thm new_thm =
	let imp_seq = thm_seq imp_thm in let imp_thy = thm_thy imp_thm
	in let ant_seq = thm_seq ant_thm in let ant_thy = thm_thy ant_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(MP_rule imp_seq ant_seq new_seq 
	(new_thy extends imp_thy)  (new_thy extends ant_thy))
Ë
The axiom schemata for theorems are even more straightforward
to define, since they hold in every theory. 
È
	âASSUMEá : TERM  THM  bool
É
	 tm thm  ASSUME tm thm = ASSUME_axiom tm (thm_seq thm)
Ë
È
	âREFLá : TERM  THM  bool
É
	 tm thm  REFL tm thm = ((thm_seq thm) = REFL_axiom tm)
Ë
È
	âBETA_CONVá : TERM  THM  bool
É
	 tm thm  BETA_CONV tm thm = BETA_CONV_axiom tm (thm_seq thm)
Ë

\section{DEFINITIONAL EXTENSIONS} \label{DEFINITIONS}

\subsection{More Object Language Constructs}

A theory {\it LOG}
in which more of the standard logical apparatus is
available will be needed to define some of the definitional
extension mechanisms.

For example, {\it new\_type\_definition}
works with a theorem whose conclusion must be an
existentially quantified term of a particular form.
To define {\it LOG} we need some more object language
types and terms and these are defined in this section.
(It is convenient to leave the definition of {\it LOG}
itself until we have defined {\it new\_definition}.)

The formulation of the various logical connectives
follows the draft manual.

It is helpful now to
have the following term constructor functions.
Note that we are now using total functions to
approximate partial ones; we must, therefore, be
careful only to apply them to appropriate arguments.

È
	âmk_vará : string  TYPE  TERM
É
	mk_var = $ o has_mk_var 
Ë
È
	âmk_constá : string  TYPE  TERM
É
	mk_const = $ o has_mk_const 
Ë
È
	âmk_combá : TERM  TERM  TERM
É
	mk_comb = $ o has_mk_comb 
Ë
È
	âmk_absá : TERM  TERM  TERM
É
	mk_abs = $ o has_mk_abs 
Ë
È
	âmk_eqá : TERM  TERM  TERM
É
	mk_eq = $ o has_mk_eq 
Ë
È
	âmk_impá : TERM  TERM  TERM
É
	mk_imp = $ o has_mk_imp 
Ë

We can now define the object language constructs needed.

% The following ML fragments are useful for checking %
% these definitions - they enable one to execute bits %
% of the HOL as ML and so see the terms pretty-printed%
% Note that this is a LaTeX and an ML comment. %
% The lines below are LaTeX comments %
% and each one starts with an ML comment! %
%% let Fun a b = mk_type(`fun`,[a; b]);;
%% let Bool = ":bool";; 
%% let Star = ":*";; let StarStar = ":**";;
\subsubsection{Truth}
The constant $T : bool$ is defined by the following equation:
$$T = (((x:bool)  x) = ((x:bool)  x))$$

È
	âTruthá : TERM
É
	Truth = mk_const(`T`, Bool)
Ë
È
	âTruth_defá : TERM
É
	Truth_def = 
	let x = mk_var(`x`, Bool)
	in
	mk_eq(mk_abs(x, x), mk_abs(x, x))
Ë
\subsubsection{Universal Quantification}
The constant $ : (*  bool)  bool$ is defined by
the following equation:
$$\$ = ((P : *  bool)  P = ((x:*)  T)$$

È
	âForallá : TYPE  TERM
É
	 tyForall ty = mk_const(``, Fun (Fun ty Bool) Bool)
Ë
È
	âForall_defá : TERM
É
	Forall_def =
	let P = mk_var(`P`, Fun Star Bool)
	in let x = mk_var(`x`, Star)
	in
	mk_abs(P, mk_eq(P, mk_abs(x,  Truth)))
Ë
È
	âmk_forallá : (TERM  TERM)  TERM
É
	 tm1 tm2mk_forall(tm1, tm2) = 	mk_comb(Forall (type_of_term tm1), mk_abs(tm1, tm2))
Ë
\subsubsection{Existential Quantification}
The constant $ : (*  bool)  bool$ is defined
by the following equation, which defines $$ in terms
of the choice function $: (*  bool) *$:
$$\$ = (P : *  bool)  P(P)$$
(This may be a little perplexing at first sight.
In the intended interpretations, given a predicate
$P : *  bool$, if there is some $x : *$ for which $P$
is true (i.e. for which $P x = T$), then $ P$ is such
an $x$. I.e. taking as known the intuitive notion of
``whether or not something with a given property exists'',
$$ chooses
something with a given property if such a thing exists.
The above definition can be viewed as taking as known
the informal notion of ``choosing something with a given
property'' and defining $$ to determine
whether or not something with a given property exists
by attempting to choose something with the given property and checking whether the attempt succeeded.)
È
	âChoiceá : TERM
É
	Choice = mk_const(``, Fun (Fun Star Bool) Star)
Ë
È
	âExistsá : TYPE  TERM
É
	 ty  Exists ty = mk_const(``, Fun (Fun ty Bool) Bool)
Ë

È
	âExists_defá : TERM
É
	Exists_def = 
	let P = mk_var(`P`, Fun Star Bool)
	in let PchoiceP = mk_comb(P,mk_comb(Choice, P))
	in
	mk_abs(P, PchoiceP)
Ë
È
	âhas_mk_existsá : (TERM  TERM)  TERM  bool
É
	 tm1 tm2 tm3 
	has_mk_exists(tm1, tm2) tm3 =
	has_mk_comb(Exists (type_of_term tm1), mk_abs(tm1, tm2))tm3
Ë
È
	âmk_existsá : (TERM  TERM)  TERM
É
	 tm1 tm2mk_exists(tm1, tm2) = 	mk_comb(Exists (type_of_term tm1), mk_abs(tm1, tm2))
Ë
\subsubsection{Falsity}
The constant $F:bool$ is defined by the following equation:
$$F = (x:bool)  x$$
(Again this may seem perplexing. The type $bool$
is intended to contain the truth values. The above definition
says that false is the truth value of the proposition that
every truth value is true!)
È
	âFalsityá : TERM
É
	Falsity = mk_const(`F`, Bool)
Ë
È
	âFalsity_defá : TERM
É
	Falsity_def =
	let x = mk_var(`x`, Bool)
	in
	mk_forall(x, x)
Ë
\subsubsection{Negation}
The constant $:bool  bool$ is defined by the following
equation:
$$\$ = (b:bool)b  F$$
È
	âNegationá : TERM
É
	Negation = mk_const(``, Fun Bool Bool)
Ë
È
	âNegation_defá : TERM
É
	Negation_def =
	let b = mk_var(`b`, Bool)
	in
	mk_abs(b, mk_imp(b, Falsity))
Ë
\subsubsection{Conjunction}
The constant $: bool  bool  bool$
is defined by the following equation:
$$\$ = b1b2b(b1  (b2  b))  b$$
(I assume, but do not know, that the above formulation
has some practical advantage in the present
context over the more obvious definition
in terms of $$ and $$.)

The name of the constant is a slash, $/$, followed by a
backslash, $\backslash$. The backslash character
must be escaped by another backslash character within
an HOL string.
È
	âConjunctioná : TERM
É
	Conjunction = mk_const(`/\\`, Fun Bool (Fun Bool Bool))
Ë
È
	âConjunction_defá : TERM
É
	Conjunction_def =
	let b = mk_var(`b`, Bool)
	in let b1 = mk_var(`b1`, Bool)
	in let b2 = mk_var(`b2`, Bool)
	in
	mk_abs(b1, mk_abs(b2, mk_forall(b, mk_imp(mk_imp(b1, mk_imp(b2, b)), b))))
Ë
A derived constructor function for conjunctions is
useful.
È
	âmk_conjá : (TERM  TERM)  TERM
É
	 tm1 tm2
	mk_conj(tm1, tm2) = mk_comb(mk_comb(Conjunction, tm1),tm2)
Ë

\subsubsection{Disjunction}
The constant $: bool  bool  bool$
is defined by the following equation:
$$\$ = b1b2b((b1  b)  (b2  b))  b$$
(As for conjunction I assume this has some advantage
over a definition from the propositional calculus.)

The name of the constant is a
backslash, $\backslash$, followed by a slash, $/$.
The backslash character
must be escaped by another backslash character within
an HOL string.

È
	âDisjunctioná : TERM
É
	Disjunction = mk_const(`\\/`, Fun Bool (Fun Bool Bool))
Ë
È
	âDisjunction_defá : TERM
É
	Disjunction_def =
	let b = mk_var(`b`, Bool)
	in let b1 = mk_var(`b1`, Bool)
	in let b2 = mk_var(`b2`, Bool)
	in
	mk_abs(b1, mk_abs(b2, mk_forall(b, mk_imp(mk_imp(b1, b), mk_imp(mk_imp(b2, b), b)))))
Ë
A derived constructor function for disjunctions is
useful later.
È
	âmk_disjá : (TERM  TERM)  TERM
É
	 tm1 tm2
	mk_disj(tm1, tm2) = mk_comb(mk_comb(Disjunction, tm1),tm2)
Ë

\subsubsection{ONE\_ONE}
The definition of $Type\_Definition$ below requires the notion of
a one-to-one function. The constant $ONE\_ONE$
is defined by the following equation:
$$ONE\_ONE = (f:*  **)(x1:*)(x2:*)(f\,x1 = f\,x2)  (x1 = x2)$$
È
	âStarStará : TYPE
É
	StarStar = mk_vartype `**`
Ë
È
	âOne_Oneá : TERM
É
	One_One = mk_const(`ONE_ONE`, Fun(Fun Star StarStar)Bool)
Ë
È
	âOne_One_defá : TERM
É
	One_One_def = 
	let f = mk_var(`f`,Fun Star StarStar)
	in let x1 = mk_var(`x1`,Star)
	in let x2 = mk_var(`x2`,Star) in
	mk_abs(f, mk_forall(x1, mk_forall(x2,
		mk_imp(mk_eq(mk_comb(f, x1), mk_comb(f, x2)),
			mk_eq(x1, x2)))))
Ë
\subsubsection{ONTO}
The axiom of infinity requires the notion of
an onto function. The constant $ONTO$
is defined by the following equation:
$$ONTO = (f:*  **)(y:**)(x:*)y = f\,x$$
È
	âOntoá : TERM
É
	Onto = mk_const(`ONTO`, Fun(Fun Star StarStar)Bool)
Ë
È
	âOnto_defá : TERM
É
	Onto_def =
	let f = mk_var(`f`,Fun Star StarStar)
	in let x = mk_var(`x`,Star)
	in let y = mk_var(`y`,StarStar) in
	mk_abs(f, mk_forall(y, mk_exists(x, mk_eq(y, mk_comb(f, x)))))
Ë
\subsubsection{Type\_Definition}

{\it Type\_Definition} may be new to some readers.
It is a term asserting that a function  represents
one type as a subtype of another. It is used
in defining {\it new\_type\_definition}.
It has type $(**bool)(***)bool$ and
is defined by the following equation:
\begin{eqnarray*}
Type\_Definition = &(P:**bool)(rep:***)&ONE\_ONE\,rep \\
	&& (x:**)P\,x = (y:*)x = rep\,y
\end{eqnarray*}

It is useful later to have a version of {\it Type\_Definition}
parameterised over the types involved.
È
	âType_Definitioná : TYPE  TYPE  TERM
É
	 ty1 ty2 
	Type_Definition ty1 ty2 = mk_const(`Type_Definition`, (Fun (Fun ty2 Bool) (Fun(Fun ty1 ty2)Bool)))
Ë
È
	âType_Definition_defá : TERM
É
	Type_Definition_def = 
	let P = mk_var(`P`,Fun StarStar Bool)
	in let rep = mk_var(`rep`,Fun Star StarStar)
	in let x = mk_var(`x`,StarStar)
	in let y = mk_var(`y`,Star) in
	mk_abs(P, mk_abs(rep,
		mk_conj(mk_comb(One_One, rep),
			mk_forall(x, mk_eq(mk_comb(P, x), mk_exists(y, mk_eq(x, mk_comb(rep, y))))))))
Ë

\subsection{{\it new\_type} and {\it new\_constant}}

The first two definitional extension mechanisms,
{\it new\_type} and {\it new\_constant} are
conservative, but not very powerful.

{\it new\_type}  is used to declare a name to be used
as a type constructor. No axioms about the type are
introduced so that only instances of polymorphic
functions may be applied to it.
The only constraint is that the name should not
be a type constructor in the theory to be extended.

È
	ânew_typeá :   string  THEORY  THEORY  bool
É
	 arity name thy1 thy2 
	new_type arity name thy1 thy2 =
	( n   (types thy1 name n)) 
	( s n  types thy2 s n = ((s = name)  (n = arity))  (types thy1 s n)) 
	(constants thy2 = constants thy1) 
	(axioms thy2 = axioms thy1) 
	(theorems thy2 = theorems thy1)
Ë
{\it new\_constant}  is used to declare a name to be used
as a constant of a given type.
No axioms about the constant are
introduced so that it behaves as a value
which we cannot determine.
The only constraint is that the name should not
be a constant in the theory to be extended.

È
	ânew_constantá : string  TYPE  THEORY  THEORY  bool
É
	 name type thy1 thy2 
	new_constant name type thy1 thy2 =
	( ty   (constants thy1 name ty)) 
	( s ty  constants thy2 s ty = ((s = name)  (ty = type))  (constants thy1 s ty)) 
	(types thy2 = types thy1) 
	(axioms thy2 = axioms thy1) 
	(theorems thy2 = theorems thy1)

Ë

\subsection{{\it new\_axiom}}

{\it new\_axiom} is both powerful and dangerous!
It allows a sequent with no hypotheses and a
given conclusion to be taken as an axiom.
The only constraint is that the sequent be well-formed
with respect to the environments of the theory being
extended.

È
	ânew_axiomá : TERM  THEORY  THEORY  bool
É
	 tm thy1 thy2 
	new_axiom tm thy1 thy2 =
	let seq = (¤, tm)
	in
	((seq  sequents thy1) 
	(types thy2 = types thy1) 
	(constants thy2 = constants thy1) 
	(axioms thy2 = axioms thy1 ¡ singleton_set seq) 
	(theorems thy2 = theorems thy1))

Ë
\subsection{{\it new\_definition}}
{\it new\_definition} is useful and conservative.
It allows the simultaneous introduction of a new constant
and an axiom asserting that the new constant is equal
to a given term.
The constraints imposed are {\it (a)} the name must satisfy the
check made in {\it new\_constant}, {\it (b)} the term
must be closed and {\it (c)} the term must contain
no bound variables whose types contain type variables
which do not appear in the type of the new constant.
Condition {\it (c)} ensures that different type instances
of the term result in different instances of the
constant; this avoids a possible inconsistency.
È
	ânew_definitioná : string  TERM  THEORY  THEORY  bool
É
	 name tm thy1 thy2 
	new_definition name tm thy1 thy2 =
	let ty = type_of_term tm
	in 
	 thy1a 
	(new_constant name ty thy1 thy1a) 
	(freevars_set tm = ¤) 
	(term_tyvars tm ¥ type_tyvars ty) 
	(new_axiom (mk_eq(mk_const(name, ty), tm)) thy1a thy2)
Ë


\subsection{{\it new\_specification}}

{\it new\_specification} allows the simultaneous
introduction of a set of new constants satisfying a
given predicate provided that a theorem asserting
the existence of some set of values satisfying the
constants is given. An axiom asserting the predicate
for the new constants is introduced.
Like {\it new\_definition}, {\it new\_specification}
is useful and conservative.

The constraints imposed are analogous to those imposed
in {\it new\_definition}: {\it (a)} the constant
names must be pairwise distinct and different from
any constant name in the theory being extended,
{\it (b)} the predicate must have
no free variables apart from those corresponding
to the new constants, {\it (c)} any type variable
contained in a bound variable of the predicate must
appear as a type variable of each of the new constants.
Also, of course, the theorem must have the right form.

Since we now need to work with existential quantifiers
it is necessary to introduce the theory {\it LOG}.
We impose the restriction that {\it new\_specification}
may only be used  to extend theories which extend {\it LOG}.
È
	âLOGá : THEORY
É
	 thy1 thy2 thy3 thy4 thy5 thy6 thy7 thy8 thy9
	let Name = constyhas_mk_const(s, ty)con
	in
	(new_definition (Name Truth) Truth_def MIN thy1
	new_definition (Name (Forall Star)) Forall_def thy1 thy2
	new_definition (Name (Exists Star)) Exists_def thy2 thy3
	new_definition (Name Falsity) Falsity_def thy3 thy4
	new_definition (Name Negation) Negation_def thy4 thy5
	new_definition (Name Conjunction) Conjunction_def thy5 thy6
	new_definition (Name Disjunction) Disjunction_def thy6 thy7
	new_definition (Name One_One) One_One_def thy7 thy8
	new_definition (Name Onto) Onto_def thy8 thy9
	new_definition (Name (Type_Definition Star StarStar)) Type_Definition_def thy9 LOG)
Ë

To define {\it new\_specification} we need a list
processing utility ,{\it split}, the relation
{\it has\_list\_mk\_exists}, and the relation {\it new\_constants}
which is like {\it new\_constant} but handles a
set of new constants.

È
	âsplitá : ((*  **) list)  (* list  ** list)
É
	(split [] = ([], []))
	
	( FSThd SNDhd rest 
	split (CONS(FSThd, SNDhd)rest) =
		let splitrest = split rest
		in
		(CONS FSThd (FST splitrest), CONS SNDhd (SND splitrest)))
Ë
È
	âhas_list_mk_existsá : (TERM list)  TERM  TERM  bool
É
	(tm1 tm2 has_list_mk_exists [] tm1 tm2 = (tm1 = tm2))
	
	( v rest tm1 tm2  
	has_list_mk_exists (CONS v rest) tm1 tm2 =
	 rem  has_mk_exists(v, rem) tm2 
		has_list_mk_exists rest rem tm1)
	
Ë

È
	ânew_constantsá : ((string  TYPE)  bool)  THEORY  THEORY  bool
É
	 cons thy1 thy2 
	new_constants cons thy1 thy2 =
	( s ty1 ty2  ((s, ty1)  cons)  (constants thy1 s ty2)) 
	( s ty  constants thy2 s ty = ((s, ty)  cons)  constants thy1 s ty) 
	(types thy2 = types thy1) 
	(axioms thy2 = axioms thy1) 
	(theorems thy2 = theorems thy1)

Ë

We can now define {\it new\_specification}.
We use the cardinality function $card$ here to help
in asserting that certain lists contain no repeats.
È
	ânew_specificationá : ((string  (string  TYPE)) list) 
	TERM  THM  THEORY  THEORY  bool
É
	 pairs tm thm thy1 thy2 
	new_specification pairs tm thm thy1 thy2 =
	let conl = FST(split pairs)
	in let varl = map mk_var (SND(split pairs))
	in let tyl = map SND (SND(split pairs))
	in let subs = (s, ty) 
		( c  (c, (s, ty)) Å pairs)
		 =>	mk_const((c(c, (s, ty)) Å pairs), ty)
		| 	mk_var(s, ty)
	in let axiom = subst subs tm
	in ( conc
	(has_list_mk_exists varl tm conc)
	 (thy1 extends LOG)
	
	(freevars_set conc = ¤)
	
	(card (elems conl) = length varl)  (card(elems varl) = length varl)
	
	(thm_seq thm = (¤, conc))  (thy1 extends thm_thy thm)
	
	( ty (ty Å tyl)  (term_tyvars conc ¥ type_tyvars ty))
	
	( thy1a 
	new_constants (elems (combine conl tyl)) thy1 thy1a 
	new_axiom axiom thy1a thy2) )
Ë

\subsection{{\it new\_type\_definition}}
{\it new\_type\_definition} allows the introduction
of a new type in one-to-one correspondence with
the subset of an existing type satisfying a given
predicate, given a theorem asserting that the subset
is not empty. A new axiom asserting the existence
of a representation function for the new type is introduced.
Like {\it new\_definition}, {\it new\_type\_definition}
is useful and conservative.

For simplicity, we have made the list of type variable
names to be used as the parameters of the type being
defined, a parameter to {\it new\_type}.
The constraints imposed are {\it (a)} that the list
of type parameter names contain
no repeats, {\it (b)} the theorem must have the right form
and {\it (c)} all type variables contained in the
predicate must be contained in the list of type parameters
names.
Condition {\it (c)} ensures that different type instances
of the new axiom involve different type instances of
the new type.

È
	ânew_type_definitioná : string  (string list)  THM  THEORY  THEORY  bool
É
	 name typars thm thy1 thy2 
	new_type_definition name typars thm thy1 thy2=
	 p xty x ty px thy1a axiom newty 
	let f = mk_var(`f`, Fun newty ty)
	in let newty = mk_type(name, map mk_vartype typars)
	in (
	(thy1 extends LOG)
	
	(hyp (thm_seq thm) = ¤) 
	has_mk_exists (xty, px) (concl (thm_seq thm)) 
	has_mk_var (x, ty) xty 
	has_mk_comb (p, xty) px
	
	(freevars_set p = ¤) 
	(term_tyvars p ¥ elems typars)
	
	(length typars = card(elems typars))
	
	has_mk_exists(f, mk_comb(mk_comb(Type_Definition newty ty, p), f)) axiom
	
	(new_type (length typars) name thy1 thy1a) 
	(new_axiom axiom thy1a thy2) )
Ë
\section{The theory INIT}
\label{INIT}
By extending the theory $LOG$ with five axioms
we will arrive at the theory $INIT$. In a typical
HOL proof development system all theories will be
extensions of this theory. 


\subsection{The Axioms}
\subsubsection{BOOL\_CASES\_AX}
This is the law of the excluded middle:
\begin{eqnarray*}
BOOL\_CASES\_AX&&(b : bool)(b = T)\;\;(b = F)
\end{eqnarray*}
È
	âBOOL_CASES_AXá : TERM
É
	BOOL_CASES_AX =
	let b = mk_var(`b`, Bool)
	in mk_forall(b, mk_disj(mk_eq(b, Truth), mk_eq(b, Falsity)))
Ë

\subsubsection{IMP\_ANTISYM\_AX}

This says that implication is an antisymmetric
relation:
\begin{eqnarray*}
IMP\_ANTISYM\_AX&&
(b1:bool)(b2:bool)(b1\,\,b2)\,\,(b2\,\,b1)\,\,(b1=b2)
\end{eqnarray*}
È
	âIMP_ANTISYM_AXá : TERM
É
	IMP_ANTISYM_AX =
	let b1 = mk_var(`b1`, Bool)
	in let b2 = mk_var(`b2`, Bool)
	in mk_forall(b1, mk_forall(b2,
		mk_imp(mk_imp(mk_imp(b1, b2), mk_imp(b2, b1)), mk_eq(b1, b2))))
Ë

\subsubsection{ETA\_AX}
This says that an $\eta$-redex is equal to
its $\eta$-reduction.
\begin{eqnarray*}
ETA\_AX&&(f: *  **)((x:*)f\,x) = f
\end{eqnarray*}
È
	âETA_AXá : TERM
É
	ETA_AX =
	let f = mk_var(`f1`, Fun Star StarStar)
	in let x = mk_var(`x`, Star)
	in mk_forall(f, mk_eq(mk_abs(x, mk_comb(f, x)), f))
Ë
\subsubsection{SELECT\_AX}
This is the defining property of the choice function $$.
\begin{eqnarray*}
SELECT\_AX&&(P:*bool)(x:*)P\,x\;\;P( P)
\end{eqnarray*}
È
	âSELECT_AXá : TERM
É
	SELECT_AX =
	let P = mk_var(`P`, Fun Star Bool)
	in let x = mk_var(`x`, Star)
	in mk_forall(P,mk_forall(x, mk_imp(mk_comb(P, x), mk_comb(P, mk_comb(Choice, P)))))
Ë
\subsubsection{INFINITY\_AX}
This is the axiom of infinity. It asserts that the
type $ind$ is in one-to-one correspondence with
a proper subset of itself:
\begin{eqnarray*}
INFINITY\_AX&&(f:indind)ONE\_ONE\,f\;\;ONTO\,f
\end{eqnarray*}
We need first to define the new type $ind$:
È
	âIndá : TYPE
É
	Ind = mk_type(`Ind`, [])
Ë
È
	âINFINITY_AXá : TERM
É
	INFINITY_AX =
	let f = mk_var(`f`, Fun Ind Ind)
	in mk_conj(mk_comb(One_One, f), mk_comb(Negation, mk_comb(Onto, f)))
Ë

\subsection{The Theory INIT}
È
	âINITá : THEORY
É
	 thy1 thy2 thy3 thy4 thy5 thy6 
	new_axiom BOOL_CASES_AX LOG thy1
	new_axiom IMP_ANTISYM_AX thy1 thy2
	new_axiom ETA_AX thy2 thy3
	new_axiom SELECT_AX thy4 thy5
	new_type 0 (FST(dest_type Ind)) thy5 thy6
	new_axiom INFINITY_AX thy6 INIT
Ë


\section{The Type STANDARD\_THEORY} \label{STANDARD}

Of particular importance are theories which
may be obtained from $INIT$ by the {\em conservative}
extension mechanisms defined in section \ref{DEFINITIONS}
above.
These theories are of interest since, we
assert, they form a sound formalism
in which much of the practical machine-checked
proof work one might wish to do can be carried out.
We define this set of theories as a subtype,
$STANDARD\_THEORY$ of $THEORY$.

\subsection{Relations}

We need some generalities about relations.
First the standard notion of antisymmetry:


È
	âantisymmetricá : (*  *  bool)  bool
É
	 R  antisymmetric R =  x y  (R x y)  (R y x)  (x = y)
Ë

Next domain and codomain:

È
	âdomainá : (*  **  bool)  (*  bool)
É
	 R x  (x  domain R)   y R x y
Ë

È
	âcodomainá : (*  **  bool)  (**  bool)
É
	 R x  (x  codomain R)   y R y x
Ë
The {\it field}
of a relation is the union of its domain and codomain.

È
	âfieldá : (*  *  bool)  (*  bool)
É
	 R  field R = domain R ¡ codomain R
Ë

We need the notion of a path between two elements in a
relation. 
 
È
	âpathá : (* list)  (*  *  bool)  *  *  bool
É
	 l R x y 
	path l R x y  
	( (l = [x; y])  R x y ) 
	( x1 rest  (l = CONS x (CONS x1 rest))  R x x1  path rest R x1 y)
Ë
Using {\it path} we can define the ancestral of a relation:
 
È
	âancestralá : (*  *  bool)  *  *  bool
É
	 R x y 
	ancestral R x y  l  path l R x y
Ë

\subsection{STANDARD\_THEORY}

If a theory $thy1$ extends a theory $thy2$, let
us say the extension is
{\em by proof} if the theories only differ in
their theorems component:
È
	âextends_by_proofá : THEORY  THEORY  bool
É
	thy1 thy2
	extends_by_proof thy1 thy2 = 
		(theorems thy2 ¥ theorems thy1)
		(types thy2 = types thy1)
		(constants thy2 = constants thy1)
		(axioms thy2 = axioms thy1)
Ë
We will say that a theory $thy1$ is a $standard$ extension
of a theory $thy2$ if one may go from $thy2$ to $thy1$ by
some sequence of
extensions either by proof or by the functions 
$new\_type$, $new\_constant$, $new\_definition$,
$new\_specification$ and $new\_type\_definition$:

È
	âstandard_extensioná : THEORY  THEORY  bool
É
	let one_step =
		(thy1 thy2
		(extends_by_proof thy1 thy2)
		
		( arity name  new_type arity name thy2 thy1)
		
		( name type  new_constant name type thy2 thy1)
		
		(name tm  new_definition name tm thy2 thy1)
		
		( pairs tm thm  new_specification pairs tm thm thy2 thy1)
		
		(name typars thm  new_type_definition name typars thm thy2 thy1))
	in
	(standard_extension = ancestral one_step)
Ë

We may now define STANDARD\_THEORY as the subtype of
THEORY comprising the theories which are standard
extensions of $INIT$.
å
sim_type_def `STANDARD_THEORY`
		"thy : THEORY,
		standard_extension thy INIT";;
æ
\section{THEORY HIERARCHIES AND THE HOL SYSTEM} \label{THEORYHIERARCHIES}

The HOL system operates not with the totality
of the type {\it THEORY}, but with subsets of it.
The subsets are structured as hierarchies in which
each theory has a unique name and a parenthood relation is
given on the names. We will view this structure
as a function from names to theories. The function
is required to be order-preserving with respect
to parenthood (of names) and extension (of theories).

\subsection{More on Relations}
We will use the term {\it root} for a least element
of the ancestral of a relation. Such an element is
necessarily unique for a non-empty relation whose ancestral is
antisymmetric.

È
	ârootá : (*  *  bool)  *  bool
É
	 R min  root R min = y  (y  min)  (y  field R)  ancestral R min y
Ë

È
	ârootedá : (*  *  bool)  bool
É
	 R  rooted R =  min  root R min
Ë
We will need the idea of an order-preserving function:
È
	âorder_preservingá : (*  **)  (*  *  bool)  (**  **  bool)  bool
É
	 f R1 F2  order_preserving f R1 R2 =  x y  R1 x y  R2 (f x) (f y)
Ë


\subsection{The Abstract State of a HOL System}

We can now give an abstract model for the state of
an implementation of an HOL system. The part of the
state which is to do with the theory hierarchy
is as follows:

ÇÍ`âHOL_STATEá``HSt`ÍÍÍÍÍÍÍÍÍÍß
	parent	: string  string  bool,
	theory	: string  THEORY
ÉÍÍÍÍÍÍÍÍÍÍÍÍ
	(antisymmetric (ancestral parent)) 
	(rooted parent) 
	(init  root parent init  (theory init = INIT)) 
	(order_preserving theory parent $extends)
ÊÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍà

(The projection functions for the above type are
$HSt\_parent$ and $HSt\_theory$.)

In using the above definition we will only consider
theories associated with names within the field
of the parenthood relation. Thus the implementation
need not include an infinite database.

A HOL system would then be an
instance of the following datatype:

Ç`âHOL_SYSTEMá``HSy`ÍÍÍÍÍÍÍÍß
	transitions :(*INPUT  HOL_STATE)  (HOL_STATE  *OUTPUT)
ÉÍÍÍÍÍÍÍÍÍÍÍÍ
	T
ÊÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍÍà

Note that, the types ``${:}{*}INPUT$''
and ``${:}{*}OUTPUT$'' are meant to model more than just
commands from a keyboard and responses on a screen.
For instance, the metalanguage interpreter and associated
state might be a component of both types.

Moreover, if we wish,
we can restrict our attention to ``safe'' systems,
i.e. those permitting only consistent theories, using
the following predicates.
We say a state is consistent if all the theories named
in it are consistent.


È
	âconsistent_stateá : HOL_STATE  bool
É
	 hol_state
	consistent_state hol_state = 
	 thy 
	( name 
		(name  field (hol_state.HSt_parent)) 
		((hol_state.HSt_theory) name = thy)
	)  	consistent_theory thy
Ë

È
	âsafeá : (*INPUT, *OUTPUT)HOL_SYSTEM  bool
É
	 hol_system 
	safe hol_system =
	 input hol_state 
	consistent_state hol_state 
	consistent_state (FST((hol_system.HSy_transitions)(input, hol_state)))
Ë
Perhaps of even more importance are the HOL systems
whose transitions only introduce theories which are
standard extensions of existing theories.
In the following definition we also allow deletion of theorems
from theories (i.e. the inverse of
extension by proof).
È
	âstandardá : (*INPUT, *OUTPUT)HOL_SYSTEM  bool
É
	 hol_system 
	standard hol_system =
	 new_name input old_state 
	let thy = ((FST((hol_system.HSy_transitions)(input, old_state))).HSt_theory) new_name
	in
	old_name
	(standard_extension thy ((old_state.HSt_theory) old_name)
	
	extends_by_proof ((old_state.HSt_theory) old_name)thy)
Ë

%\section{THE THEORY}
%\begin{FT}{}
% \input{holsyn.th.prt}
%\end{FT}

\twocolumn
\section{Index of Defined Terms}
\printindex
\end{document}

