\showboxbreadth=999 \showboxdepth=999
\documentstyle[FM,hol]{article}
\makeindex
\ftlinepenalty=5000
\def\Hide#1{}
\pagestyle{FM}
\setcounter{section}{-1}
\FMtitle{HOL in HOL}
\FMidentity{DS/FMU/RBJ/150}
\FMissue{0.1}
\FMclass{}
\FMdate{\today}
\FMauthor{R.D. Arthan}
\FMstatus{Draft}
\FMtype{}
\FMauthority{}
\FMsummary{ }
\FMdistribution{}
\begin{document}
\makeFMfrontpage
\section{Document control}
\subsection{Contents list}
\tableofcontents
\subsection{Document cross references}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes history}  % to get section number `0.3'

First version.

\subsection{Changes forecast}

Under development, highly incomplete, totally volatile.

\subsection{Abbreviations and notation}
\begin{tabular}{ll}
HOL & Higher Order Logic\\
\end{tabular}
\section{INTRODUCTION}
This document is an attempt to specify the
syntactic aspects of the
HOL logic using the HOL system.
The document should be viewed as a formal treatment
of chapters 3, 4 and 5 of Mike Gordon's
description of the HOL logic and system
(\cite{gordon87}).

Where possible we have tried to present the
specification to serve
both as a specification of the logic
(i.e. the formal theory
in the sense of a mathematical structure with terms,
well-formed terms, inference rules etc.) and the
system (i.e. the program which enable one
to calculate theorems).
We have erred on the side of abstraction whenever
presentation of a constructive formulation would
lead to inappropriate complexity.

In formalising the system we have, on occasion, felt
that certain changes would be desirable for one reason
or another. We have resisted all such urges ---
what is presented here is meant to be a rigorous
formulation of the logic as described in \cite{gordon87}.
Where \cite{gordon87} has proved a little too loose for our
purposes (e.g. in the details of type instantiation),
we have tried to follow the spirit of the HOL system.
An appendix discusses some of the issues.

\subsection{Introducing the new theory}

\Hide{
extend_theory`holsyn`;;
map loadf [`TAUT`;`infra`];;
lemmas_on := false;;
garbage_collection_diags false;;
}
We intoduce the new theory. Its parents are
library theories which we will use later.
We set some controls for the infrastructure which
supports the Z-like definition mechanism and for the
ML system.
Â
new_theory`holsyn`;;
map new_parent [`string`; `infra`; `set`];;
map loadf [`infra`];;
lemmas_on := false;;
garbage_collection_diags false;;
Ê
»
	£ : ((* ã bool) ã bool) ã (* ã bool)
…
	É sets x é x ù $£ sets = Ñsetéx ù set Ä set ù sets
À


\section{THE SYNTAX OF TYPES AND TERMS}

In this section we define the abstract syntax of HOL terms
and of the types which they contain.
The terms will be given as that subtype of a type of ``free
terms'' which comprises the terms which are well-formed
(i.e. well-typed) in a sense we will define.

The well-formedness check does not consider
context-sensitive issues such
conformance of the type of a
constant or the arity of a type
with the definition of the constant or type ---
such considerations are deferred until we have defined the
notion of a theory.
To some extent this approach is forced on us
since we wish to define a type of well-formed terms.
Since the system does not permit dependent types the
well-formedness predicate cannot be parameterised by
any form of context.

To define types for the various syntactic classes
we use {\tt new\_type}. To populate them we use
{\tt new\_constant}. To lend verisimilitude to our
account we formulate as an axiom for each new type,
a principle of definition by structural recursion, which
might be used to justify the functions we will later
define on the types.
The consistency of the specification
could, we hope, be demonstrated using T.~Melham's
system for defining recursive types.
We are using HOL in the spirit of Z or VDM here.

\subsection{Types}
As a consequence of our approach,
the HOL types constitute a free algebra.
It is only in the context of the type definitions within
a hierarchy of theories that a type can be ill-formed.

Â
new_type 0 `TYPE`;;

new_constant (`‚mk_vartype·`,":string ã TYPE");;

new_constant (`‚mk_type·`,":string â TYPE list ã TYPE");;

let ‚TYPE_axiom· = new_axiom(`TYPE_axiom`,"
	É(f0:string ã *) (f1: string â TYPE list ã * list ã *)é
        ¿ (fn:TYPE ã *)é
         (Ésé fn(mk_vartype s) = f0 s) Ä
         (És tlé fn(mk_type (s,tl)) = f1 (s, tl) (map fn tl))
");;
Ê

We try to adopt the convention of defining destructor
functions whenever we define constructor functions:
»
	‚dest_vartype·: TYPE ã string 
…
		dest_vartype o mk_vartype = I
À
»
	‚dest_type·: TYPE ã string â (TYPE list)
…
		dest_type o mk_type = I
À

\subsection{Free Terms}

The type {\it FTERM} is the syntactic class for what we
will call free terms, i.e.
``HOL terms which are well-formed enough to parse, but
which may not be well-typed''.

Â
new_type 0 `FTERM`;;

new_constant (`‚mk_fvar·`,":string â TYPE ã FTERM");;

new_constant (`‚mk_fconst·`,":string â TYPE ã FTERM");;

new_constant (`‚mk_fcomb·`,":FTERM â FTERM  ã FTERM");;

new_constant (`‚mk_fabs·`,":string â TYPE â FTERM  ã FTERM");;

let ‚FTERM_axiom· = new_axiom(`FTERM_axiom`,"
	É
	(f0:string â TYPE ã *)
	(f1:string â TYPE ã *)
	(f2: FTERM â FTERM ã * â * ã *)
	(f3: string â TYPE â FTERM ã * ã *)é
        ¿ (fn:FTERM ã *)é
         (És tyé	fn (mk_fvar (s, ty))
			= f0 (s, ty))
	Ä  (És tyé	fn(mk_fconst (s, ty))
			= f1 (s, ty))
	Ä  (Éf aé	fn(mk_fcomb (f, a))
			= f2 (f, a) (fn f, fn a))
	Ä  (Év ty bé	fn(mk_fabs (v, ty, b))
			= f3 (v, ty, b) (fn b))
");;
Ê

We now define the destructor functions which are
left inverse to the constructor functions
{\it mk\_fvar} etc. The destructor functions
would most naturally be implemented as partial
functions --- i.e. they would treat as erroneous
arguments which
are not in the codomain of the corresponding constructor.

»
	‚dest_fvar·: FTERM ã string â TYPE
…
		dest_fvar o mk_fvar = I
À
»
	‚dest_fconst·: FTERM ã string â TYPE
…
		dest_fconst o mk_fconst = I
À
»
	‚dest_fcomb·: FTERM ã FTERM â FTERM
…
		dest_fcomb o mk_fcomb = I
À
»
	‚dest_fabs·: FTERM ã string â TYPE â FTERM
…
		dest_fabs o mk_fabs = I
À

\subsection{Free Variables}
To illustrate how the principle of definition
by structural recursion for the type {\it FTERM}
might be used, we specify some simple functions
which are useful later and whose specifications could
be proved consistent using it.

{\it freevars\_fset} returns the set of free variables
of a term.
We use it in cases where the order of appearance
of the free variables in the term is immaterial.

»
	‚freevars_fset·: FTERM ã (string â TYPE ã bool)
…
	É(s : string) (t : TYPE) (f : FTERM)
	(a : FTERM) (v : string) (b : FTERM) é
	(freevars_fset (mk_fvar(s,t)) = çxé x = (s,t))
Ä	(freevars_fset (mk_fconst(s,t)) = çxé F)
Ä	(freevars_fset (mk_fcomb(f, a)) =
			(freevars_fset f) ° (freevars_fset a))
Ä	(freevars_fset (mk_fabs(v, t, b)) =
			(freevars_fset b) ƒ çxé x = (v,t))
À

{\it freevars\_flist} returns the free variables of a term
listed in order of first appearance (from left to
right in the usual concrete syntax).

»
	‚freevars_flist·: FTERM ã ((string â TYPE)list)
…
	É(s : string) (t : TYPE) (f : FTERM)
	(a : FTERM) (v : string) (b : FTERM) é
	(freevars_flist (mk_fvar(s,t)) = [(s,t)])
Ä	(freevars_flist (mk_fconst(s,t)) = [])
Ä	(freevars_flist (mk_fcomb(f, a)) =
			freevars_flist f µ
			(freevars_flist a ¡ çxéx ∆ freevars_flist f))
Ä	(freevars_flist (mk_fabs(v, t, b)) =
			freevars_flist b ¡ çxé x à (v,t))
À

\subsection{Typing Terms}

We now give the relation which relates a free term
to its type, if it has one.

Note that two variables
with the same name but different types are simply
considered as different --- this agrees with both
the HOL logic and the HOL system (except that a term
containing two such names in the same scope cannot
be entered via the parser --- the constructor functions 
must be used).

We do not check here that the type assigned to
a constant is an instance of the type with which it
is declared. Indeed, we have not yet defined the
mechanisms required to do this.

A function returning function types is useful:

»
	‚Fun· : TYPE ã TYPE ã TYPE
…
	É ty1 ty2éFun ty1 ty2 = mk_type(`ã`, [ty1; t2])
À

»
	‚type_of_fterm·: FTERM ã TYPE ã bool
…
	É(s : string) (t : TYPE) (ty: TYPE)
	 (f : FTERM) (a : FTERM) (v : string)
	 (b : FTERM) é
	(type_of_fterm (mk_fvar(s,t)) ty = (t = ty))
Ä	(type_of_fterm (mk_fconst(s,t)) ty = (t = ty))
Ä	(type_of_fterm (mk_fcomb(f, a)) ty = 
		Ñ(t1 : TYPE)é
			(type_of_fterm f (Fun t1 ty))
		Ä	(type_of_fterm a t1))
Ä	(type_of_fterm (mk_fabs(v, t, b)) ty = 
		Ñ(t1 : TYPE)é
			(type_of_fterm b t1)
		Ä	(Fun t t1 = ty))
À

\subsection{Well-Formedness And The Type of Well-Formed Terms}

A term is well-formed if it has a type:

»
	‚is_wf_term· : FTERM ã bool
…
	Éterm:FTERMé
	is_wf_term term = Ñtype:TYPEé type_of_fterm term type
À

We now define the type {\it TERM} of well-formed terms
as a subtype of the type {\it FTERM} of free terms.

Â
	sim_type_def `‚TERM·` ("x:FTERM, is_wf_term x");;
Ê

The constructor functions for the type {\it TERM}
are easily defined as composites in terms of
the constructor functions for {\it FTERM} and
the abstraction and representation functions for
{\it TERM}:

»
	‚mk_var· : string â TYPE ã TERM
…
	mk_var = ABS_TERM o mk_fvar 
À
»
	‚mk_const· : string â TYPE ã TERM
…
	mk_const = ABS_TERM o mk_fconst 
À
»
	‚mk_comb· : TERM â TERM ã TERM
…
	mk_comb = (ABS_TERM o mk_fcomb) o ç(x,y)é (REP_TERM x, REP_TERM y)
À
»
	‚mk_abs· : TERM â TERM ã TERM
…
	mk_abs = (ABS_TERM o mk_fabs) o
			ç(x,y)é (	FST(dest_var x),
					SND(dest_var x),
					REP_TERM y)
À
As for {\it FTERM,} the destructor functions are
specified as left inverses of the corresponding
constructor functions:

»
	‚dest_var·: TERM ã string â TYPE
…
		dest_var o mk_var = I
À
»
	‚dest_const·: TERM ã string â TYPE
…
		dest_const o mk_const = I
À
»
	‚dest_comb·: TERM ã TERM â TERM
…
		dest_comb o mk_comb = I
À
»
	‚dest_abs·: TERM ã TERM â TERM
…
		dest_abs o mk_abs = I
À

We specify functions which test the class of a term.
These will not all be needed here, but, as the definitions
are a little tricky, we keep them close to the
constructor functions to which they are related
\footnote{This is the price of the fiction that the
constructor and destructor functions are total.}.
The first two are easy (because the constructor functions
are one-to-one).
»
	‚is_var·: TERM ã bool
…
	É tm é is_var tm = (mk_var(dest_var tm)) = tm
À
»
	‚is_const·: TERM ã bool
…
	É tm é is_const tm = (mk_const(dest_const tm)) = tm
À
For {\it is\_comb} we need to check when one term may be
applied to another:
»
	‚applicable·:  TERM ã TERM ã bool
…
	É f a é applicable f a = Ñ ty é type_of_term f = Fun (type_of_term a) ty
À
»
	‚is_comb·: TERM ã bool
…
	É tm é is_comb tm = Ñf aé applicable f a Ä (mk_comb(f, a) = tm)
À
»
	‚is_abs·: TERM ã bool
…
	É tm é is_abs tm = Ñvty bé is_var vty Ä (mk_abs(vty, b) = tm)
À


We can also define functions for typing terms and extracting
free variables using the ones we have already defined
for free terms:

»
	‚type_of_term· : TERM ã TYPE
…
	É tm é  type_of_fterm (REP_TERM tm) (type_of_term tm)
À
»
	‚freevars_set· : TERM ã (string â TYPE ã bool)
…
	freevars_set = freevars_fset o REP_TERM 
À
»
	‚freevars_list· : TERM ã ((string â TYPE) list)
…
	freevars_list = freevars_flist o REP_TERM 
À

\section{SYNTAX OF SEQUENTS}
A sequent is simply a set of assumptions
and a conclusion. Assumptions
and conclusion alike are just terms.
The following definition allows infinite
assumption sets, since they are easier for us to define.
However the axioms with which we shall work all have
finite sets of assumptions and the inference rules
will preserve this property.
Another pleasant property of sequents is for their
constituent terms to have type ``:bool''. This property
too holds of our axioms and is preserved by our inference
rules.

{\tiny Should we have taken a subtype?}

Â
new_type_abbrev(`‚SEQ·`, ":(TERM ã bool) â TERM");;
Ê

The destructor functions for sequents are as follows.
(Their names are as in the HOL system) 
»
	‚concl· : SEQ ã TERM
…
	concl = SND 
À

»
	‚hyp· : SEQ ã (TERM ã bool)
…
	hyp = FST 
À


\section{THE AXIOM SCHEMATA AND RULES OF INFERENCE}

In this section we treat the syntax manipulating
functions required to define the various rules of
inference. We consider each inference rule in turn.
In the HOL system the inference rules are functions
which take theorems (and other things) as arguments
and return theorems. Since we cannot define
the type of theorems until we have defined the inference
rules we define the rules as functions taking
sequents (and other things) as arguments and returning
sequents.

\subsection{The Axiom Schema ASSUME}

This is straightforward;
»
	‚ASSUME_axiom· : TERM ã SEQ
…
	É tm é ASSUME_axiom tm = (singleton_set tm, tm)
À

\subsection{The Axiom Schema REFL}

We now need the constant type ``:bool'':
»
	‚Bool· : TYPE
…
	Bool = mk_type(`bool`, [])
À

We define some utilities for handling equations:

»
	‚Equality· : TYPE ã TERM
…
	É ty é Equality ty = mk_const(`=`, Fun ty (Fun ty Bool))
À
»
	‚mk_eq· : (TERM â TERM) ã TERM
…
	É tm1 tm2 é mk_eq(tm1, tm2) = mk_comb(mk_comb(Equality (type_of_term tm1), tm1), tm2)

À
»
	‚dest_eq· : TERM ã (TERM â TERM)
…
	dest_eq o mk_eq = I
À
»
	‚is_eq· : TERM ã bool
…
	Étm é is_eq tm = Ñlhs rhsé (type_of_term lhs = type_of_term rhs) Ä (mk_eq(lhs, rhs) = tm)
À

»
	‚REFL_axiom· : TERM ã SEQ
…
	É tm é REFL_axiom tm = (§, mk_eq(tm, tm))
À



\subsection{The Inference Rule SUBST}

In this section we define the functions needed to
define the inference rule {\it SUBST}.

In essence, {\it SUBST} says that given a
theorem whose conclusion is an equation ${\cal A} = {\cal B}$, where
$\cal A$ and $\cal B$ are arbitrary terms of the same
type, and given any other theorem with conclusion
$\cal C$ say, we may obtain a new theorem by substituting
$\cal B$ for 
any subterm of $\cal C$ which is identical with $\cal A$. This is subject to the proviso that no variable
capture problems arise, i.e. no
free variables of $\cal B$ should become bound in the
conclusion of the new theorem. (The assumption set of the
consequent theorem is the union of the assumption sets of
the antecedent theorems.)

The inference rule is, in fact, formulated slightly more
general. It allows one to use a whole set of theorems
whose conclusions are equations to perform (simultaneous)
substitutions for many subterms of $\cal C$. Moreover,
it is implemented as a functional relation, effectively by
renaming any bound variables of $\cal C$ which would
give rise to the capture problem.

The inference rule is parametrised by a template term
and a set of some of its free variables, one for each equation.
The actual statement of the rule is, essentially, that, 
if the result of substituting the left hand sides
of the equations for the corresponding variables
in the template term
is equal to $\cal C$ ({\it modulo} renaming bound
variables), then we may infer the result of substituting
the right hand sides of the equations for the
corresponding template variables in the template term
(providing we rename bound variables to avoid the capture
problem).


The notions we must formalise are therefore: (i) renaming a variable in a term; (ii) testing equivalence of
terms {\it modulo} renaming of bound variables (aka.
$\alpha$-conversion); (iii) substituting terms for
free variables in a term according to a given mapping
of variables to terms avoiding variable capture.


\subsubsection{Renaming}
$\it rename (v, ty) w\, e$ is the result of changing
the name in every free occurrence of the
variable with name {\it v} and type {\it ty} in the
term {\it e} to {\it w}.

»
	‚rename· : (string â TYPE) ã string ã TERM ã TERM
…
	É
	(v : string) (ty : TYPE) (w: string)
	(vv :string) (tty : TYPE) (cc : string)
	(ff : TERM) (aa : TERM) (bb : TERM)
	é
	(rename (v, ty) w (mk_var(vv, tty)) =
		((v = vv) Ä (ty = tty)) =>
			mk_var(w, ty) | mk_var(vv, tty))
	Ä
	(rename (v, ty) w (mk_const(cc, tty)) =
		mk_const(cc, tty))
	Ä
	(rename (v, ty) w (mk_comb(ff, aa)) =
		mk_comb(rename (v, ty) w ff, rename (v, ty) w aa))
	Ä
	(rename (v, ty) w (mk_abs(mk_var(vv, tty), bb)) =
		((v = vv) Ä (ty = tty)) =>
			mk_abs(mk_var(vv, tty), bb) |
			mk_abs(mk_var(vv, tty), rename (v, ty) w bb))
À

\subsubsection{$\alpha$-conversion}

»
	‚aconv· : TERM ã TERM ã bool
…
	É(t1 : TERM) (t2 : TERM)é
	aconv t1 t2 =
		(t1 = t2)
	Å	(Ñt1f t1a t2f t2aé
			(t1 = mk_comb(t1f, t1a))
		Ä	(t2 = mk_comb(t2f, t2a))
		Ä	(aconv t1f t2f Ä aconv t1a t2a))
	Å	(Ñv1 v2 ty b1 b2é
			(t1 = mk_abs(mk_var(v1, ty), b1))
		Ä	(t2 = mk_abs(mk_var(v2, ty), b2))
		Ä	aconv t1 (mk_abs(mk_var(v1, ty), rename (v2, ty) v1 b2)))

À

\subsubsection{Substitution}

We will need to choose new names for variables.
More precisely,
given a variable and a set of same we will
wish to rename the variable, when necessary,
to ensure that the result
does not lie in the set.
In practice in an implementation we would insist that the new name
be derived from the old one in a specified way.

»
	‚variant· : (string â TYPE ã bool) ã (string â TYPE) ã string
…
	É vs v ty é ((v, ty) ì vs) => (variant vs (v, ty) = v) | (variant vs (v, ty), ty) ì vs
À

The following function is useful in {\it subst} and
elsewhere.

»
›	‚image· :  (* ã **) ã (* ã bool) ã (** ã bool)
…
›	Éfunction seté image function set = 
›		çx:**é Ñy:*é (x = f y) Ä y ù set
À

Now we can define {\it subst}. {\it subst F t1} gives the
term resulting from replacing every free variable
$\it mk\_var(s, t)$
in {\it t1} by $\it F(mk\_var(s, t))$ with bound
variables renamed as necessary to avoid capture.
Variables which are not to be changed correspond
to pairs $(s, t)$ with $\it F (s, t) =  mk\_fvar (s, t)$.
Note that we rely on {\it variant}
not to change bound variable names unnecessarily.

»
	‚subst· : (string â TYPE ã TERM) ã TERM ã TERM
…
	É
	(v : string) (ty : TYPE) (c : string)
	(f : TERM) (a : TERM) (b : TERM)
	é
	(subst R (mk_var(v, ty)) = R (v,ty))
	Ä
	(subst R (mk_const(c, ty)) = mk_const(c, ty))
	Ä
	(subst R (mk_comb(f, a)) = mk_comb(subst R f, subst R a))
	Ä
	(subst R (mk_abs(mk_var(v, ty), b)) =
		let new_frees = £(image (freevars_set o R) (freevars_set b ƒ singleton_set (v, ty)))
		in  let v' = variant new_frees (v, ty)
		in let RR = çxé (x = (v', ty)) => (mk_var x) | R x
		in
			mk_abs(mk_var(v', ty), subst RR (rename (v, ty) v' b))
	)
À

We can now define the inference rule.
Its first argument gives the correspondence between the
template variables and equation theorems.
We could take this argument to 
behave as {\it REFL o MK\_VAR} on variables which
are not template variables . 
Note that, to allow implementation as a partial function,
we test up to $\alpha$-convertibility on the first
sequent argument only.

»
	‚SUBST_rule· : ((string â TYPE) ã SEQ) ã
			TERM ã SEQ ã SEQ ã bool
…
	É eqs tm old_asms old_conc new_asms  new_concé
	SUBST_rule eqs tm (old_asms, old_conc) (new_asms, new_conc) = 
	(Éasms conc v ty é (eqs(v, ty) = (asms, conc)) ä
		(Ñlhs rhsé(conc = mk_eq(lhs, rhs)) Ä
		(type_of_term lhs = ty)))
	Ä
	(aconv old_conc (subst (FST o dest_eq o SND o eqs) tm))
	Ä
	(new_conc = subst (SND o dest_eq o SND o eqs) tm)
	Ä
	(new_asms = old_asms ° £ (çasmséÑvtyéasms =  (FST (eqs vty))))
À



\subsection{The Axiom Schema BETA\_CONV}

{\it BETA\_CONV} may be specified using the
apparatus we have set up for {\it SUBST}.
It is necessarily a partial rather than total,
function, given the way it
is parameterised. There is no obvious reparameterisation
to
avoid the problem. (If you supply the subterms of the
abstraction as parameters the types must be right).
It is, of course, useful for the implementers of the
HOL system to know that the relation we specify for it is in
fact a partial function:.

»
	‚BETA_CONV_axiom· : TERM ã SEQ ã bool
…
	É tm asms new_seqé
	BETA_CONV_axiom tm new_seq =
	Ñ v ty b a é
	(tm = mk_comb(mk_abs(mk_var(v, ty), b), a)) Ä
	(new_seq = 
	let subs: ((string â TYPE) ã TERM) = (ç(vx, tyx)é((vx = v) Ä (tyx = ty)) => a | mk_var(vx, tyx))
	in
		(§, (mk_eq(tm, subst subs b))))
À



\subsection{Abstraction: ABS}

Again {\it ABS} is a partial function which we
specify as a relation:

»
	‚ABS_rule· : (string â TYPE) ã SEQ ã SEQ ã bool
…
	É vty old_asms old_conc new_asms new_conc é
	ABS_rule vty (old_asms, old_conc) (new_asms, new_conc) =
	(Ñ lhs rhs é
		(old_conc = mk_eq(lhs, rhs)) Ä
		(let abstract = (çx é mk_abs(mk_var vty, x))
		in (new_conc = mk_eq(abstract lhs, abstract rhs))))
	Ä
	(vty ì £(image freevars_set old_asms))
	Ä
	(new_asms = old_asms)
À



\subsection{Type Instantiation: INST\_TYPE}

The ability to prove and use general (polymorphic)
theorems  is one of the great strengths of the HOL
system. The feature in the inference system which
gives this strength is the inference rule {\it INST\_TYPE}
which allows us to instantiate the type variables
in the conclusion of a polymorphic theorem.

In essence, the inference rule says that, given a theorem
with conclusion $\cal A$ say we may infer the theorem
which has the same assumption set and whose conclusion
results from instantiating every type in $\cal A$
according to a given mapping of type variables to types.
This is subject to two provisos: (i) no type variable may
be changed which appears in the assumption set for the
theorem; (ii) no two variables in the assumptions or
conclusion of the antecedent theorem, which are
different, by virtue of their type,  should become
identified in the consequent theorem as a result of
the transformation.

The first proviso is, we believe, only enforced to preserve
the natural deduction notion that inference rules
involve only simple set operations on the assumption
sets. It would seem to be quite in order for the first
proviso to be dropped provided we insisted that the
type instantiation be applied to every term in the sequent
(we have, of course, not done this).

The second proviso cannot be avoided. Consider for
example: $ç(x:**)éç(x:*)é(x:**)$. If this were type
instantiated according to $\{:** ó :*, :* ó :*\}$,
then from:
$$Ö É(y:**)(z:*)é(ç(x:**)éç(x:*)é(x:**))y z = y$$
we could infer that:
$$Ö É(y:*)(z:*)é(ç(x:*)éç(x:*)é(x:*))y z = y$$
whence, by $\beta$-conversions:
$$Ö É(y:*)(z:*)éz = y.$$
This leads to a contradiction whenever $:*$ is instantiated
to a type with more than one inhabitant.

To permit an implementation which is convenient to use,
the inference rule is actually formulated without the
second proviso. Instead, variables (both free and bound,
in general) in the conclusion of the consequent theorem,
which would violate the rule are renamed to
avoid the problem. It is valid to rename free variables
in these circumstances, given the first proviso, since
the variables in question cannot occur free in the
assumption set. Note that it would be invalid to
rename free variables in $\cal A$
which are not changed by the type instantiation
(since these may appear free in the assumption set).

Formalising these notions is a little tricky. We present
here a highly unconstructive specification, reminiscent
of $\alpha$-conversion.
The two notions to be formalised are: (i) the type
instantiation of a type given by a mapping of
type variables to types and (ii) the predicate on
pairs of terms which says that one is a type instance
of another according to a given mapping of type
variables to types and with respect to a set of
variables with which clashes must not occur (this
will be the set of free variables of the assumptions
in practice).

It is entertaining and instructive to consider
algorithms meeting these specifications and we consider
some possibilities in an appendix.


\subsubsection{Instantiation Of Types}
This is straightforward:
»
	‚inst_type· : (string ã TYPE) ã TYPE ã TYPE
…
	É(f: string ã TYPE) é
		(Ésé  inst_type f (mk_vartype s) = f s)
	Ä	(És tléinst_type f (mk_type(s, tl)) =
			mk_type(s, map (inst_type f) tl))
À

\subsubsection{Instantiation Of Terms}

Instantiation of terms is a little tricky.
The following two functions should be viewed as
local to the function {\it inst}.
{\it inst\_loc1} is very similar to an
$\alpha$-convertibility test. Indeed {\it aconv} could
have been defined as $\it inst\_loc1\,I$.
The first {\it TERM} argument of {\it inst\_loc1}
and {\it inst\_loc2}
gives the terms whose types are being instantiated (i.e.
it is the ``more polymorphic'' term).

»
	‚inst_loc1· : (string ã TYPE) ã TERM ã TERM ã bool
…
	É
	(tysubs : string ã TYPE)
	(tm1 : TERM) (tm2 : TERM)é
	inst_loc1 tysubs tm1 tm2 =
		(Ñtm1s tm1t tm2s tm2t mk_Xé
			((mk_X = mk_var) Å (mk_X = mk_const))
		Ä	(tm1 = mk_X(tm1s, tm1t)) Ä (tm2 = mk_X(tm2s, tm2t))
		Ä	(tm1s = tm2s) Ä (tm2t = inst_type tysubs tm1t))
	Å	(Ñtm1f tm1a tm2f tm2aé
			(tm1 = mk_comb(tm1f, tm1a)) Ä (tm2 = mk_comb(tm2f, tm2a))
		Ä	(inst_loc1 tysubs tm1f tm2f Ä inst_loc1 tysubs tm1a tm2a))
	Å	(Ñv1 v2 ty1 ty2 b1 b2é
			(tm1 = mk_abs(mk_var(v1, ty1), b1))
		Ä	(tm2 = mk_abs(mk_var(v2, ty2), b2))
		Ä	inst_loc1
			tysubs
	(mk_abs(mk_var(v2, ty1), rename (v1, ty1) v2 b1))
			tm2)
À


»
	‚inst_loc2· : ((string â TYPE) ã bool) ã 
		(string ã TYPE) ã
		(((string â TYPE) â (string â TYPE)) list) ã
		TERM ã TERM ã bool
…
	É(avoid : (string â TYPE) ã bool)
	(tysubs :string ã TYPE)
	(v1 : string) (ty1 : TYPE)
	(v2 : string) (ty2 : TYPE)
	(rest : ((string â TYPE) â (string â TYPE)) list)
	(tm1 : TERM) (tm2 : TERM)é
	(inst_loc2 avoid tysubs [] tm1 tm2 =
		inst_loc1 tysubs tm1 tm2)
	Ä
	(inst_loc2 avoid tysubs (CONS ((v1, ty1),(v2, ty2)) rest) tm1 tm2 =
		((v2, ty2) ù avoid ä ((v1, ty1) = (v2, ty2)))
	Ä	(ty2 = inst_type tysubs ty1)
	Ä	inst_loc2 avoid tysubs rest
		(rename (v1, ty1) v2 tm1) tm2)
À

The following simple list processing function is
needed:

»
	‚combine· : (* list) ã (** list) ã ((* â **) list)
…
	É hd1 hd2 tl1 tl2é
	(combine [] [] = [])
	Ä
	(combine (CONS hd1 tl1) (CONS hd2 tl2) =
			CONS (hd1, hd2) (combine tl1 tl2))
À

With the above preliminaries we can now define {\it inst}.

»
	‚inst· : ((string â TYPE) ã bool) ã
		(string ã TYPE) ã TERM ã TERM
…
	É((avoid : (string â TYPE) ã bool))
	(tysubs :string ã TYPE) (tm1 : TERM)é
	let tm2 = inst avoid tysubs tm1
	in let fl1 = freevars_list tm1
	in let fl2 = freevars_list tm2
	in	(length fl1 = length fl2)
	Ä	inst_loc2 avoid tysubs (combine fl1 fl2) tm1 tm2
À

We need to detect the type variables in a term:

»
	‚type_tyvars· :  TYPE ã (string ã bool)
…
		(És:stringé  type_tyvars (mk_vartype s) = singleton_set s)
	Ä	(És tlé type_tyvars (mk_type(s, tl)) =
			£ çxé x ≈ (map term_tyvars tl))
À

»
	term_types :  TERM ã (TYPE ã bool)
…
		(És té term_types (mk_var (s,t)) = singleton_set t)
	Ä	(És té term_types (mk_const (s,t)) = singleton_set t)
	Ä	(Éf aé term_types (mk_comb (f,a)) =
			(term_types f) ° (term_types a))
	Ä	(Év bé term_types (mk_abs(v,b)) =
			(term_types v) ° (term_types b))
À
»
	term_tyvars :  TERM ã (string ã bool)
…
	Étm é term_tyvars tm = £(image type_tyvars (term_types tm))
À

Yet again the rule is a partial function:

»
	‚INST_TYPE_rule· : (string ã TYPE) ã SEQ ã SEQ ã bool
…
	É tysubs old_asms old_conc new_seqé
	INST_TYPE_rule tysubs (old_asms, old_conc) new_seq =
	(É (tyv : string) é
		tyv ù £ (image term_tyvars old_asms) ä
		(tysubs tyv = mk_vartype tyv))
	Ä
	(let asms_frees = £ (image freevars_set old_asms)
	in
		(new_seq = (old_asms, inst asms_frees tysubs old_conc)))
À


\subsection{Discharging an Assumption: DISCH}

We now need  utilities for handling implications. 
»
	‚Implication· : TERM
…
	Implication = mk_const(`=>`, Fun Bool (Fun Bool Bool))
À

»
	‚mk_imp· : (TERM â TERM) ã TERM
…
	É tm1 tm2 é mk_imp(tm1, tm2) = mk_comb(mk_comb(Implication, tm1), tm2)

À

»
	‚dest_imp· : TERM ã (TERM â TERM)
…
	dest_imp o mk_imp = I
À

For completeness, we add {\it is\_imp} which is needed
in handling modus ponens.

»
	‚is_imp· : TERM ã bool
…
	É tm é is_imp tm = Ñ tm1 tm2 é
	(type_of_term tm1 = Bool) Ä (type_of_term tm2 = Bool) Ä
	(mk_imp(tm1, tm2) = tm)

À

The rule may now be defined. Again it is a partial
function.

»
	‚DISCH_rule· : TERM ã SEQ ã SEQ ã bool
…
	É tm old_asms old_conc new_seq é
	DISCH_rule tm (old_asms, old_conc) new_seq =
	(type_of_term tm = Bool) Ä
	(new_seq = (old_asms ƒ singleton_set tm, mk_imp(tm, old_conc)))
À

\subsection{Modus Ponens: MP}

This is straightforward. But, note the tacit assumption
that the conclusion of the antecedent theorem is a term
of type {\it bool}.

»
	‚MP_rule· : SEQ ã SEQ ã SEQ ã bool
…
	É imp_asms imp_conc ant_asms ant_conc new_seq é
	MP_rule (imp_asms, imp_conc) (ant_asms, ant_conc) (new_asms, new_conc) =
	(is_imp imp_conc) Ä
	(imp_conc = mk_imp(ant_conc, new_conc)) Ä
	(new_asms = imp_asms ° ant_asms)
À



\section{DERIVABILITY}


In this section we will define derivability.
This is a relation between sets of sequents
and sequents. As usual, we first define direct
derivability:
»
	‚directly_derivable_from· : SEQ ã (SEQ ã bool) ã bool
…
	É seq seqs é
	directly_derivable_from seq seqs = 
	(Ñ eqs tm old_seq é
	(image eqs (çxéT) • seqs) Ä (old_seq ù seqs) Ä SUBST_rule eqs tm old_seq seq)
	Å
	(Ñ vty old_seq é (old_seq ù seqs) Ä ABS_rule vty old_seqs seq)
	Å
	(Ñ tysubs old_seq é (old_seq ù seqs) Ä INST_TYPE_rule tysubs old_seqs seq)
	Å
	(Ñ tm old_seq é (old_seq ù seqs) Ä DISCH_rule tm old_seqs seq)
	Å
	(Ñ imp_seq ant_seq é (imp_seq ù seqs) Ä (ant_seq ù seqs) Ä MP_rule imp_seq ant_seq seq)
À
We need the following utility:

»
	‚elems· :  (* list) ã (* ã bool)
…
	e ù elems s Ç e ≈ s
À

Proofs will just be lists of sequents. Any non-empty
list is is a valid proof (of the sequent at its
head) on the premisses given by those elements
of the list which are not directly derivable
from elements later in the list.
There is little point in making the relevant type
definition for a syntactic class of proofs in this sense,
since they contain so little information.
We simply define the function which extracts the set
of premisses.

»
	‚premisses· :  (SEQ list) ã (SEQ ã bool)
…
	É seq rest é
	(premisses [] = §)
	Ä
	(premisses (CONC seq rest) =
		(directly_derivable_from seq (elems rest) => § | singleton_set seq) ° premisses rest)
À


»
	‚derivable_from· : SEQ ã (SEQ ã bool) ã bool
…
	É seq seqs é
	derivable_from seq seqs =
	Ñ seql é premisses (CONS seq seql) • seqs
À

\section{THEORIES}

The following type definitions help us to
formalise the context-sensitive aspects of the
well-formedness of terms, which we have avoided until
now. Once this is done we can define the type of all
well-formed HOL theories.

Â
new_type_abbrev(`‚TY_ENV·`, ":string ã num ã bool");;

new_type_abbrev(`‚CON_ENV·`, ":string ã TYPE ã bool");;

new_type_abbrev(`‚SEQS·`, ":SEQ ã bool");;
Ê


We can now define the well-formedness of types and terms with
respect to a type environment. We assume that
the names for type variables and type constructors
are in distinct lexical categories, and so we do not
impose any check apart from on the arity of constructors.
(This agrees with the HOL system, except that the HOL
system imposes additional lexical constraints on the
names).
 
»
	‚wf_type· : TYPE ã TY_ENV ã bool
…
	É ty tyenv é
	wf_type ty tyenv = 
	(Ñs é ty = mk_vartype s)
	Ä
	(Ñs tyl é (tyenv s (length tyl)) Ä É t é t ≈ tyl ä wf_type t tyenv)
À

For terms we place no restrictions on the names of
variables. (The HOL system tries to prevent constant
names being used as variable names but does not
always succeed, e.g, if the constant is declared after
a theorem using a variable with the same name has been
saved on a theory).

»
	‚wf_term·: TERM ã TY_ENV ã CON_ENV ã bool
…
	É s ty f a v b  tyenv conenv é
	let ok = çtmé wf_term tm tyenv conenv
	in 
	((ok (mk_var(s,ty)) = (wf_type ty tyenv) Ä É t é å(conenv s t))
Ä	(ok (mk_const(s,ty)) = 
		(wf_type ty tyenv) Ä
		(Ñ ty' tysubsé (conenv s ty') Ä (inst_type tysubs ty' = ty)))
Ä	(ok (mk_comb(f, a)) = (ok f) Ä (ok a))
Ä	(ok (mk_abs(v, b)) = (ok v) Ä (ok b)))
À

The well-formedness of terms extends straightforwardly
to sequents and to sets thereof. We impose an
additional constraint for sequents: they must be
made up from terms of type ``{\it:bool}''.

»
	‚wf_seq·: SEQ ã TY_ENV ã CON_ENV ã bool
…
	É seq tyenv conenvé
	let ok = çtmé (wf_term tm tyenv conenv) Ä (type_of_term tm = Bool)
	in 
	(wf_seq seq tyenv conenv =
	((ok (concl seq)) Ä (Étmé (tm ù (hyp seq)) ä (ok tm))))
À

»
	‚wf_seqs·: SEQS ã TY_ENV ã CON_ENV ã bool
…
	É seqs tyenv conenvé
	wf_seqs seqs tyenv conenv =
	É seq é (seq ù seqs) ä (wf_seq seq tyenv conenv)
À

For the constant environments, we insist that the
type associated with each name be well-formed and
that at most one type is associated with each name.
Overloaded constant names could, in principle, be allowed,
as an extension to the system. This function would be
modified to impose some weaker condition.

»
	‚wf_con_env·: CON_ENV ã TY_ENV ã bool
…
	É conenv tyenvé
	wf_con_env conenv tyenv =
	(É con tyé (conenv con ty) ä (wf_type ty tyenv)) Ä
	(É con ty1 ty2 é (conenv con ty1) ä (conenv con ty2) ä (ty1 = ty2))
À

We insist that at most one arity be associated with
each name in a well-formed type environment:

»
	‚wf_ty_env·: TY_ENV ã bool
…
	É tyenvé
	wf_ty_env tyenv =
	É ty n1 n2 é (tyenv ty n1) ä (tyenv ty n2) ä (n1 = n2)
À

We can now define the type of all theories whose
components are well-formed. We will then take the subtype
of this consisting of all theories which extend the
minimal one (with just the constants for equality
and implication and the type of propositions).

{\tiny I have deleted the $\it extensions : SEQS$
component of $\it THEORY$. It can easily go back in if
it turns out to be useful.}

«Õ`‚FTHEORY·``T`ÕÕÕÕÕÕÕÕÕÕﬂ
	ty_env		:TY_ENV,
	con_env		:CON_ENV,
	axioms		:SEQS,
	theorems	:SEQS
…ÕÕÕÕÕÕÕÕÕÕÕÕ
	(wf_ty_env ty_env) Ä
	(wf_con_env con_env ty_env) Ä
	(wf_seqs axioms ty_env con_env) Ä
	(wf_seqs theorems ty_env con_env) Ä
	(theorems • çseqéderivable_from seq axioms)
 ÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕ‡

»
	‚Star· : TYPE
…
	Star = mk_vartype `*`
À
»
	‚FMIN· : FTHEORY
…
	(	FMIN.T_ty_env = çty n é
		(	(ty = FST(dest_type Bool)) Ä
			(n  = length(SND(dest_type Bool)))
		) Å (	(ty = FST(dest_type(Fun Bool Bool))) Ä
			(n  = length(SND(dest_type(Fun Bool Bool))))
		)
	) Ä (	FMIN.T_con_env = çs tyé
			((s, ty) = dest_const (Equality Star)) Å
			((s, ty) = dest_const Implication)
	) Ä (	FMIN.T_axioms = §
	) Ä (	FMIN.T_theorems = §
	)
À

Á
	fextends : FTHEORY ã FTHEORY ã bool
…
	É thy1 thy2é
	fextends thy1 thy2 =
	(UNCURRY(thy2.T_ty_env) • UNCURRY(thy1.T_ty_env)) Ä
	(UNCURRY(thy2.T_con_env) • UNCURRY(thy1.T_con_env)) Ä
	((thy2.T_axioms) • (thy1.T_axioms)) Ä 
	((thy2.T_theorems) • (thy1.T_theorems))
À

We restrict attention to theories which extend the
minimal theory {\it FMIN}. Note that we do not
exclude inconsistent theories here. (This corresponds
to the possibility of introducing inconsistent axioms
in the HOL system).

Â
	sim_type_def `‚THEORY·`
	"thy, (thy fextends FMIN)";;
Ê

We can, at last, define the type of all HOL theorems.
A theorem will consist of a sequent and a theory.
The type is the subtype of the type of all such  pairs
in which the sequent is well-formed with respect to the
type and constant environments of the theory and in which
the sequent may be derived from the axioms of the theory.

«Õ`THM``thm`ÕÕÕÕÕÕÕÕÕÕﬂ
	theorem	: SEQ,
	theory	: THEORY
…ÕÕÕÕÕÕÕÕÕÕÕÕ
	let fthy = REP_THEORY theory
	in
	((wf_seq theorem (fthy.T_ty_env) (fthy.T_con_env))
	Ä
	(theorem ù çseqéderivable_from seq (fthy.T_axioms)))
 ÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕ‡

»
	‚MIN· : THEORY
…
	MIN = ABS_THEORY FMIN
À
Á
	‚extends· : THEORY ã THEORY ã bool
…
	É thy1 thy2é
	extends (ABS_THEORY thy1) (ABS_THEORY thy2) =
	thy1 fextends thy2
À

»
	‚consistent_theory· : THEORY ã bool
…
	É thy é
	consistent_theory (ABS_THEORY thy) =
	Ñ seq é
	(wf_seq seq (thy.T_ty_env) (thy.T_con_env))
	Ä
	(seq ì çseqéderivable_from seq (thy.T_axioms))
À

\section{NAMED HIERARCHIES OF THEORIES}

The HOL system operates not with the totality
of the type {\it THEORY}, but with subsets of it.
The subsets are structured as hierarchies in which
each theory has a unique name and a parenthood relation is
given on the names. We will view this structure
as a function from names to theories. The function
is required to be order-preserving with respect
to parenthood (of names) and extension (of theories).

\subsection{Relations}

We need some generalities about relations.
First the standard notion of antisymmetry:


»
	‚antisymmetric· : (* ã * ã bool) ã bool
…
	antisymmetric R = É x y é (R x y) ä (R y x) ä (x = y)
À

Next domain and codomain:

»
	‚domain· : (* ã * ã bool) ã (* ã bool)
…
	É R x é (x ù domain R)  Ç Ñyé R x y
À

»
	‚codomain· : (* ã * ã bool) ã (* ã bool)
…
	É R x é (x ù codomain R)  Ç Ñyé R y x
À
We make the {\it ad hoc} definition that the {\it field}
of a relation is the union of its domain and codomain.

»
	‚field· : (* ã * ã bool) ã (* ã bool)
…
	É R é field R = domain R ° codomain R
À

We need the notion of a path between two elements in a
relation. (This would enable us to define the ancestral,
or transitive closure, of a relation, but we do not need
that concept.)
 
»
	‚path· : (* list) ã (* ã * ã bool) ã * ã * ã bool
…
	É l R x y é
	path l R x y Ç 
	( (l = [x; y]) Ä R x y ) Å
	(Ñ x1 rest é (l = CONS x (CONS x1 rest)) Ä R x x1 Ä path rest R x1 y)
À

We will use the term {\it root} for a least element
of the ancestral of a relation. Such an element is
necessarily unique for an antisymmetric relation.

»
	‚root· : (* ã * ã bool) ã * ã bool
…
	É R min é root R min = Éy é (y ù field R) ä Ñl é path l R min y
À

»
	‚rooted· : (* ã * ã bool) ã bool
…
	É R é rooted R = Ñ min é root R min
À

The final generality that we need is the idea of
an order-preserving function:
»
	‚order_preserving· : (* ã **) ã (* ã * ã bool) ã (** ã ** ã bool) ã bool
…
	order_preserving f R1 R2 = É x y é R1 x y ä R2 (f x) (f y)
À


\subsection{The Abstract State of a HOL System}

We can now give an abstract model for the state of
an implementation of an HOL system. The part of the
state which is to do with the theory hierarchy
is as follows:

«Õ`‚HOL_STATE·``HSt`ÕÕÕÕÕÕÕÕÕÕﬂ
	parent	: string ã string ã bool,
	theory	: string ã THEORY
…ÕÕÕÕÕÕÕÕÕÕÕÕ
	(antisymmetric parent) Ä
	(rooted parent) Ä
	(Émin é root parent min ä (theory min = MIN)) Ä
	(order_preserving theory parent $extends)
 ÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕ‡

In using the above definition we will only consider
theories associated with names within the field
of the parenthood relation. Thus the implementation
need not include an infinite database.

A HOL system would then be an
instance of the following datatype:

«`‚HOL_SYSTEM·``HSy`ÕÕÕÕÕÕÕÕﬂ
	transitions :(*INPUT â HOL_STATE) ã (HOL_STATE â *OUTPUT)
…ÕÕÕÕÕÕÕÕÕÕÕÕ
	T
 ÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕÕ‡

Moreover, if we wish,
we can restrict our attention to ``safe'' systems,
i.e. those permitting only consistent theories, using
the following predicates.
We say a state is consistent if all the theories named
in it are consistent.

»
	‚consistent_state· : HOL_STATE ã bool
…
	É hol_stateé
	consistent_state hol_state = 
	É thy é
	(Ñ name é
		(name ù field (hol_state.HSt_parents)) Ä
		((hol_state.HSt_theory) name = thy)
	) ä 	consistent_theory thy
À

»
	‚safe· : (*INPUT, *OUTPUT)HOL_SYSTEM ã bool
…
	É hol_system é
	safe hol_system =
	É input hol_state é
	consistent_state hol_state ä
	consistent_state (FST((hol_system.HSy_transitions)(input, hol_state)))
À

\section{THE INFERENCE RULES REVISITED}

Given our type of theorems, we can now define
the inference rules as relations between theorems, rather
than sequences.

»
	‚thm_seq· : THM -> SEQ
…
	É thm é thm_seq thm = FST (REP_THM thm)
À
»
	‚thm_thy· : THM -> THEORY
…
	É thm é thm_thy thm = SND (REP_THM thm)
À

»
	‚SUBST· : ((string â TYPE) ã THM) ã
			TERM ã THM ã THM ã bool
…
	É eqs tm old_thm new_thm é
	SUBST eqs tm old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(SUBST_rule (thm_seq o eqs) tm old_seq new_seq
	Ä
	(new_thy extends old_thy) Ä
	(image (thm_thy o eqs)(çxéT) • $extends new_thy))
À
»
	‚ABS· : (string â TYPE) ã THM ã THM ã bool
…
	É vty old_thm new_thm é
	ABS vty old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(ABS_rule vty old_seq new_seq Ä
	(new_thy extends old_thy)) 
À
»
	‚INST_TYPE· : (string ã TYPE) ã THM ã THM ã bool
…
	É tysubs old_thm new_thm é
	INST_TYPE tysubs old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(INST_TYPE_rule tysubs old_seq new_seq Ä
	(new_thy extends old_thy)) 
À
»
	‚DISCH· : TERM ã THM ã THM ã bool
…
	É tm old_thm new_thm é
	DISCH tm old_thm new_thm =
	let old_seq = thm_seq old_thm in let old_thy = thm_thy old_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(DISCH_rule tm old_seq new_seq Ä
	(new_thy extends old_thy))
À
»
	‚MP· : THM ã THM ã THM ã bool
…
	É imp_thm ant_thm new_thm é
	MP imp_thm ant_thm new_thm =
	let imp_seq = thm_seq imp_thm in let imp_thy = thm_thy imp_thm
	in let ant_seq = thm_seq ant_thm in let ant_thy = thm_thy ant_thm
	in let new_seq = thm_seq new_thm in let new_thy = thm_thy new_thm
	in
	(MP_rule imp_seq ant_seq new_seq Ä
	(new_thy extends imp_thy) Ä (new_thy extends ant_thy))
À
\section{THE THEORY}
\section{SEMANTIC DOMAINS}
\begin{enumerate}
\item{}
Mono-types are sets (objects of type SET).
\item{}
A type variable assignment is a map from strings to Mono-types (SETS).
\item{}
A type constant assignment is a map from (string X SET list) to SET.
\item{}
Monomorphic individuals are elements of SET.
\item{}
Polmorphic values are maps from type variable assignments to Monomorphic values.
\item{}
A variable assignment is a map from string to polymorphic value.
\item{}
A constant assignment is a map from string to polymorphic value.
\end{enumerate}

\section{ISSUES}
\subsection{Changes to the Language}
I am strongly tempted to make some adjustments to the language.
The strongest temptation I have is to outlaw overloading of variable names.
This might be achieved by insisting that the following
predicate were satisfied either by the set of
all variables in a term, or less stringently by
the free variables of the term and of the body of every
ç-abstraction within it.

»
	consistent_vartypes: (string â TYPE ã bool) ã bool
…
	consistent_vartypes sts =
		É(s,t)(s',t')é sts (s,t) Ä sts (s',t') Ä (s = s')
			ä (t = t')
À

I am also tempted to have term formation rules which are independent of the theory environment (i.e. allow constants to be used before declaration).
Also to allow overloading of constants.
(rules for conservative extension permitting sets of constant definitions provided the types used are pairwise non-unifiable).
\subsection{Formalisation}
I would like to avoid having FAILure results on all functions which are not certain to succeed, but am not sure whether they can be avoided.
The reason is to keep the specification simple.
Where a function is normally used in circumstances when its arguments are known to be satisfactory, I think it is better to use a version which does not have failure codes in it.
To make this possible as consistently as possible I think functions with failure results should be used only where absolutely necessary.
This corresponds to programming in ML by checking with "is\_?" before doing "dest\_?" instead of going ahead regardless and then trapping the exception.
Trapping exceptions is easier in ML but more complicated in HOL.


\begin{FT}{}
% \input{holsyn.th.prt}
\end{FT}
\section{Index of Defined Terms}
\twocolumn
\printindex
\end{document}
