=TEX
\documentstyle[hol1,11pt,TQ]{article}
\ftlinepenalty=9999
\makeindex
\TPPproject{FST PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Detailed Design of Algebraic Normalisation Conversions}  %% Mandatory field
\TPPref{DS/FMU/IED/DTD081}  %% Mandatory field
\def\SCCSversion{$Revision$
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date$%
}}
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{SML Literate Script}
\TPPkeywords{}
%\TPPauthor{R.D.~Arthan & WIN01}  %% Mandatory field
\TPPauthors{R.D.~Arthan & WIN01\\K.~Blackburn & WIN01}
\TPPauthorisation{R.B.~Jones & FMU Manager}
\TPPabstract{This document contains the detailed design of conversions which
perform normalisation of monomials in a commutative and associative operator
and of polynomials in a pair of commutative and associative operators
one of which distributes over the other. Some associated functions of general
utility are also provided (such as facilities for creating ordering relations
on types and terms) as well as three applications of the polynomial normalisation
(namely, disjunctive and conjunctive normal forms for the propositional calculus
and a normalisation of arithmetic expressions over $+$ and $*$ analogous to
the procedure of ``multiplying out and collecting like terms'' of elementary
algebra).}
\TPPdistribution{\parbox[t]{4.0in}{%
	    Library
}}
\begin{document}
\makeTPPfrontpage
\vfill
\begin{centering}
\bf Copyright \copyright\ : International Computers Ltd \number\year
\end{centering}
\pagebreak
\section{Document control}
\subsection{Contents list}
\tableofcontents
\subsection{Document cross references}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes history} 
\begin{description}
\item[\SCCSversion~(\FormatDate{$Date$%
})] First draft (adapted from prototype implementation of \cite{DS/FMU/IED/SML023}) for comment.
\end{description}
\subsection{Changes forecast}
Error messages and numbers TBA.
\section{GENERAL}
\subsection{Scope}
This document contains the detailed design of part of the \ProductHOL\ system.
The document responds to \cite{DS/FMU/IED/HLD012}.
\subsection{Introduction}
\subsubsection{Purpose and Background}
Some proof procedures are facilitated if certain classes of term can
be brought into an appropriate normal form.
Some generally useful  classes are the class of
terms formed using a commutative and associative
operator and the class of terms formed using a pair of commutative and
associative operators one of which distributes over the other.
We will refer to normalisation for the former class as {\em monomial normalisation}
and for the latter as {\em polynomial normalisation}.

Informally, monomial normalisation is so natural as to feel trivial.
Given an expression
=INLINEFT
xâ1 + xâ2 + ... + xâk
=TEX
, in the commutative associate operator $+$, monomial normalisation amounts
to the observation that variant bracketing of the expression is irrelevant,
as is the order of the 
=INLINEFT
xâi
=TEX
. Thus, given an ordering on the
=INLINEFT
xâi
=TEX
, we may write the expression with the
=INLINEFT
xâi
=TEX
\ arranged in order and with the brackets arranged in the right-associative
fashion, say.
In \Product, this idea may be realised by a conversion, parameterised
by an ordering relation and by
theorems expressing the associativity and commutativity of the operator,
which given any expression over the operator will prove the theorem that
that expression is equal to one in the monomial normal form.

Similarly, the polynomial normalisation is just the usual ``multiplying out''
part of the process of ``multiplying out and collecting like terms'' which
is familiar from elementary algebra in the integers say.
Again, this may be realised in \Product\ as a conversion parameterised
by an ordering and by theorems about the two operators.

Useful extra generality may be obtained by adding additional parameters
to the normalisation conversions allowing them, for example, to evaluate
literal sub-expressions during the normalisation process. This is achieved
by having extra parameters which are conversions to be applied at selected
points during normalisation. ``Collecting like terms'' may be implemented
in this fashion, for example.

Many useful special effects can be achieved by adjusting the ordering
relation used on terms. For example, arranging for the immediate
successor of any boolean term $t$ is $≥t$ greatly simplifies elimination
of trivial conjuncts when the polynomial normalisation is used to find
conjunctive normal form. Consequently, we supply reasonably general
means for creating ordering relations on terms as part of the normalisation
tool-kit.
\subsubsection{Dependencies}
This document depends on the theory $basic\_hol$ defined in
\cite{DS/FMU/IED/DTD045} and on the tactics and rules of
\cite{DS/FMU/IED/DTD027,DS/FMU/IED/DTD029}.
\subsubsection{Algorithms}
These are described in the body of the document.
Some of the normalisation procedures involve sorting
which is done by two-way merge sorting
(see \cite{Knuth73}). Background information on
conjunctive and disjunctive normal forms may be found
in e.g. \cite{Manna74}. 
\subsubsection{Known Deficiencies}
The prototype version of this had asymmetric versions of the various
rewriting tools. These are not currently supplied since there is
no direct way of producing variants of the rewriting tools which only
differ from the standard ones in the choice of traversal strategy
(i.e. the conversional).
\subsubsection{Possible Enhancements}
A form of polynomial normalisation in which the ``multiplication''
is not required to be commutative could easily be provided if desired.

The prototype version exposed the merge part of the monomial
(sorting) conversion as a separate conversion. This has not been made
visible here for several reasons: (a) I cannot see what use it is;
(b) the parameterisation which is most natural and efficient in the
implementation is not nice for an end-user; and (c) if we wanted to use
a slicker sorting algorithm it would be annoying to have to supply part
of an earlier algorithm just in case someone had ever used it in its own
right. It would be fairly simple to expose the merge conversion if a case
for doing so can be made (although a user-friendly reparameterisation would
be in order).

It has been assumed in designing the interface that the user of the general
purpose interfaces (such as
=INLINEFT
sort_conv
=TEX
) will be fairly aware and prepared to read the manual. Thus positional
parameters (rather than labelled records) are used even though there are
quite a lot of them. This allows for a certain amount of partial evaluation
and is, perhaps, cleaner for the expert. More self-explanatory interfaces
could be supplied if desired.

\section{SIGNATURE}
=DOC 
signature €Normalisation› = sig
=DESCRIBE
This is the signature of a structure containing conversions for monomial
and polynomial term normalisation and related metalanguage functions.
=ENDDOC
\section{TERM ORDERING}
=DOC 
	val €type_order› : TYPE -> TYPE -> int;
=DESCRIBE
=INLINEFT
type_order
=TEX
\ gives a useful ordering relation HOL types. The ordering relation
follows the same conventions as those used
by the sorting function $sort$, namely,
=INLINEFT
type_order t1 t2
=TEX
\ is negative if $t1$ precedes $t2$, $0$ if $t1$ and $t2$ are
equivalent and positive if $t2$ precedes $t1$.
The ordering used is essentially that type variables are ordered by
the alphabetic ordering of their names and precede all compound types
which are ordered by the lexicographic ordering on their immediate
constituents (using the alphabetic ordering for the type constructor
names and the type ordering recursively for its operands).
=ENDDOC
=DOC 
	val €term_order› : TERM -> TERM -> int;
	val €gen_term_order› : (TERM -> (TERM * int)) -> TERM -> TERM -> int;
=DESCRIBE
=INLINEFT
term_order
=TEX
\ gives an ordering relation on HOL terms. The ordering relation
follows the same conventions as those used
by the sorting function $sort$, namely,
=INLINEFT
term_order t1 t2
=TEX
\ is negative if $t1$ precedes $t2$, $0$ if $t1$ and $t2$ are
equivalent and positive if $t2$ precedes $t1$.
The ordering used is, with two exceptions, that all constants precede all variables
which precede all abstractions which precede all applications.
Lexicographic ordering on the immediate constituents
gives the ordering within each of these four classes (using alphabetic
ordering of strings,
=INLINEFT
type_order
=TEX
\ or
=INLINEFT
term_order
=TEX
\ recursively to order the constituents as appropriate).
The exceptions are that any term of the form
=INLINEFT
≥t
=TEX
\ comes immediately after $t$ and that the numeric literals
=INLINEFT
0, 1, ...
=TEX
\ are taken in numeric rather than alphabetic order and come before all other
terms.

=INLINEFT
gen_term_order
=TEX
\ gives a slightly more general means of creating orderings on terms.
In the call
=INLINEFT
gen_term_order special
=TEX
, the idea is that whenever two terms, $tm1$ and $tm2$ say,
are compared, $special$ is applied to them to produce
two pairs, $(tm1,\,k1)$ and $(tm2,\,k2)$ say. These
pairs are then compared lexicographically (using the
ordering recursively for the first components).
It is the caller's responsibility to provide an argument $special$ which
will ensure that this procedure terminates.
A sufficient condition is only to use functions
$special$ with the property that for some
disjoint sets of terms $X_1$, $X_2$, \ldots, we have that
$special\,tm=(tm,\,0)$ if $tm \not\in X_i$ for any $i$
and that $special\,tm=(x_i,\,f_i tm)$ if $tm \in X_i$,
where $x_i$ is a fixed element of $X_i$ and $f_i$
is a fixed injection of $X_i$ into the natural numbers.
=ENDDOC
\section{ASYMMETRIC EQUATIONAL REASONING}
=DOC
	val €ASYM_C› : CONV -> CONV
	val €GEN_ASYM_C› : (TERM -> TERM -> int) -> CONV -> CONV
=DESCRIBE
These conversionals allow one to control the behaviour of a conversion
by making it asymmetric with respect to an ordering relation on terms
(in the sense that the resulting conversion will only prove theorems
of the form
=INLINEFT
t1 = t2
=TEX
\ in which $t2$ strictly precedes $t1$ in the ordering.

=INLINEFT
ASYM_C c
=TEX
\ is a conversion which behaves like $c$ on terms $t$ for which
=INLINEFT
c t
=TEX
\ is a theorem with conclusion
=INLINEFT
t = t1
=TEX
\ where $t1$ (strictly) precedes $t$ in the standard ordering on terms given by 
=INLINEFT
term_order
=TEX
q.v. and fails on other terms.

=INLINEFT
GEN_ASYM_C
=TEX
\ is like
=INLINEFT
ASYM_C
=TEX
\ but allows the ordering function used to be supplied as a parameter.
The parameter is interpreted as an ordering relation on terms
in the same sense as the ordering relations used by $sort$, q.v.
=ENDDOC
=DOC 
	val €sort_conv› : 
		(TERM -> TERM -> int) ->
		THM -> THM -> 
		CONV -> CONV ->
		CONV:
=DESCRIBE
This conversion normalises a term constructed from literals
using an associative and commutative binary operator,
$op$ say.
Here, by ``literal'' we mean any term which is not of the form
=INLINEFT
t1 op t2
=TEX
.
The theorems computed by the conversion have the form
=INLINEFT
t = tâ1 op tâ2 op ...
=TEX
, where the
=INLINEFT
tâi
=TEX
are in non-decreasing order with respect to the ordering on terms given
by the first parameter.

The associativity and commutativity of the operator are given as the two
theorem parameters (which are also used to infer what $op$ is; n.b. $op$
can be an arbitrary term, it need not be a constant).
The remaining parameters are conversions which are applied to each literal
as it is encountered and to each subterm of the form
=INLINEFT
t = tâi op ...
=TEX
\ as it is created.

In more detail the parameters are, in order, as follows:

\begin{enumerate}
\item
A term ordering, such as $term\_order$, q.v.
\item
A theorem of the form
=INLINEFT
Ù µx y∑t x y = t y x
=TEX
.
\item
A theorem of the form
=INLINEFT
Ù µx y z∑t(t x y) z = t y (t x z)
=TEX
.
(i.e. if the term $t$ is an infix operator, $op$ say:
=INLINEFT
Ù µx y z∑(x op y) op z = x op y op z
=TEX
).
\item
A conversion to be applied to each subterm of the form:
=INLINEFT
t = tâi op ...
=TEX
\ as it is created.
\item
A conversion to be applied to each literal as it is encountered.
\end{enumerate}

Note that either of the conversions supplied as parameters may introduce new non-literal
subterms. These are normalised recursively as they are produced.
Typically, however, these conversions are used just to simplify sub-terms.
=ENDDOC
=DOC 
	val €poly_conv› :
		(TERM -> TERM -> int) ->
		THM -> THM -> THM -> THM -> THM ->
		CONV -> CONV -> CONV ->
		CONV;
=DESCRIBE
This conversion normalises terms constructed from literals using two operators,
both associative and commutative, the second of which one, say
=INLINEFT
opâ*
=TEX
\ distributes over the other, say
=INLINEFT
opâ+
=TEX
.
Here, by ``literal'' we mean any term which is not of the form
=INLINEFT
t1 opâ+ t2
=TEX
\ or
=INLINEFT
t1 opâ* t2
=TEX
.
The theorems computed by the conversion have the form
=INLINEFT
t = tâ1 opâ+ tâ2 opâ+ ...
=TEX
, where the 
=INLINEFT
tâi
=TEX
are in non-decreasing order with respect to the ordering on terms given
by the first parameter and have the form
=INLINEFT
sâ1 opâ* sâ2 opâ* ...
=TEX
where the
=INLINEFT
sâi
=TEX
are literals and are in non-decreasing order.

The associativity and commutativity of the operators and the distributivity
are given as the five
theorem parameters (which are also used to infer what the two operators are;
n.b. the operators
can be arbitrary terms, they need not be constants).
The remaining parameters are conversions which are applied to each literal
as it is encountered and to each subterm of the form
=INLINEFT
t = tâi opâ+ ...
=TEX
\ or.
=INLINEFT
t = tâi opâ* ...
=TEX
\ as they are created.

In more detail the parameters are, in order, as follows:
\begin{enumerate}
\item
A term ordering, such as $term\_order$, q.v.
\item
A theorem of the form
=INLINEFT
Ù µx y∑x opâ+ y = y opâ+ x
=TEX
.
(n.b.
=INLINEFT
opâ+
=TEX
and
=INLINEFT
opâ*
=TEX
need not be infix constants, however, for clarity, we write them in
infix form here)
\item
A theorem of the form
=INLINEFT
Ù µx y z∑(x opâ+ y) opâ+ z = x opâ+ y opâ+ z
=TEX
.
\item
A theorem of the form
=INLINEFT
Ù µx y∑x opâ* y = y opâ* x
=TEX
.
\item
A theorem of the form
=INLINEFT
Ù µx y z∑(x opâ* y) opâ* z = x opâ* y opâ* z
=TEX
.
\item
A theorem of the form
=INLINEFT
Ù µx y z∑x opâ* (y opâ+ z) = (x opâ* y) opâ+ (x opâ* z)
=TEX
.
\item
A conversion to be applied to any subterm of the form
=INLINEFT
tâi opâ+ ...
=TEX
\ as it is created.
\item
A conversion to be applied to any subterm of the form
=INLINEFT
tâi opâ* ...
=TEX
\ as it is created.
\item
A conversion to be applied to any literal as it is encountered.
\end{enumerate}
Note that any of the conversions supplied as parameters may introduce new non-literal
subterms. These are normalised recursively as they are produced.
Typically, however, these conversions are used just to simplify sub-terms.

=ENDDOC
=DOC 
	val €cnf_conv› : CONV;
=DESCRIBE
This is a conversion which proves theorems of the form
=INLINEFT
Ù t1 § t2
=TEX
\ where $t2$ is in conjunctive normal form, i.e. either $T$ or $F$
or a conjunction of one or more disjunctions
in which each disjunct is a propositional literal. Here, by literal
we mean either a term whose principal connective is not a propositional
calculus connective or the negation of such a term.

The conversion simplifies disjunctions and conjunctions
as they are generated according to the following schema.
=GFT
a ≤ T	≠	T
T ≤ a	≠	T
F ≤ a	≠	a
a ≤ F	≠	a
a ≤ a	≠	a
a ≤ ≥a	≠	T
a ≤ T	≠	T
T ≤ a	≠	T
F ≤ a	≠	a
a ≤ F	≠	a
a ≤ a	≠	a
a ≤ ≥a	≠	T
≥T	≠	F
≥F	≠	T
=TEX

Note, however, that more global simplifications are not done,
e.g. there is no attempt to eliminate a conjunct all of whose constituent
literals are contained in another conjunct.
Thus, the conversion will not automatically prove tautologies.
=SEEALSO
=INLINEFT
strip_tac
=TEX
and
=INLINEFT
taut_rule
=TEX
\ which supply a more useful and efficient means for working with the propositional calculus
in most cases.
=ENDDOC
=DOC 
	val €dnf_conv› : CONV;
=DESCRIBE
This is a conversion which proves theorems of the form
=INLINEFT
Ù t1 § t2
=TEX
\ where $t2$ is in disjunctive normal form, i.e. either $T$ or $F$
or a disjunction of one or more conjunctions
in which each conjunct is a propositional literal. Here, by literal
we mean either a term whose principal connective is not a propositional
calculus connective or the negation of such a term.

The conversion simplifies disjunctions and conjunctions
as they are generated according to the following schema.
=GFT
a ≤ T	≠	T
T ≤ a	≠	T
F ≤ a	≠	a
a ≤ F	≠	a
a ≤ a	≠	a
a ≤ ≥a	≠	T
a ≤ T	≠	T
T ≤ a	≠	T
F ≤ a	≠	a
a ≤ F	≠	a
a ≤ a	≠	a
a ≤ ≥a	≠	T
≥T	≠	F
≥F	≠	T
=TEX

Note, however, that more global simplifications are not done,
e.g. there is no attempt to eliminate a disjunct all of whose constituent
literals are contained in another disjunct.
Thus, the conversion will not automatically prove tautologies.

=SEEALSO
=INLINEFT
strip_tac
=TEX
and
=INLINEFT
taut_rule
=TEX
\ which supply a more useful and efficient means for working with the propositional calculus
in most cases.
=ENDDOC


=DOC 
	val €anf_conv› : CONV;
=DESCRIBE
This is a conversion which proves theorems of the form
=INLINEFT
Ù t1 = t2
=TEX
\ where $t1$ is a term formed from literals of type Ó and
$t2$ is in what we may call additive normal form, i.e. it has the form:
=INLINEFT
t = tâ1 + tâ2 + ...
=TEX
, where the 
=INLINEFT
tâi
=TEX
have the form
=INLINEFT
sâ1 * sâ2 * ...
=TEX
where the
=INLINEFT
sâi
=TEX
are literals.
Here, by literal
we mean a term which is not of the form
=INLINEFT
tâ1 + tâ2 + ...
=TEX
or
=INLINEFT
sâ1 * sâ2 * ...
=TEX
.

The summands
=INLINEFT
tâi
=TEX
\ and,
within them,
the factors
=INLINEFT
sâi
=TEX
are given in increasing order with respect to the ordering
on terms given by the function 
=INLINEFT
term_order
=TEX
, q.v. Arithmetic computation is carried out on literals to ensure
that at most one of the summands is a numeric literal and that, within
each summand, at most one factor is a numeric literal. Any literal appears
at the beginning of its factor or summand and addition of $0$
or multiplication by $1$ is simplified out.
=ENDDOC
\section{EPILOGUE}
=SML
end (* of signature Normalisation *);
=TEX
\twocolumn[\section{INDEX}]
\small
\printindex
\end{document}

