% $Id$
=TEX
\documentstyle[hol1,11pt,TQ]{article}
\ftlinepenalty=9999
\makeindex
\TPPproject{FST PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Detailed Design of the Resolution Facilities}  %% Mandatory field
\TPPref{DS/FMU/IED/DTD067}  %% Mandatory field
\def\SCCSversion{$Revision$ %
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date$ %
}}
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{SML Literate Script}
\TPPkeywords{}
\TPPauthor{K.Blackburn & WIN01}
\TPPauthorisation{R.D. Arthan & FST Team Leader}
\TPPabstract{This document contains the detailed design
of the resolution facilities in ICL HOL.}
\TPPdistribution{\parbox[t]{4.0in}{%
	    Library
}}
\begin{document}
\makeTPPfrontpage
\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}
\pagebreak
\section{DOCUMENT CONTROL}
\subsection{Contents List}
\tableofcontents
\subsection{Document Cross References}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes History} 
\begin{description}
\item[Issue 1.1,1.2] 
First versions.
\end{description}
\subsection{Changes Forecast}
None known.
\pagebreak
\section{GENERAL}
\subsection{Scope}
Tools providing resolution
are called for in \cite{DS/FMU/IED/HLD012}.
This document provides a detailed design for these tools.
\subsection{Introduction}
\subsubsection{Purpose and Background}
This document contains a detailed design for the
resolution facilities in ICL HOL.

\cite{DS/FMU/IED/DTD028} and \cite{DS/FMU/IED/WRK031} discuss
the tactics provided for proving theorems of the predicate calculus
using the subgoal package. These tactics are complete, in the
sense that they allow proof of any theorem of the predicate calculus,
however they do not constitute a fully automated proof procedure,
in particular user-guidance is always required when an existential
witness has to be supplied or when a universally quantified
assumptions has to be specialised.

In the Cambridge HOL system a similar (but less uniform) suite
of tactics is provided augmented by a so-called ``resolution''
tactic (the basic form being called $RES\_TAC$), which is in fact just a means of increasing the stock
of assumptions essentially by looking for pairs of assumptions of the
form $A[t]$ and $µx·A[x]´B[x]$ and
using such a pair to add $B[t]$ to the stock of assumptions.

Experience indicates that many problems would be much easier
to solve if more powerful analogues of this ``resolution''
tactic were available. Desirable features would be:

\begin{itemize}
\item
reduced dependence on particular forms of assumptions, e.g.
an assumption of the form
$µx·B[x]²³A[x]$
should be treated uniformly with
$µx·A[x]´B[x]$;
\item
unification rather than just pattern matching (allowing particular
consequences of two universally quantified assumptions to be
drawn).
\end{itemize}

Both of these features are steps on the road to the provision
of a tactic which implements a complete proof procedure
for the predicate calculus using classical resolution or one of
its more recent derivatives (see \cite{Ramsay88} for a survey).
There is a large literature on such provers (some of which is
discussed in \cite{DS/FMU/IED/WRK010}). Perhaps the
biggest problem is to decide which of the many techniques to
choose, given that it is likely to take too long to implement
and compare different approaches exhaustively.

\subsubsection{Dependencies}
This document depends upon ???
of \cite{DS/FMU/IED/???}.
\subsubsection{Deficiencies}
None known.
\subsubsection{Possible Enhancements}
None known.
\section{METHODS AND ISSUES}
\subsection{Tactics or Inference Rules?}
There are two apparent ways to implement the primitive facilities.
The first is as an inference rule which take as inputs
collections of theorems.
The second is as a tactic, which manipulates a collection of theorems
and the current assumptions, halting either on solving the goal,
or some other criteria.

The difference is between a uniform treatment
of assumptions and input theorems,
against a special treatment, both have their advantages.
Once the primitive form is done, the alternative can be 
done in a derived form by pre- and postprocessing,
or use of, e.g. 
$tac\_proof$.
We choose an inference rule approach as uniformity between
assumption and theorem is considered more helpful than
the benefits of, say, the pre-existing $strip\_asm\_tac$
as the basis of a postprocessor,
in a system that would also handle multiple subgoals.
In particular $strip\_asm\_tac$ as a postprocessor of the results of each resolution would sometimes lead to case
splits on irrelevant results, causing the important
work to be duplicated.
\subsection{Modes of Use}
One difficulty in designing resolution facilities is the 
variety of different desired methods of use the facilities may have.
These differences can categorised as follows:

\paragraph{By what the input is} 
The possibilities for a tactic-based method include:
\begin{enumerate}
\item
All the current goal goals assumptions,
with no external input.
\item
All the current assumptions, and the (stripped?) negation of the 
current goal.
This could be implemented as a derived facility,
which would also do any necessary ``Set of Support'' book-keeping (see below).
\item
Take some theorems and work with both these and the current
assumptions.
Note that we can type instantiate external theorems, but
not assumptions.
\end{enumerate}
For an inference rule method we are just interested in either
a single list of theorems, or two lists, one of which is the ``Set of Support''

\paragraph{By what ``fairness'' there is between the inputs}
We could treat all inputs equally when searching for successful resolvents, but it is probably
better to work using the ``Set of Support'' paradigm.
This states that resolution will only be attempted when at least one of the two resolvents
is in the set of support.
In such a paradigm it is usual for the results of a resolution
to be added into the set of support
(we shall assume this is so in the first attempt).
Since making the entire of the inputs be considered the initial
set of support we include the ``fair'' option, we will choose
to have various methods of adding items into the set of support,
and always use this paradigm.

Further possibilities for search strategies include ``weighting'' assumptions for interest, e.g. preferring those that contain particular symbols,
or choosing by number of disjuncts (in particular, one disjunct).
This will not be attempted in the first attempt at the primitive tool.

Even when a general search strategy has been determined, the precise algorithm will still need to be fixed (e.g. which of two members of the set of support are chosen first).
This is a much less problematical area, and will be ``built-in'' in the first attempt.

A more sophisticated approach could be to use a technique analogous to discrimination nets.
This has each input entered in turn, and the entry may indicate possible resolution attempts with earlier entries, based on the
similarity of form that discrimination nets can indicate
quite rapidly.
This requires more advanced nets than those of rewriting, as
ideally they should handle two-way matches (i.e. full unification),
and should understand the difference between ``fixed'' variables and specialisable ones.
Entry into the net could also be combined with fragmenting a term into subterms based on understood connectives.

\paragraph{By what is done with the results of resolution}
These could be:
\begin{enumerate}
\item
Added back into the assumption list or set of working theorems (and probably the set of support),
\item
Stripped into the assumption list by $strip\_asm\_tac$ (for the tactic approach), or other simplification,
\item
Filtered in some manner before further processing,
for instance by a user-supplied routine to eliminate known useless assumptions, or by various subsumption filters.
Such user-supplied filters could take the current assumption
list or working theorem set as one of their arguments, to aid with subsumption checking, etc.
Notice that subsumption filters can be of various degrees of
completeness, at differing evaluation costs.
\item
Remembered and used in further reasoning, but some or all discarded when the resolution halts.
This includes various ``solve or fail'' approaches.
This could be done via a postprocessing tidying function.
\end{enumerate}
All of the above can be encoded in a tactic (if that is the approach taken) that takes a list of theorems, and is applied to the current goal, if
we assume inference is not deferred.

\paragraph{By the actual method of attempting to resolve two objects}
These vary from pattern matching to two-way unification with domain knowledge.
This includes doing Associative-Commutative
unification, or a special understanding of equality.
Only when handling theorems will this approach be
able to do type instantiation.
If we wish to treat some known operators equally,
we are likely to attempt to resolve the subterms that are 
combined by the operators to create the assumption or theorems
conclusion.

\paragraph{By what optimisations are used, and where}
We have already mentioned subsumption in filtering the results
of resolution: we could also discard pre-existing assumptions or theorems that
are fully subsumed by others (newly added or pre-existing) - this is called backward subsumption.
Boyer and Moore's work also includes ideas on heuristics for discarding
irrelevant assumptions.
This can be encoded in the same tactic as handles the results
of the resolution, if tactic there be.

\paragraph{By what halts the resolution}
This includes running out of things to do, solving some goal, deriving false, or hitting
some limit, such as number of resolutions, or the size of assumption list.
In fact, we can reasonably assume that proving false or the goal causes the function to always grinds to halt, it is other limits that are of interest.
In our first attempt we will assume that the problem is set up with any goal negated and present in the inputs, so that
we are always working towards proving false.

\paragraph{By what simplifications are done to the input}
We could choose to normalise, strip or do some lesser
simplification to both the initial assumptions and initial theorems.
We might also discard some of the inputs as irrelevant immediately.
These should be implemented as preprocessors for the primitive resolution facilities.

A pair of possible heuristics, inspired by the ICL HOL approach to rewriting, are that
type instantiation will only be done in resolution to theorems with no 
assumptions, and only outer universal quantifications will be
specialised. 
This places a one-off burden on the preprocessing to
handle inner quantification, free variables, and useful assumptions.
This is a more reasonable burden than full normalisation,
and is less likely to spoil the recognition of the origin of the results (it is often difficult for a user to equate a fully normalised term with its original).
We will only adopt the second heuristic in our first attempt
to provide a practical inference rule and pair of tactics.

Future developments, if time permits, might involve investigating
the use of matrix methods (see, e.g. \cite{Wallen90}) to improve
performance and the provision of unification procedures adapted
to particular problem domains (e.g. AC unification which
has been implemented for Cambridge HOL see \cite{Slind91}).

\subsection{Immediacy of Inference}
Something that is mostly an implementation issue, but may be
visible in the design is the question of whether the
actual inference is done on the fly, or whether
a description of the required proof steps is built up, and
only executed at the end.
This is particularly important in the ``solve or fail'' modes of use.
An analogous question also has bearing when results are often thrown away as irrelevant, as if we can create them by an approach faster than doing the actual
inference this might have significant speed gains.

Being able to display the required inference steps may
please some users:
and deferring the inference by certain means would make this easier.
\section{PREAMBLE}
=DOC
signature ÛResolutionÝ  = sig
=DESCRIBE
This is the signature of a structure providing Resolution
facilities to ICL HOL.
=ENDDOC
\section{UNIFICATION OF TERMS}
=IGN
 =DOC
val Ûtype_unifyÝ : (TYPE * TYPE OPT)list -> TYPE -> TYPE ->
	 (TYPE * TYPE OPT)list;
 =DESCRIBE
This is a method of unifying two types, in the context
of a partial mapping of type variables onto types.
If the input mapping maps a type variable onto $Nil$
then it may be instantiated as required,
if it maps the type variable onto some value
then the unification will treat the type variable as if it is this instantiation,
and otherwise the type variable may not be instantiated.
The result is the initial mapping, extended by the
newly required instantiations.

Type variables common to both input types are treated as equal.
 =FAILURE
67005	Cannot unify ?0 and ?1
67007	Cannot unify ?0 and ?1 as cannot instantiate ?2
67012	Cannot unify ?0 and ?1 as ?0 occurs in expansion of ?1
 =ENDDOC
=TEX
The following provides a way of unifying two subterms in the context of
limitations on both type instantiation and term specialisation.
=DOC
val Ûterm_unifyÝ : Unification.SUBS -> (TYPE list) -> (TERM list) ->
	(TERM * TERM list * TYPE list) * 
	(TERM * TERM list * TYPE list) -> 
	((TYPE * TYPE) list * (TERM * TERM) list) *
	((TYPE * TYPE) list * (TERM * TERM) list);
=DESCRIBE
This is a method of unifying two subterms in the context of
limitations on both type instantiation and term specialisation.
The $SUBS$ argument is a ``scatchpad'' for the type unifier.
The initial type list is a list of type variables to avoid in generating new names,
and the term list a list of term variables to likewise avoid.
The other two input arguments are each a tuple of:
a term to unify,
a list of variables in the term that may be specialised,
and a list of types for which instantiation is allowed.
If the two terms can be unified then it returns two
tuples, referring to each of the two input tuples.
The tuple is a list of type instantiations and a list of
term specialisations (after type instantiation).
=FAILURE
3007	?0 is not a term variable
3019	?0 is not a type variable
67005	Cannot unify ?0 and ?1
67006	Cannot unify ?0 and ?1 as cannot specialise ?2
67007	Cannot unify ?0 and ?1 as cannot instantiate ?2
67012	Cannot unify ?0 and ?1 as ?0 occurs in expansion of ?1
=ENDDOC
As a design error:
=FAILURE
67013	DESIGN ERROR: Encountered mapping to self of ?0
=TEX
\section{FORWARD RESOLUTION}
\subsection{A Primitive Resolution Rule}
=DOC
val Ûprim_resolution_ruleÝ : 
	(THM list -> THM list -> ('a list * 'a list * 'a list * 'b)) -> (* preprocessor *)
	('a -> 'a -> THM list) -> (* the resolver function *)
	((THM list * ('a list * 'a list * 'a list * 'b)) -> 
		(('a list * 'a list * 'a list * 'b) * bool)) -> (* postprocessor *)
	('a list * 'a list * 'a list * 'b -> THM list) -> (* extract results *)
	int -> (* maximum number of new theorems *)
	THM list -> (* input set of support theorems *)
	THM list -> (* input other theorems *)
	THM list;   (* final outcome *)
=DESCRIBE
$prim\_resolution\_rule$ $prep$ $reso$ $postp$ $extract$ $limit$
$sos$ $rest$ works as follows:
\begin{itemize}
\item
If any of the input theorems have $¬F®$ as a conclusion
then that theorem is returned as a singleton list.
\item
Evaluate $prep$ $sos$ $rest$, and set $(against,$ $tried,$ $toprocess,$ $dbdata))$ to this.
\item
Attempt resolutions, choosing the head of $toprocess$ against the head of $against$.
Commonly, the head of $toprocess$ should be the first fragment from the set of support, 
$against$ is all the non-set of support fragments, plus the head of $toprocess$,
and $tried$ is empty.
\item
When a resolution attempt returns a list of theorems, $res$,
(resolution failures should not occur, just $[]$),
then evaluate $postp$ $(against,$ $tried,$ $toprocess,$ $dbdata)$ to 
extract the same, and $halt$.
In addition, add the length of $res$ to the sum of new theorems
so far, and compared with $limit$.
It is up to the postprocessor to move the head of $against$ either to $tried$ or just thrown away.
\item
If $limit$ has been reached or exceeded,
$halt$ is true (e.g. have proved $... ô F$),
or the $toprocess$ list is empty then return as a result of the call $extract$ $(against,$ $tried,$ $toprocess,$ $dbdata)$.
\item
If $limit$ is not exceeded, then continue with the new data.
If $against$ is $[]$ then the head of $toprocess$ is dropped, the new head cons'd to $done$ and $against$ is set to $done$ reversed, and then $done$ set to [].
\end{itemize}
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
67010	Postprocessor corrupted processing
=ENDDOC
Notice the following about $prim\_resolution\_rule$:
\begin{itemize}
\item
The genericity $:'a list * 'b$ allows, e.g., the preprocessing to make one entry
per subterm of the theorem, and keep a list of actual theorems as well.
\item
From the initialisation of the $hwm$ the set of support strategy will always be followed
(though in only its simplest form).
\item
The limit includes new theorems which are discarded by the postprocessor
(this is a problem with the generic nature of the primitive
rule).
\item
If the postprocessor does backwards subsumption, etc, it must
recalculate the current index and high water mark.
\item
If the resolver is not symmetric
(the resulting lists has the same members, but perhaps different ordering for either way round of argument) then some valid resolution attempts won't
be scheduled.
\end{itemize} 

\subsection{A Basic Resolution Tool Kit}
The following provides one way of filling in the arguments
to the above function.
It lacks sophistication in some areas: e.g. in deferring
inference.
=DOC
type ÛBASIC_RES_TYPEÝ 	(* TERM * bool * TERM list * TYPE list * THM 
	* TERM list * TYPE list *);
type ÛRES_DB_TYPEÝ (* = BASIC_RES_TYPE list * BASIC_RES_TYPE list *
	BASIC_RES_TYPE list * THM list *);
=DESCRIBE
These are type abbreviation for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
The arguments to $BASIC\_RES\_TYPE$ are:
\begin{enumerate}
\item
The term is a subterm of the theorem argument(5), 
reached through outer universal quantifications and
all propositional connectives.
\item
The bool is false if and only if the subterm occurs ``negatively'' in the conclusion of the theorem.
\item
The term list is the specialisable variables of the subterm.
\item
The type list is the instantiable type variables of the subterm.
\item
The theorem is the source of the fragment.
\item
The next term list is the term variables that may not be used
in unifying the fragment
\item
The next type list is the type variables that may not be used
in unifying the fragment
\end{enumerate}
The arguments to $RES\_DB\_TYPE$:
\begin{enumerate}
\item
Items yet to be checked against.
\item
Items checked against, but to be rechecked against new items to check with.
\item
Items to check with.
\item
Theorems used to derive current items.
\end{enumerate}
=ENDDOC
=DOC
val Ûfragment_termÝ : TERM -> (TERM * bool * TERM list) list * TERM list;
=DESCRIBE
This function fragments a term into subterms with no propositional
connections, with the boolean indicating a positive position within the original term if true,
negative otherwise,
and any variables that are bound in the position of the subterm (except for outer universals).
It will also return any propositional fragments that are within inner bindings, but have no bound variables,
in addition to the binding term itself.
The second list is of the outer universal quantified variables (which may be paired in the original term).
=EXAMPLE
fragment_term ¬µ a · a ± ³ b ´ (µ e · e ± c) ± f d® =
	([(¬a®,false,[]), (¬b®,true,[]), 
	(¬µ e · e ± c®,true,[]), 
	 (¬c®,true,[¬e®]), (¬f d®, true,[])],
	[¬a®])
=TEX
=USES
In implementing $basic\_res\_pre$ and $basic\_res\_post$
=ENDDOC
=DOC
val Ûbasic_res_subsumptionÝ : THM -> THM -> int;
=DESCRIBE
This returns $1$ if the conclusion of the first theorem equals
the second's, or is
a less general form than the second
(i.e. could be produced only by specialising the second theorem).
It returns $2$ if the second theorem's conclusion 
is a less general form than the first,
and otherwise returns $0$.
=ENDDOC
A more general redundancy test than $basic\-\_pre\-\_subsumption$ should be written when the other
basic mechanisms are in place,
as it is rather weak.
In particular noticing that one conclusion is the succedent or disjunct of
another would be helpful.
Another test would be for simple reordering of quantifiers.
The resolution process generating the newly inserted theorem could give hints here.
=DOC
val Ûbasic_res_preÝ : THM list -> THM list -> RES_DB_TYPE;
=DESCRIBE
This is the preprocessor for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
The first argument is the set of support theorems,
the second argument is the rest of the input theorems.
Each theorem will be stripped of universal quantifiers, and then fragmented (via $fragment\_term$), and each fragment
added to the appropriate list
(i.e. to the third list if set of support,
and the first list if otherwise).
The theorem list part of the result is just the appending of the first list of theorems to the second.
=ENDDOC
We could do, e.g., $basic\_res\_subsumption$ on each pair of theorems before adding any.
=DOC
val Ûbasic_resolve_ruleÝ: TERM -> THM -> THM -> THM;
=DESCRIBE
$basic\_resolve\_rule$ $subterm$ $pos$ $neg$
attempts to resolve two theorems
that have a common subterm, $subterm$, occurring ``positively'' in $pos$
and ``negatively'' in $neg$.
=FRULE 1 Rule
basic_resolve_rule
subterm
÷
 ô P [subterm]
 ô N [subterm]
÷
simplify (,  ô P[F] ² N[T])
=TEX
Where $simplify$ carries out the simplifications in the predicate calculus where an argument is the constant $¬T®$ or $¬F®$,
plus a few others.
=FAILURE
3031	?0 is not of type ¬:BOOL®
67009	?0 is not a subterm of ?1
=ENDDOC
This is implemented via $²\_elim$.
=DOC
val Ûbasic_res_resolverÝ : Unification.SUBS -> BASIC_RES_TYPE -> BASIC_RES_TYPE -> THM list;
=DESCRIBE
This is the resolver for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
Resolution seeks to find sufficient term specialisation
and type instantiation on both terms to make one of the two term fragments the negation of the other,
using $term\_unify$.
If this can be done then the two original theorems are 
specialised and instantiated in the same manner and the term fragment cancelled by $basic\-\_resolve\-\_rule$,
and the result returned as a singleton list.
Prior to being returned, any allowed universal quantification
will be added back in.
In the basic resolution tool the generality of a list of theorems is unnecessary.

The $SUBS$ argument is a ``scatchpad'' for the type unifier.
=FAILURE
67001	Neither argument is in the set of support
67002	Cannot resolve the two arguments
67008	term_unify succeeded on ?0 and ?1 but failed to resolve ?2 and ?3
=FAILUREC
Message is a variant on 67002, included for diagnostic purposes.
It will be removed in a more stable product.
=ENDDOC
The returned theorem could also be re-universally quantified,
either just by $all\_µ\_intro$, or more intelligently.
=DOC
val Ûbasic_res_postÝ : 
	(THM -> THM -> int) ->
	THM list * RES_DB_TYPE -> 
	(RES_DB_TYPE * bool);
=DESCRIBE
This is the post processor for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
The results will be split into their respective conjuncts
(if any).
Then
$basic\_res\_post$ $subsum$ $(res,$ $data)$
will test each member of $res$, checking for the conclusion $T$ or $F$, and then against each member of the theorem list of $data$.
In checking one theorem against another 
it will use $subsum$ - discarding the new theorem if the result is $1$,
and discarding (with tidying up of $data$)
the original if the result is $2$,
or keeping both (except for discards from further tests)
if the result is $0$, or any other value bar $1$ and $2$.
=ENDDOC
=DOC
val Ûbasic_res_extractÝ : RES_DB_TYPE -> THM list;
=DESCRIBE
This is the extraction function for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
It does no more than return the second argument.
=ENDDOC
Some one-off subsumption checks could be placed in this rule,
rather than $basic\_res\_post$.
\subsection{Derived Resolution Tools}
=DOC
val Ûbasic_resolution_ruleÝ : int -> THM list -> THM list ->
	THM list;
=DESCRIBE
$basic\_resolution\_rule$ $limit$ $sos$ $rest$ will 
resolve the theorems in the set of support and the rest
against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will belong to the set of support, or be derived from
an earlier resolution in the evaluation.
Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation where necessary and allowed.
Duplicates and pure specialisations in the resulting list will be discarded.

If any of the input theorems have $¬F®$ as a conclusion
then that theorem is returned as a singleton list.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
The implementation of this function is primarily by combining
the above bits.
Roughly:
=GFTSHOW Defn
fun basic_resolution_rule limit sos rest = 
	prim_resolution_rule 
		basic_res_pre
		(basic_res_resolver (new_subs 100))
		(basic_res_post basic_res_subsumption)
		basic_res_extract
		limit
		sos
		rest;
=TEX
=DOC
val ÛBASIC_RESOLUTION_TÝ : int -> THM list -> (THM -> TACTIC) -> 
	(THM -> TACTIC) -> TACTIC;
=DESCRIBE
$BASIC\_RESOLUTION\_T$ $limit$ $thms$ $thmtac1$ $thmtac2$ $(asms, conc)$
will first apply $thmtac1$ to the negated goal,
probably adding it into the assumption list in some manner.
The assumptions derived from this will become the set of support,
the pre-existing assumptions and the input $thms$ will be
 the rest of the theorems.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will be assumed fragments from the stripped goal, or be derived from
an earlier resolution in the evaluation.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The resulting list of theorems will have all the $thms$ removed,
all the theorems derived from stripping and negating the 
goal,
and all the old assumptions removed.
$MAP\_EVERY$ $thmtac$ is then applied to the new theorems,
and then to the goal.
As a special case, $...ô\ F$ is checked for, before any
further processing.
If present it will be used to prove the goal.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
This is $basic\_resolution\_rule$ with some pre- and postprocessing.
=DOC
val ÛBASIC_RESOLUTION_T1Ý : int -> THM list -> (THM -> TACTIC) ->
	TACTIC;
=DESCRIBE
$BASIC\_RESOLUTION\_T1$ $limit$ $thms$ $thmtac$ $(asms, conc)$
will take the theorems gained by $asm\_rule$'ing the assumptions and $thms$ as inputs.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will be from the original goals assumptions, or be derived from
an earlier resolution in the evaluation.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The resulting list of theorems will have all the $thms$ removed,
and all the old assumptions removed.
$MAP\_EVERY$ $thmtac$ is then applied to the new theorems,
and then to the goal.
As a special case, $...ô\ F$ is checked for, before any
further processing.
If present it will be used to prove the goal.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
=DOC
val Ûbasic_resolution_tacÝ : int -> THM list ->
	TACTIC;
=DESCRIBE
$basic\_resolution\_tac$ $limit$ $thms$ $(asms, conc)$
will first strip the negated goal into the assumption list.
This uses $strip\_tac$, except that the negation
is pushed through all the outer universals.
The assumptions derived from this will become the set of support,
the pre-existing assumptions and the input $thms$ will be
 the rest of the theorems.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will be assumed fragments from the stripped goal, or be derived from
an earlier resolution in upon those fragments.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The resulting list of theorems will have all the $thms$ removed,
all the theorems derived from stripping and negating the 
goal removed, 
and all the old assumptions removed.
$MAP\_EVERY$ $strip\_asm\_tac$ is then applied to the new theorems,
and then to the goal.
As a special case, $...ô\ F$ is checked for, before any
further processing.
If present it will be used to prove the goal.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
This is $basic\_resolution\_rule$ with some pre- and postprocessing.
=DOC
val Ûbasic_resolution_tac1Ý : int -> THM list ->
	TACTIC;
=DESCRIBE
$basic\_resolution\_tac1$ $limit$ $thms$ $(asms, conc)$
will take the theorems gained by $asm\_rule$'ing the assumptions and $thms$ as inputs.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will be from the original goals assumptions, or be derived from
an earlier resolution in the evaluation.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The resulting list of theorems will have all the $thms$ removed,
and all the old assumptions removed.
$MAP\_EVERY$ $strip\_asm\_tac$ is then applied to the new theorems,
and then to the goal.
As a special case, $...ô\ F$ is checked for, before any
further processing.
If present it will be used to prove the goal.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
This is $basic\_resolution\_rule$ with some pre- and postprocessing.
=DOC
val Ûbasic_resolution_tac2Ý : int -> THM list ->
	TACTIC;
=DESCRIBE
$basic\_resolution\_tac2$ $limit$ $thms$ $(asms, conc)$
will first strip the negated goal into the assumption list.
This uses $strip\_tac$, except that the negation
is pushed through all the outer universals.
The assumptions derived from this will become the set of support,
the pre-existing assumptions and the input $thms$ will be
 the rest of the theorems.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will be assumed fragments from the stripped goal, or be derived from
an earlier resolution in upon those fragments.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The tactic will fail unless the resulting list of theorems contains $...ô\ F$.
If present it will be used to prove the goal.
=FAILURE
67003	The limit, ?0, must be a positive integer
67014	Failed to prove goal
=ENDDOC
=DOC
val Ûbasic_resolution_tac3Ý : int -> THM list ->
	TACTIC;
=DESCRIBE
$basic\_resolution\_tac3$ $limit$ $thms$ $(asms, conc)$
will take the theorems gained by $asm\_rule$'ing the assumptions and $thms$ as inputs.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will be from the original goals assumptions, or be derived from
an earlier resolution in the evaluation.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The tactic will fail unless the resulting list of theorems contains $...ô\ F$.
If present it will be used to prove the goal.
=FAILURE
67003	The limit, ?0, must be a positive integer
67014	Failed to prove goal
=ENDDOC

\section{EPILOGUE}
=SML
end; (* of signature Resolution *)
=TEX
\twocolumn[\section{INDEX}]
\small
\printindex
\end{document}


