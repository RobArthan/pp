% $Id$
=TEX
\documentstyle[hol1,11pt,TQ]{article}
\ftlinepenalty=9999
\makeindex
\TPPproject{FST PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Detailed Design of the Resolution Facilities}  %% Mandatory field
\TPPref{DS/FMU/IED/DTD067}  %% Mandatory field
\def\SCCSversion{$Revision$ %
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date$ %
}}
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{SML Literate Script}
\TPPkeywords{}
\TPPauthor{K.Blackburn & WIN01}
\TPPauthorisation{R.D. Arthan & FST Team Leader}
\TPPabstract{This document contains the detailed design
of the resolution facilities in ICL HOL.}
\TPPdistribution{\parbox[t]{4.0in}{%
	    Library
}}
\begin{document}
\makeTPPfrontpage
\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}
\pagebreak
\section{DOCUMENT CONTROL}
\subsection{Contents List}
\tableofcontents
\subsection{Document Cross References}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes History} 
\begin{description}
\item[Issue 1.1] 
First version.
\end{description}
\subsection{Changes Forecast}
None known.
\pagebreak
\section{GENERAL}
\subsection{Scope}
Tools providing resolution
are called for in \cite{DS/FMU/IED/HLD012}.
This document provides a detailed design for these tools.
\subsection{Introduction}
\subsubsection{Purpose and Background}
This document contains a detailed design for the
resolution facilities in ICL HOL.

\cite{DS/FMU/IED/DTD028} and \cite{DS/FMU/IED/WRK031} discuss
the tactics provided for proving theorems of the predicate calculus
using the subgoal package. These tactics are complete, in the
sense that they allow proof of any theorem of the predicate calculus,
however they do not constitute a fully automated proof procedure,
in particular user-guidance is always required when an existential
witness has to be supplied or when a universally quantified
assumptions has to be specialised.

In the Cambridge HOL system a similar (but less uniform) suite
of tactics is provided augmented by a so-called ``resolution''
tactic (the basic form being called $RES\_TAC$), which is in fact just a means of increasing the stock
of assumptions essentially by looking for pairs of assumptions of the
form $A[t]$ and $µx·A[x]´B[x]$ and
using such a pair to add $B[t]$ to the stock of assumptions.

Experience indicates that many problems would be much easier
to solve if more powerful analogues of this ``resolution''
tactic were available. Desirable features would be:

\begin{itemize}
\item
reduced dependence on particular forms of assumptions, e.g.
an assumption of the form
$µx·B[x]²³A[x]$
should be treated uniformly with
$µx·A[x]´B[x]$;
\item
unification rather than just pattern matching (allowing particular
consequences of two universally quantified assumptions to be
drawn).
\end{itemize}

Both of these features are steps on the road to the provision
of a tactic which implements a complete proof procedure
for the predicate calculus using classical resolution or one of
its more recent derivatives (see \cite{Ramsay88} for a survey).
There is a large literature on such provers (some of which is
discussed in \cite{DS/FMU/IED/WRK010}). Perhaps the
biggest problem is to decide which of the many techniques to
choose, given that it is likely to take too long to implement
and compare different approaches exhaustively.

\subsubsection{Dependencies}
This document depends upon ???
of \cite{DS/FMU/IED/???}.
\subsubsection{Deficiencies}
None known.
\subsubsection{Possible Enhancements}
None known.
\section{METHODS AND ISSUES}
\subsection{Tactics or Inference Rules?}
There are two apparent ways to implement the primitive facilities.
The first is as an inference rule which take as inputs
collections of theorems.
The second is as a tactic, which manipulates a collection of theorems
and the current assumptions, halting either on solving the goal,
or some other criteria.

The difference is between a uniform treatment
of assumptions and input theorems,
against a special treatment, both have their advantages.
Once the primitive form is done, the alternative can be 
done in a derived form by pre- and postprocessing,
or use of, e.g. 
$tac\_proof$.
We choose an inference rule approach as uniformity between
assumption and theorem is considered more helpful than
the benefits of, say, the pre-existing $strip\_asm\_tac$
as the basis of a postprocessor,
in a system that would also handle multiple subgoals.
\subsection{Modes of Use}
One difficulty in designing resolution facilities is the 
variety of different desired methods of use the facilities may have.
These differences can categorised as follows:

\paragraph{By what the input is} 
The possibilities for a tactic-based method include:
\begin{enumerate}
\item
All the current goal goals assumptions,
with no external input.
\item
All the current assumptions, and the (stripped?) negation of the 
current goal.
This could be implemented as a derived facility,
which would also do any necessary ``Set of Support'' book-keeping (see below).
\item
Take some theorems and work with both these and the current
assumptions.
Note that we can type instantiate external theorems, but
not assumptions.
\end{enumerate}
For an inference rule method we are just interested in either
a single list of theorems, or two lists, one of which is the ``Set of Support''

\paragraph{By what ``fairness'' there is between the inputs}
We could treat all inputs equally when searching for successful resolvents, but it is probably
better to work using the ``Set of Support'' paradigm.
This states that resolution will only be attempted either
within the set of support, or by one of the two resolvents
being in the set of support.
In such a paradigm it is usual for the results of a resolution
to be added into the set of support
(we shall assume this is so in the first attempt).
Since making the entire of the inputs be considered the initial
set of support we include the ``fair'' option, we will choose
to have various methods of adding items into the set of support,
and always use this paradigm.

Further possibilities for search strategies include ``weighting'' assumptions for interest, e.g. preferring those that contain particular symbols,
or choosing by number of disjuncts.
This will not be attempted in the first attempt at the primitive tool.

Even when a general search strategy has been determined, the precise algorithm will still need to be fixed (e.g. which of two members of the set of support are chosen first).
This is a much less problematical area, and will be ``built-in'' in the first attempt.

A more sophisticated approach could be to use a technique analogous to discrimination nets.
This has each input entered in turn, and the entry may indicate possible resolution attempts with earlier entries, based on the
similarity of form that discrimination nets can indicate
quite rapidly.
This requires more advanced nets than those of rewriting, as
ideally they should handle two-way matches (i.e. full unification),
and should understand the difference between ``fixed'' variables and specialisable ones.
Entry into the net could also be combined with fragmenting a term into subterms based on understood connectives.

\paragraph{By what is done with the results of resolution}
These could be:
\begin{enumerate}
\item
Added back into the assumption list or set of working theorems (and probably the set of support),
\item
Stripped into the assumption list by $strip\_asm\_tac$ (for the tactic approach), or other simplification,
\item
Filtered in some manner before further processing,
for instance by a user-supplied routine to eliminate known useless assumptions, or by various subsumption filters.
Such user-supplied filters could take the current assumption
list or working theorem set as one of their arguments, to aid with subsumption checking, etc.
Notice that subsumption filters can be of various degrees of
completeness, at differing evaluation costs.
\item
Remembered and used in further reasoning, but some or all discarded when the resolution halts.
This includes various ``solve or fail'' approaches.
This could be done via a postprocessing tidying function.
\end{enumerate}
All of the above can be encoded in a tactic (if that is the approach taken) that takes a list of theorems, and is applied to the current goal, if
we assume inference is not deferred.

\paragraph{By the actual method of attempting to resolve two objects}
These vary from pattern matching to two-way unification.
This includes doing Associative-Commutative
unification, or a special understanding of equality.
Only when handling theorems will this approach be
able to do type instantiation.
If we wish to treat some known operators equally,
we are likely to attempt to resolve the subterms that are 
combined by the operators to create the assumption or theorems
conclusion.

\paragraph{By what optimisations are used, and where}
We have already mentioned subsumption in filtering the results
of resolution: we could also discard pre-existing assumptions or theorems that
are fully subsumed by others (newly added or pre-existing) - this is called backward subsumption.
Boyer and Moore's work also includes ideas on heuristics for discarding
irrelevant assumptions.
This can be encoded in the same tactic as handles the results
of the resolution, if tactic there be.

\paragraph{By what halts the resolution}
This includes running out of things to do, solving some goal, deriving false, or hitting
some limit, such as number of resolutions, or the size of assumption list.
In fact, we can reasonably assume that proving false or the goal is always grinds to halt, it is other limits that are of interest.
In our first attempt we will assume that the problem is set up with any goal negated and present in the inputs, so that
we are always working towards proving false.

\paragraph{By what simplifications are done to the input}
We could choose to normalise, strip or do some lesser
simplification to both the initial assumptions and initial theorems.
We might also discard some of the inputs as irrelevant immediately.
These should be implemented as preprocessors for the primitive resolution facilities.

A possible two heuristics, inspired by the ICL HOL approach to rewriting, are that
type instantiation will only be done in resolution to theorems with no 
assumptions, and only outer universal quantifications will be
specialised. 
This places a one-off burden on the preprocessing to
handle inner quantification, free variables, and useful assumptions.
This is a more reasonable burden than full normalisation,
and is less likely to spoil the recognition of the origin of the results (it is often difficult for a user to equate a fully normalised term with its original).
We will only adopt the second heuristic in our first attempt
to provide a practical inference rule and pair of tactics.

Future developments, if time permits, might involve investigating
the use of matrix methods (see, e.g. \cite{Wallen90}) to improve
performance and the provision of unification procedures adapted
to particular problem domains (e.g. AC unification which
has been implemented for Cambridge HOL see \cite{Slind91}).

\subsection{Immediacy of Inference}
Something that is mostly an implementation issue, but may be
visible in the design is the question of whether the
actual inference is done on the fly, or whether
a description of the required proof steps is built up, and
only executed at the end.
This is particularly important in the ``solve or fail'' modes of use.
An analogous question also has bearing when results are often thrown away as irrelevant, as if we can create them by an approach faster than doing the actual
inference this might have significant speed gains.

Being able to display the required inference steps may
please some users:
and deferring the inference by certain means would make this easier.
\section{PREAMBLE}
=DOC
signature ÛResolutionÝ  = sig
=DESCRIBE
This is the signature of a structure providing Resolution
facilities to ICL HOL.
=ENDDOC
\section{THE PRIMITIVE RULE}
=DOC
val Ûprim_resolution_ruleÝ : 
	(THM list -> THM list -> ('a list * 'b)) ->
		(* preprocessor *)
	('a -> 'a -> THM list) ->
		(* the resolver function *)
	((THM list * ('a list * 'b) * int * int) -> 
		(('a list * 'b) * int * int * bool)) ->
		(* postprocessor *)
	('a list * 'b -> THM list) -> (* extract results *)
	int -> (* maximum number of new theorems *)
	(THM list) -> (* input set of support theorems *)
	(THM list) -> (* input other theorems *)
	(THM list);   (* final outcome *)
=DESCRIBE
$prim\_resolution\_rule$ $prep$ $reso$ $postp$ $extract$ $limit$
$sos$ $rest$ works as follows:
\begin{itemize}
\item
Evaluate $prep$ $sos$ $rest$, and set $(dblist,$ $dbdata)$ to this.
\item
Attempt resolutions, based on a high water mark, $hwm$.
The function
matches members of the $dblist$ indexed by $ind$, running from 1 to $hwm$ to that indexed by $hwm$ itself, and then incrementing $hwm$ when it is reached by $ind$, and starting with $ind$ of 1 again.
$hwm$ is also initially $1$.
The high water mark item will be the first argument, allowing some partial evaluation.
\item
When a resolution attempt returns a non-nil list of theorems, $res$,
(resolution failures and results $[]$ are treated alike),
then evaluate $postp$ $(res,$ $(dblist,$ $dbdata)$ $ind,$ $hwm)$ to 
extract the $(dblist,$ $dbdata)$, $ind$, $hwm$ and $halt$.
In addition, add the length of $res$ to the sum of new theorems
so far, and compared with $limit$.
\item
If $limit$ has been reached or exceeded,
$halt$ is true (e.g. have proved $... ô F$),
or the high water mark and index are both the length of $dblist$, then return as a result of the call $extract$ $(dblist,$ $dbdata)$.
\item
If $limit$ is not exceeded, then continue with the new $(dblist,$ $dbdata)$, $ind$ and $hwm$.
\end{itemize}
=ENDDOC
Notice the following about $prim\_resolution\_rule$:
\begin{itemize}
\item
The genericity $:'a list * 'b$ allows, e.g., the preprocessing to make one entry
per subterm of the theorem, and keep a list of actual theorems as well.
\item
It is up to the preprocessor to indicate membership of the set of support in its result, and up to the resolver to immediately fail if neither argument in set of support.
\item
The limit includes new theorems which are discarded by the postprocessor
(this is a problem with the generic nature of the primitive
rule).
\item
If the postprocessor does backwards subsumption, etc, it must
recalculate the current index and high water mark.
\item
If the resolver is not symmetric
(the resulting lists has the same members, but perhaps different ordering for either way round of argument) then some valid resolution attempts won't
be scheduled.
\end{itemize} 
\section{A BASIC RESOLUTION TOOL KIT}
The following provides one way of filling in the arguments
to the above function.
It lacks sophistication in some areas: e.g. in deferring
inference.
=DOC
type ÛBASIC_RES_TYPEÝ 	(* bool * TERM * TERM list * TYPE list * THM *);
=DESCRIBE
This is a type abbreviation for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
The $bool$ is true if the theorem is in the set of support,
the term is a subterm of the theorem argument, reached through outer universal quantifications and
all propositional connectives,
except a single $³$ if the subterm occurs ``negatively'' in the conclusion of the theorem.
The term list is the specialisable variables of the subterm.
The type list is the instantiable type variables of the subterm.
=ENDDOC
=DOC
val Ûfragment_termÝ : TERM -> TERM list;
=DESCRIBE
This function fragments a term into subterms with no propositional
connections, except a single negative if it occurs ``negatively'' in the original term.
=EXAMPLE
fragment_term ¬a ± ³ b ´ c ± f d® =
	[¬³ a®, ¬b®, ¬c®, ¬f d®]
=TEX
=USES
In implementing $basic\_res\_pre$ and $basic\_res\_post$
=ENDDOC
=DOC
val Ûbasic_res_subsumptionÝ : THM -> THM -> int;
=DESCRIBE
This returns $1$ if the conclusion of the first theorem equals
the second's, or is
a less general form than the second
(i.e. could be produced only by specialising the second theorem).
It returns $2$ if the second theorem's conclusion 
is a less general form than the first,
and otherwise returns $0$.
=ENDDOC
A more general redundancy test than $basic\-\_pre\-\_subsumption$ should be written when the other
basic mechanisms are in place,
as it is rather weak.
In particular noticing that one conclusion is the succedent or disjunct of
another would be helpful.
The resolution process generating the newly inserted theorem could give hints here.
=DOC
val Ûbasic_res_preÝ : THM list -> THM list -> BASIC_RES_TYPE list * THM list;
=DESCRIBE
This is the preprocessor for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
The first argument is the set of support theorems,
the second argument is the rest of the input theorems.
Each theorem will be checked against those already
added with $basic\-\_res\-\_subsumption$, and if OK stripped of universal quantifiers, and then fragmented (by $fragment\_term$), and for each fragment
the appropriate item added to the resulting list
(i.e. whether it came from the set of support,
the fragment, the list of specialisable variables of the fragment, the list of instantiable type variables and the originating theorem).
The second part of the result is just the appending of the first list of theorems to the second.
=ENDDOC
=DOC
val Ûterm_unifyÝ : (TERM * TERM list * TYPE list) * 
	(TERM * TERM list * TYPE list) -> 
	((TYPE * TYPE) list * (TERM * TERM) list) *
	((TYPE * TYPE) list * (TERM * TERM) list);
=DESCRIBE
The two input arguments are each a tuple of:
a term to unify,
a list of variables in the term that may be specialised,
and a list of types for which instantiation is allowed.
If the two terms can be unified then it returns two
tuples, referring to each of the two input tuples.
The tuple is a list of type instantiations and a list of
term specialisations.
=FAILURE
67005	Cannot unify ?0 and ?1
67006	Cannot unify ?0 and ?1 as cannot specialise ?2
67007	Cannot unify ?0 and ?1 as cannot instantiate ?2
=ENDDOC
=DOC
val Ûbasic_res_resolverÝ : BASIC_RES_TYPE -> BASIC_RES_TYPE -> THM list;
=DESCRIBE
This is the resolver for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
It will fail if neither argument is in the set of support.
It will also fail if resolution doesn't work!
Resolution seeks to find sufficient term specialisation
and type instantiation on both terms to make one of the two term fragments the negation of the other,
using $term\_unify$.
If this can be done then the two original theorems are 
specialised and instantiated in the same manner and the term fragment cancelled,
and the result returned as a singleton list.
Prior to being returned, any allowed universal quantification
will be added back in.
In the basic resolution tool the generality of a list of theorems is unnecessary.
=FAILURE
67001	Neither argument is in the set of support
67002	Cannot resolve the two arguments
67008	term_unify succeeded on ?0 and ?1 but failed to resolve ?2 and ?3
=FAILUREC
Message is a variant on 67002, included for diagnostic purposes.
It will be removed in a more stable product.
=ENDDOC
=DOC
val Ûbasic_res_postÝ : 
	(THM -> THM -> int) ->
	(THM list * (BASIC_RES_TYPE list * THM list) * int * int) -> 
	((BASIC_RES_TYPE list * THM list) * int * int * bool);
=DESCRIBE
This is the post processor for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
$basic\_res\_post$ $subsum$ $(res,$ $frags,$ $before,$ $hwm,$ $ind)$
will test each member of $res$, checking for the conclusion $T$ or $F$, and then against each member of $before$.
In checking one theorem against another 
it will use $subsum$ - discarding the new theorem if the result is $1$,
and discarding (with tidying up of $frags$, $before$, $hwm$, and $ind$)
the original if the result is $2$,
accepting the new theorem (modifying $frags$ and $before$)
if the result is $0$, or any other value bar $1$ and $2$.
=ENDDOC
=DOC
val Ûbasic_res_extractÝ : BASIC_RES_TYPE list * THM list ->
	THM list;
=DESCRIBE
This is the extraction function for the basic resolution tool
based on $prim\-\_resolution\-\_rule$.
It does no more than return the second argument.
=ENDDOC
Some one-off subsumption checks could be placed in this rule,
rather than $basic\_res\_post$.
=DOC
val Ûbasic_resolution_ruleÝ : int -> THM list -> THM list ->
	THM list;
=DESCRIBE
$basic\_resolution\_rule$ $limit$ $sos$ $rest$ will 
resolve the theorems in the set of support and the rest
against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will belong to the set of support, or be derived from
an earlier resolution in the evaluation.
Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation where necessary and allowed.
Duplicates and pure specialisations in the resulting list will be discarded.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
The implementation of this function is primarily by combining
the above bits.
Roughly:
=GFTSHOW Defn
fun basic_resolution_rule limit sos rest = 
	prim_resolution_rule 
		basic_res_pre
		basic_res_resolver
		(basic_res_post basic_res_subsumption)
		basic_res_extract
		limit
		sos
		rest;
=TEX
=DOC
val Ûbasic_resolution_tacÝ : int -> THM list ->
	TACTIC;
=DESCRIBE
$basic\_resolution\_tac$ $limit$ $thms$ $(asms, conc)$
will first strip the negated goal into the assumption list.
The assumptions derived from this will become the set of support,
the pre-existing assumptions and the input $thms$ will be
 the rest of the theorems.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will belong to the set of support, or be derived from
an earlier resolution in the evaluation.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The resulting list of theorems will have all the $thms$ removed,
all the theorems derived from stripping and negating the 
goal removed, 
and the rest used to determine a new assumption list.
Any previous assumption not present as a conclusion
in the resulting list of theorems will be removed,
all the new theorems will become assumptions.
As a special case, $...ô\ F$ is checked for, before any
further processing.
If present it will be used to prove the goal.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
This is $basic\_resolution\_rule$ with some pre- and postprocessing.
=DOC
val Ûbasic_resolution_tac1Ý : int -> THM list ->
	TACTIC;
=DESCRIBE
$basic\_resolution\_tac1$ $limit$ $thms$ $(asms, conc)$
will take the assumptions gained by $asm\_rule$ to be the set of support, and $thms$ to be the rest of the theorems.
These theorems will be resolved against each other until $limit$ new theorems have been 
derived, or until $...ô\ F$ is derived, or until no
further resolution can be done.
In any resolution attempt at least one of the two theorems will belong to the set of support, or be derived from
an earlier resolution in the evaluation.
Duplicates and pure specialisations will be discarded.

Resolution will be attempted on subterms reached through 
outer universal quantification, and propositional
connectives, by specialising the outer quantifications,
and by type instantiation on the input theorems $thms$ where necessary and possible.

The resulting list of theorems will have all the $thms$ removed,
and the rest used to determine a new assumption list.
Any previous assumption not present as a conclusion
in the resulting list of theorems will be removed,
all the new theorems will become assumptions.
As a special case, $...ô\ F$ is checked for, before any
further processing.
If present it will be used to prove the goal.
=USES
On its own, or in combination with some canonicalisation
of the input theorems.
=FAILURE
67003	The limit, ?0, must be a positive integer
67004	No resolution occurred
=ENDDOC
This is $basic\_resolution\_rule$ with some pre- and postprocessing.
\section{EPILOGUE}
=SML
end; (* of signature Resolution *)
=TEX
\twocolumn[\section{INDEX}]
\small
\printindex
\end{document}


