=IGN
********************************************************************************
usr005C.doc: this file is part of the ProofPower system

Copyright (c) 2002 Lemma 1 Ltd.

See the file LICENSE for your rights to use and change this file.

Contact: Rob Arthan < rda@lemma-one.com >
********************************************************************************
% usr005C.doc   %Z% $Date: 1993/12/08 11:50:24 $ $Revision: 1.3 $ $RCSfile: usr005C.doc,v $
=TEX
The design of the logical kernel is a development of the LCF paradigm
which has been used in earlier implementations of the HOL logic, most
notably the Cambridge implementation described in \cite{SRI89a}.
The original reference for LCF is \cite{Gordon79}.
The ideas depend upon the use of a strongly typed metalanguage supporting
the  abstract data type facility, whereby a data type may be declared
together with one or more so-called constructors, in such a way
that the type discipline ensures that all values of the data type are
created using the constructors.
For \Product{} the metalanguage is Standard ML, see \cite{Milner90},
in which the {\tt abstype} construct provides the necessary feature.

Integrity is ensured in an LCF-style proof development system by representing theorems as elements of an abstract data type, which we will call $THM$.
The representation type for $THM$ is the set of sentences of the logic --- sequents in the case of HOL as formulated in \cite{DS/FMU/IED/SPC001}.
The constructors of the abstract data type are the axioms and inference
rules of the logic, so that values of type $THM$ arise from computations
which directly represent formal proofs.
The merit of this approach is that it concentrates all the code which is critical to the integrity of the system in the abstract data type and the small amount of code which supports it.
Facilities such as user-interfaces and proof procedures may be implemented using the primitive operations of the abstract data type and are not themselves critical since they cannot compromise the integrity of the system.

This paradigm has been adapted slightly in \Product{}.

=IGN
The following paragraphs summarise the key issues and solutions for \Product{}.

\begin{enumerate}
\item

The systems supports the introduction by the user of definitions and other extensions, both conservative and axiomatic.

\item

Extensions are associated with particular theories.
Theories are organised in hierarchies, whose parent/child relationships form directed acyclic graphs.

Proofs (i.e. computations of theorems) are carried out with respect to a context determined by the collection of such extensions, i.e. a {\em theory} in the sense of \cite{DS/FMU/IED/SPC001}.

In order to ensure that theorems used for deriving results in any context have themselves all been derived in that context, each theorem is marked with an indicator which identifies the context in which it was derived.
An attempt to use a theorem which is out of scope in a proof is rejected by the logical kernel.


The context in which the user is working is determined by which theory is currently ``open'' (known as the ``current theory'').
In such a context only those extensions which were made in the current theory or one of its parents are in scope, and only theorems proven in this context are available for use in deriving new theorems.

If the user choses to remove or modify a constant definition or other extension the system will insist on deleting all extensions made subsequent to that extension (strictly, made in a context with that extension in scope), and will invalidate any theorems which have been derived with the extension in scope.

We wish to store the collection of theories belonging to one or more users
in a reasonably efficient fashion. Two measures facilitate this.
Firstly, we make the concrete representation of a theory hold
only those extensions which are specific to it.
The theories are organised as a directed acyclic graph given by a parenthood relation defined by the user.
The context (or abstract theory) determined by such a concrete theory
comprises the union of the extensions contained in it and its ancestors with
respect to this relation and is represented by a set of theory addresses.
Secondly, we organise the theories themselves into a tree of theory hierarchies. A theory hierarchy is intended to represent the set of theories constructed by a particular user.
A theory hierarchy may conveniently be implemented
as a physical store or {\em database} in which we hold a set of theories
together with a pointer to a parent theory hierarchy. This parenthood
relation on theory hierarchies allows a collection of theories to be
shared amongst many users without undue replication in the physical store.
A theory hierarchy determines a set of theory addresses from which the
user may construct contexts in which to carry out proof.

\item
We wish to allow the user to edit the contents of a theory by deleting
extensions, and then, perhaps, making new extensions which are logically
incompatible with the ones which have been deleted.
This implies that a theorem must be marked with an indicator identifying
the set of extensions on which it may depend. For reasons of efficiency,
this indicator comprises a so-called {\em level number}. Each extension
to a theory or deletion of an extension from a theory causes the level
number to be incremented. When an extension is deleted, the corresponding
level number is added to a set of invalid levels maintained in the data
structure representing the theory. The inference rules both check
that any theorem presented to them has a valid level number and also
generate theorems which have a level number corresponding to the
most recent extension to the context.
\end{enumerate}

=TEX
Users start their HOL sessions within a current theory, which perhaps possesses some parent theories.
They may then add to the theory by operations upon its contents, or change the current theory by an operation upon theory attributes.
=IGN
The user is recommended to use the access functions provided,
rather than manipulate this ``raw'' theory type.

The user sees each theory as named by a string.
Internally however this name is represented and manipulated 
as an integer (that is an index to the internal representation of
a theory hierarchy).
This internal representation of names is visible from various functions.

Similarly, a theory contains a current definition level,
which is incremented by 1 at each definition, axiom, etc., saved in the
theory.
Various things, in particular theorems, are created and saved with a field
set to their current definition level.
This definition level mechanism is used to allow sound deletion of 
definitions and theorems.
These declaration levels will also be integers.

=TEX
\subsection{Types}
\subsubsection{The type $THM$}
This is the abstract data type of theorems in \Product{}, whose primitive constructors are the inference rules and extensional mechanisms
of the abstract data type.
=INLINEFT
 =|-
=TEX
\ provides a strict equality test on the conclusion and assumptions of theorems,
=INLINEFT
~=|-
=TEX
\ provides an equality test on the conclusion and assumptions of theorems up to $Á$-convertibility and order of assumptions.
\subsubsection{The type $SEQ$}
This is the type of sequents, consisting of a list of assumptions and a conclusion.
=GFT Definition
type SEQ = (TERM list) * TERM;
=TEX
=INLINEFT
 =#
=TEX
\ provides a strict equality test on sequents,
=INLINEFT
~=#
=TEX
\ provides an equality test on the sequents up to $Á$-convertibility and order of assumptions.
\subsubsection{The type $CONV$}
This is the type name conventionally used for conversions, that is, inference rules whose last argument is a term, and whose result is an equation whose LHS is that term.
Though it would be type correct, we conventionally do not use this type name for other functions of type $\ldots\ ->\ TERM\ ->\ THM$.

Conversions supplied with \Product{} normally prove equations whose left hand side is strictly equal to their term argument, though functions which take conversions as arguments (e.g. conversionals) accept equations whose left hand side is $Á$-convertible to the term argument.

=GFT Definition
type CONV = TERM -> THM;
=TEX

\subsection{Primitive Rules of Inference}
All the inference rules will check that the theorems they
are given are valid (i.e. do not belong to theories that are out
of scope, nor were they potentially derived from now deleted
definitions or axioms).
They will not check that their term arguments are well-formed, however,
as even if they are malformed, this cannot introduce logical inconsistencies.
Theorems saved in, or otherwise associated with changes in, a theory are checked for well-formedness however.

\subsubsection{subst\_rule}
=GFT Signature
val subst_rule : (THM * TERM) list -> TERM -> THM -> THM;
=TEX
=DESCRIBE
Substitution of equational theorems according to a template.
=FRULE 1 Rule
subst_rule
÷
[‡1 ô t1=t1', ... , ‡n ô tn=tn']
‡ ô t[t1,...tn]
÷
‡1 À ... ‡n À ‡ ô t[t1',...tn']
=TEX
$subst\_rule$ $[(thm_1, x_1),\ldots,(thm_n, x_n)]$ $template$ $thm$
returns a theorem in which $template$ determines where in $thm$ the $thm_i$ are substituted.
The $x_i$ must be variables.
The template is of the form $t[x_1,\ldots,x_n]$, and wherever the $x_i$ occur free in $template$ their associated equational theorem, $thm_i$,
is substituted into $thm$.
The rule will rename as necessary to avoid variable capture,
in the same manner as $var\_subst$ (q.v).
The assumption list of the resulting theorem is the union of all
substitution theorems, regardless of use.

The conclusion of the resulting theorem will take its bound variable names
from $template$, not $thm$, as shown in the following example.
This provides an $\alpha$-conversion facility.

The function may be usefully partially evaluated with one or two arguments.
=EXAMPLE
subst_rule [(`ô p = q`, ¬x1®), (`ô r = s`, ¬x2®)] 
	(¬µ y · f x1 r y + g x2 p = h y®)
	(`ô µ x · f p r x + g r p = h x`)
	=
	`ô µ y · f q r y + g s p = h y`
=SEEALSO
$subst\_conv$
=TEX
%($SUBST$ in Cambridge HOL)

=IGN
The $(\ldots * TERM)$ argument in the specification is a $string$ $*$ $TYPE$, representing destroyed variables.
A list is used to represent the specification's (partial) function,
on the assumption that its domain is finite.
\subsubsection{simple\_Ì\_eq\_rule}
=TEX

=GFT Signature
val simple_Ì_eq_rule : TERM -> THM -> THM;
=TEX
=DESCRIBE
Given an equational theorem, return the equation formed by abstracting the term argument (which must be a variable) from both sides.
=FRULE 1 Rule
simple_Ì_eq_rule
¬x®
÷
‡ ô t1[x] = t2[x]
÷
‡ ô (Ì x · t1[x]) = (Ì x · t2[x])
=TEX
=SEEALSO
$abs\_conv$, $abs\_rule$
=TEX
%($ABS$ in Cambridge HOL)

The $TERM$ argument in the specification is a $string$ $*$ $TYPE$, representing destroyed variables.
\subsubsection{inst\_type\_rule}
=GFT Signature
val inst_type_rule : (TYPE * TYPE) list -> THM -> THM;
=TEX
=DESCRIBE
Parallel instantiation of some of the type variables of the conclusion of a theorem.
=FRULE 1 Rule
inst_type_rule
[(Ó1, tyv1), ..., (Ón,tyvn)]
÷
‡ ô t[tyv1,...tyvn]
÷
‡ ô t[Ó1,...Ón]
=TEX
$inst\_type\_rule$ $talist$ $thm$ will instantiate each type variable in
$talist$ with its associated type.
It will decorate free variables that would become identified with
other variables (both in conclusion and assumptions)
by their types becoming the same and the names originally being the same.
To instantiate types in the assumption list, see $asm\_inst\_type\_rule$.
=TEX
($INST\_TYPE$ in Cambridge HOL)

=IGN
The $(\ldots * TYPE)$ argument in the specification is a $string$, representing the name of a type variable.
A list is used to represent the specification's (partial) function,
on the assumption that its domain is finite.
=TEX

\subsubsection{´\_intro}
=GFT Signature
val ´_intro : TERM -> THM -> THM;
=TEX
=DESCRIBE
Prove an implicative theorem, removing, if $\alpha$-convertibly present, the antecedent of the implication from the assumption list.
=FRULE 1 Rule
´_intro
¬t1®
÷
‡ ô t2
÷
‡ - {t1} ô t1 ´ t2
=TEX
%($DISCH$ in Cambridge HOL)
\subsubsection{´\_elim}
=GFT Signature
val ´_elim : THM -> THM -> THM;
=TEX
=DESCRIBE
Modus Ponens
=FRULE 1 Rule
´_elim
÷
‡1 ô t1 ´ t2; ‡2 ô t1'
÷
‡1 À ‡2 ô t2
=TEX
where $t1$ and $t1'$ must be $\alpha$-convertible.
=SEEALSO
$¤\_mp\_rule$(reminiscent of Modus Ponens on $¤$)
=TEX
%($MP$ in Cambridge HOL)

\subsubsection{asm\_rule}
=GFT Signature
val asm_rule : TERM -> THM;
=TEX
=DESCRIBE
``A term is true on the assumption that it is true''.
=FRULE 1 Rule
asm_rule
¬t®
÷
÷
t ô t
=TEX
%($ASSUME$ in Cambridge HOL)
\subsubsection{refl\_conv}
=GFT Signature
val refl_conv : CONV;
=TEX
=DESCRIBE
The reflexivity of equality implemented as a conversion.
=FRULE 1 Rule
refl_conv
¬t®
÷
÷
ô t = t
=TEX
%($ALL\_CONV$ and $REFL$ in Cambridge HOL)
\subsubsection{simple\_$\beta$\_conv}
=GFT Signature
val simple_Â_conv : CONV;
=TEX
=DESCRIBE
Apply a $\beta$-reduction to a simple abstraction.
=FRULE 1 Conversion
simple_Â_conv
¬(Ì x · t1[x]) t2®
÷
÷
ô (Ì x · t1[x]) t2 = t1[t2]
=TEX
=SEEALSO
$\beta\_conv$
=TEX
%($BETA\_CONV$ in Cambridge HOL)

\subsection{Definition Schemata}
\subsubsection{suc\_conv}
=GFT Signature
val suc_conv : CONV;
=TEX
=DESCRIBE
This function defines the constants with names consisting only of decimal digits, and type $î$.
=FRULE 1 Rule
suc_conv
(mk_î (m+1))
÷
÷
ô ‘(mk_î(m+1))® = 
	Suc ‘mk_î m®
=TEX
=FRULE 1 Rule
suc_conv
(mk_î 0)
÷
÷
ô 0 = Zero
=TEX
=SEEALSO
$suc\_conv$, $mk\_num$
=TEX
%($num\_CONV$ in Cambridge HOL)

$suc\_conv$ will not have the clause for $0$.
\subsubsection{string\_conv}
=GFT Signature
val string_conv : CONV;
=TEX
=DESCRIBE
This function defines the string literal constants.
A string literal constant is indicated by the constant having a name starting with a double quote(\verb!"!), and having type $CHAR\ LIST$.
A type abbreviation, $STRING$ is introduced for $CHAR\ LIST$.
This is equivalent to a list of character literal constants,
one for each but the first ($"$) character of the string constant's name.
This conversion defines this relationship, by returning the head and unexploded tail of the list of characters.
A character literal constant is indicated by the constant's name starting with single backquote ($`$), having a single other character, and being of type $CHAR$.
=FRULE 1 Rule
string_conv
(mk_string ("c..."))
÷
÷
ô ‘(mk_string("c..."))® = 
Cons ‘(mk_char("c"))® 
	‘(mk_string("..."))®
=TEX
Or:
=FRULE 1 Rule
string_conv
(mk_string "")
÷
÷
ô ‘(mk_string(""))® = Nil
=TEX
=SEEALSO
$mk\_string$
=TEX
\subsubsection{char\_conv}
=GFT Signature
val char_conv : CONV;
=TEX
=DESCRIBE
This function defines the character literal constants, by giving a relationship between character literal constants and their ASCII code (derived by the Standard ML function $ord$).
A character literal is indicated by the constant's name starting with single backquote ($`$), having a single other character, and being of type $CHAR$.
=FRULE 1 Rule
char_conv
(mk_char("c"))
÷
÷
ô ‘(mk_char("c"))® = 
	AbsChar ‘ord "c"®
=TEX
=SEEALSO
$mk\_char$
=TEX
\subsection{Built-In Rules of Inference}
Each of the following inference rules is justified in terms of the primitive inference rules
and definitional schemata, or derived rules declared and justified prior to the new declaration.
We will give an informal proof 
in each case, following the documentation of the rule.
This provides a partial order of introduction on the rules that follow.
\subsubsection{eq\_sym\_rule}
=GFT Signature
val eq_sym_rule : THM -> THM;
=TEX
=DESCRIBE
Symmetry of equality:
=FRULE 1 Rule
eq_sym_rule
÷
‡ ô t1 = t2
÷
‡ ô t2 = t1
=TEX
=SEEALSO
$eq\_sym\_conv$
=TEX
%($SYM$ in Cambridge HOL)
=GFT
1.	‡ ô t1 = t2			Hypothesis
2.	ô t1 = t1			eq_refl_conv
3.	‡ ô t2 = t1			subst_rule 1,2
=TEX
\subsubsection{t\_thm}
We will use the theorem
=GFT definition
t_thm = ô T
=TEX
in the following.
It is proven by
=GFT Informal Proof
1.	ô T ¤ ((Ì x· x) = (Ì x· x))				definition of T
2.	ô (Ì x· x) = (Ì x· x)					refl_conv
3.	ô ((Ì x· x) = (Ì x· x)) ´ ((Ì x· x) = (Ì x· x))		´_intro 2
4.	ô ((Ì x· x) = (Ì x· x)) ¤ T				eq_sym_rule 1.
5.	ô ((Ì x· x) = (Ì x· x)) ´ T				subst_rule 1,4
6.	ô T								´_elim 
=TEX
where the context must contain the theorem:
=GFT
t_def = ô T ¤ ((Ì x· x) = (Ì x· x))
=TEX
\subsubsection{¤\_T\_elim}
We later use the following rule of inference (which is not built in):
=FRULE 1 Rule
¤_T_elim
÷
‡ ô t ¤ T
÷
‡ ô t
=TEX
Justified by:
=GFT Informal Proof
1.	‡ ô t ¤ T						Hypothesis
2.	‡ ô T ¤ t						eq_sym_rule 1
3.	ô T							t_thm
4.	‡ ô t							subst_rule 3,2
=TEX
\subsubsection{list\_simple\_µ\_elim}
=GFT Signature
val list_simple_µ_elim : TERM list -> THM -> THM;
=TEX
=DESCRIBE
Instantiate a (multiply) universally quantified term to a given value.
=FRULE 1 Rule
list_simple_µ_elim
[...,¬tn®,...]
÷
‡ ô µ ...xn ... · t2[...,xn,...]
÷
‡ ô t2'[...,tn,...]
=TEX
where $t2'$ is renamed from $t2$ to prevent bound variable capture,
and the $x_i$ are variables.
The terms must have the same types as the corresponding
universally quantified variables.
The instantiation is done by simultaneous substitution (as if by $var\_subst$, q.v.), rather than by
iteration of a single instantiation.
=TEX
%($SPECL$ in Cambridge HOL)

The following is a justification for a single instantiation.
It may, with some care due to the simultaneous instantiation, be iterated to gain an appropriate finite list case.
=GFT
1.	ô $µ = (ÌP · P = Ìx.T)				inst_type applied to Definition
2.	‡ ô µ x · t2[x]					Hypothesis
3.	‡ ô (ÌP · P = Ìx.T)(Ì x · t2[x])			subst_rule 1,2
4.	ô (ÌP · P = Ìx · T)(Ì x · t2[x]) = ((Ì x · t2[x]) = Ìx.T)
								simple_Â_conv
5.	‡ ô (Ì x · t2[x]) = Ìx · T				subst_rule 4,3
6.	ô (Ì x · t2[x]) t1 ¤ (Ì x · t2[x]) t1		eq_refl_conv
7.	‡ ô (Ì x · t2[x]) t1 ¤ (Ìx · T) t1			subst_rule 5,6
8.	‡ ô (Ì x · t2[x]) t1 ¤ t2'[t1]			simple_Â_conv
9.	‡ ô t2'[t1] ¤ (Ì x · t2[x]) t1			eq_sym_rule 8
10.	‡ ô t2'[t1] ¤ (Ìx · T) t1				subst_rule 9,5
11.	ô (Ìx · T) t1 ¤ T					simple_Â_conv
12.	‡ ô t2'[t1] ¤ T					subst_rule 10,11
13.	‡ ô t2'[t1]						¤_T_elim 12
=TEX
Notice in step 8. where $simple\_\beta\_conv$ may introduce some renaming
(changing $t2$ to $t2'$)
to prevent bound variable capture.
\subsubsection{eq\_trans\_rule}
=GFT Signature
val eq_trans_rule : THM -> THM -> THM;
=TEX
=DESCRIBE
Transitivity of equality:
=FRULE 1 Rule
eq_trans_rule
÷
‡1 ô t1 = t2; ‡2 ô t2' = t3
÷
‡1 À ‡2 ô t3
=TEX
where ¬t2® and ¬t2'® are $\alpha$ convertible.
%($TRANS$ in Cambridge HOL)
=GFT
1.	‡1 ô t1 = t2			Hypothesis
2.	‡2 ô t2' = t3			Hypothesis
3.	‡1 À ‡2 ô t1 = t3		subst_rule 2,1
=TEX
\subsubsection{mk\_app\_rule}
=GFT Signature
val mk_app_rule : THM -> THM -> THM;
=TEX
=DESCRIBE
Given two equational theorems, one being between two functions, apply the two functions
to the LHS and RHS of the other equation.
=FRULE 1 Rule
mk_app_rule
÷
‡1 ô u1 = u2; ‡2 ô v1 = v2
÷
‡1 À ‡2 ô u1 v1 = u2 v2
=TEX
($MK\_COMB$ in Cambridge HOL)
=GFT Informal Proof
1.	‡1 ô u1 = u2				Hypothesis
2.	‡2 ô v1 = v2					Hypothesis
3.	ô u1 v1 = u1 v1				eq_refl_conv
4.	‡1 À ‡2 ô u1 v1 = u2 v2			subst_rule [1,2] 3
=TEX
\subsubsection{¤\_T\_intro}
We later use the following rule of inference (which is not built in):
=FRULE 1 Rule
¤_T_intro
÷
‡ ô t
÷
‡ ô t ¤ T
=TEX
which is justified by:
=GFT Informal Proof
1.	ô µ b1 b2 · (b1 ´ b2) ´ (b2 ´ b1) ´ (b1 ¤ b2)	
								´_antisym_axiom
2.	ô µ b2 · (t ´ b2) ´ (b2 ´ t) ´ (t ¤ b2)	
								simple_µ_elim 1
3.	ô (t ´ T) ´ (T ´ t) ´ (t ¤ T)			simple_µ_elim 2
4.	ô T							t_thm
5.	ô t ´ T						´_intro 4
6.	ô (T ´ t) ´ (t ¤ T)				´_elim 3,5
7.	‡ ô t							Hypothesis
8.	‡ ô T ´ t						´_intro 7
9.	‡ ô t ¤ T						´_elim 6,8
=TEX
where the context must contain the theorem:
=GFT
´_antisym_axiom = 
	ô µ b1 b2 · (b1 ´ b2) ´ (b2 ´ b1) ´ (b1 ¤ b2)
=TEX

\subsubsection{¤\_mp\_rule}
=GFT Signature
val ¤_mp_rule : THM -> THM -> THM;
=TEX
=DESCRIBE
This is an inference rule reminiscent of Modus Ponens, but using a bi-implicative theorem rather than an implicative one.
=FRULE 1 Rule
¤_mp_rule
÷
‡1 ô t1 ¤ t2; ‡2 ô t1'
÷
‡1 À ‡2 ô t2
=TEX
where $t1$ and $t1'$ must be $\alpha$-convertible.
=SEEALSO
$´\_elim$ (true Modus Ponens, on $´$)
=TEX
%($EQ\_MP$ in Cambridge HOL)
=GFT Informal Proof
1.	‡1 ô t1 ¤ t2						Hypothesis
2.	‡2 ô t1'						Hypothesis
3.	‡2 ô t1' ¤ T					¤_T_intro 2
4.	‡1 À ‡2 ô t2 ¤ T					subst_rule 1,3
5.	‡1 À ‡2 ô t2					¤_T_elim 4
=TEX
\subsubsection{simple\_µ\_intro}
=GFT Signature
val simple_µ_intro : TERM -> THM -> THM;
=TEX
=DESCRIBE
Prove a simple universally quantified theorem.
=FRULE 1 Rule
simple_µ_intro
¬x®
÷
‡ ô t
÷
‡ ô µ x · t
=TEX
=SEEALSO
$µ\_intro$
=TEX
%($GEN$ in Cambridge HOL)

In the following we use $subst\_rule$ where the HOL description uses $TRANS$( which is the same as $eq\_trans\_rule$).

First we prove $µx · T$
=GFT Informal Proof
1.	ô (Ìx · T) = Ìx · T				eq_refl_conv
2.	ô ((Ìx · T) = Ìx · T) ¤ T			¤_T_intro 1
3.	ô (ÌP · P = Ìx · T)(Ìx · T)
		¤ ((Ìx · T) = Ìx · T)			simple_Â_conv
4.	ô (ÌP · P = Ìx · T)(Ìx · T) ¤ T		subst_rule 3, 2
5.	ô $µ = (ÌP · P = Ìx · T)				inst_type applied to Definition
6.	ô (ÌP · P = Ìx · T) = $µ				eq_sym_rule 5
7.	ô (µx · T) ¤ T					subst_rule 6, 4
8.	ô (µx · T)						¤_T_elim 7
=TEX
where the context must contain the stated definition of $µ$.
Then we can prove $µ\_intro$:
=GFT Informal Proof
1.	‡ ô t							Hypothesis
2.	‡ ô t ¤ T						¤_T_intro 1
3.	‡ ô (Ìy · t) = Ìy · T				abs_rule 2
4.	ô (µy · t) ¤ (µy · t)				eq_refl_conv
5.	‡ ô (µy · t) ¤ µy · T				subst_rule 3,4
6.	‡ ô (µy · T) ¤ µy · t				eq_sym_rule 5
7.	ô µx · T						inst_type_rule(ô µx · T)
8.	ô µy · T						subst_rule[] 7
9.	ô µy · t						subst_rule 6, 8
=TEX
Note that $subst\_rule\;[]\;t\;(ô\,t')$ returns $ô\,t$ only when
$t$ and $t'$ are $\alpha$-convertible.
\subsubsection{inst\_term\_rule}
=GFT Signature
val inst_term_rule : (TERM * TERM) list -> THM -> THM;
=TEX
=DESCRIBE
Parallel instantiation of term variables within a theorem's conclusion to some other values.
=FRULE 1 Rule
inst_term_rule
[..., (¬ti®, ¬xi®), ...]
÷
‡ ô t[x1, ..., xn]
÷
‡ ô t[t1, ..., tn]
=TEX
($INST$ in Cambridge HOL)

A list is used to represent the specification's (partial) function,
on the assumption that its domain is finite.
=GFT Informal Proof
1.	‡ ô t[x1, ..., xn]				Hypothesis
2.	‡ ô µ x1 ... xn · t[x1, ..., xn]		repeated simple_intro on 1
3.	‡ ô t[t1, ..., tn]				repeated simple_µ_elim on 2
=TEX
It is important to do all the generalisations before any  specialisations to gain the effect of instantiation in parallel.
Without this, if a variable to be instantiated is introduced by
a specialisation, and then generalised along with those already
present, then that variable occurrence will also be instantiated. 
\subsubsection{plus\_conv}
=GFT Signature
val plus_conv : CONV;
=TEX
=DESCRIBE
This conversion provides the value of the addition of two numeric literals.
=FRULE 1 Rule
plus_conv
¬‘mk_î m® +  ‘mk_î n®®
÷
÷
ô ¬‘mk_î m® + ‘mk_î n®® =
	‘mk_î(m + n)®
=TEX
=USES
For doing fast arithmetic proofs.
The informal justification relies on the following theorems:
=GFT
µ m n· 0 + n = n ± (m + 1) + n = (m + n) + 1 ± Suc m = m + 1

ô (µ n· ³ Suc n = Zero) ±
	OneOne Suc ±
	(µ p· p Zero ± (µ m· p m ´ p (Suc m)) ´ (µ n· p n))
=TEX
%From these we must be able to derive $plus\_assoc$
=GFT
ô µ m n p · (m + n) + p = m + (n + p)
=TEX
(a simpler result than $plus\_assoc$ might well do).
From these, and the inference rules already declared we could justify any single
instance of this theorem schemata.
E.g.
=GFT Informal Proof of 2 + 2 = 4
1.	ô 3 = Suc 2				suc_conv
2.	ô 4 = Suc 3				suc_conv
3.	ô Suc 3 = 3 + 1			defn +
4.	ô 4 = 3 + 1				eq_trans_rule 2,3
5.	ô Suc 2 = 2 + 1			defn +
6.	ô 3 = 2 + 1				eq_trans_rule 1,6
7.	ô (+) = (+)				refl_conv
8.	ô 1 = 1				refl_conv
9.	ô (+) 3 = (+) (2 + 1)		mk_app_rule 6,7
10.	ô 3 + 1 = (2 + 1) + 1		mk_app_rule 9,8
11.	ô 4 = (2 + 1) + 1			eq_trans_rule 4,10
12.	ô (2 + 1) + 1 = 2 + (1 + 1)	plus_assoc
13.	ô 4 = 2 + (1 + 1)			eq_trans_rule 11,12
14.	ô 2 = Suc 1				suc_conv
15.	ô Suc 1 = 1 + 1			defn +
16.	ô 2 = 1 + 1				eq_trans_rule 14,15
17.	ô (+) 2 = (+) 2			refl_conv
18.	ô 2 + 2 = 2 + (1 + 1)		mk_app_rule 17,16
19.	ô 2 + (1 + 1) = 2 + 2		eq_sym_rule 18
20.	ô 4 = 2 + 2				eq_trans_rule 13,19
21.	ô 2 + 2 = 4				eq_sym_rule 20
=TEX

\subsection{Operations on Theory Hierarchies}
\label{Operations on Theory Hierarchies}
Manipulation of theory hierarchies is through UNIX commands, as described below.
\subsubsection{Conventions}

The following conventions are adopted for command line
options:

\begin{table}[h]
\centering
\begin{tabular}{|l|p{4in}|}\hline
Option & Description \\\hline\hline
{\tt -d} & Precedes the name of a database to be created or to be the current one in the session. The database may have theory name affixed, if appropriate to the command in question \\\hline
{\tt -f} & Force an action without asking for confirmation (as in UNIX {\tt rm}) \\\hline
{\tt -i} & Precedes the name of an initialisation script to be run at the beginning of a Proof Development System session \\\hline
{\tt -p} & Precedes the name of a parent database, which may have a theory name affixed, if appropriate \\\hline
{\tt \#} & Used to affix a theory name to a database name, where necessary \\\hline
\end{tabular}
\caption{Command Line Options}\label{CommandLineOptions}
\end{table}

A database name is not necessarily a UNIX file name. To cater for
architecture dependencies in the database format, the UNIX file
name is obtained from the database name by prefixing
it with the name of the machine architecture and affixing to the
result the filename extension `{\tt .db}'. Either the architecture
or the filename extension may be given if desired.
Thus {\tt fred}, {\tt fred.db}, {\tt sun4fred} and {\tt sun4fred.db}
all denote the same thing, namely the database whose name is
{\tt fred} and which is stored in the UNIX file {\tt sun4fred.db}
when running on a SUN4 architecture. The intention is that
the user normally just gives the database name,
e.g. {\tt fred}, and that the longer forms are only required
in exceptional cases.


A `{\tt \#theoryname}' affix is always optional and, if omitted,
defaults to the name of the cache theory in the database (see
section \ref{holmakedatabase} below).

\subsubsection{Interrupts}
All of the commands described may loop, or run very slowly for
one reason or another (e.g. as a result of a problem in
a user-defined steering file). The commands are therefore
coded in such a way that their execution can be abandoned
by he user by a keyboard interrupt without
cluttering the user's environment with temporary files or other
unwanted material.

\subsubsection{{\tt hol}}

\begin{description}
\item[Name]
{\tt hol} --- run the HOL Proof Development System
\item[Synopsis]
{\tt hol [-i script] [-d database[\#theoryname]]}
\item[Description]
{\tt hol}
runs the HOL Proof Development System on the indicated database
of HOL theories.
If no {\tt -d database}
is supplied then the first database called {\tt hol}
(i.e. held in the file {\tt `arch`hol.db})
to be found in the search path is used.

The files identified by any {\tt [-i script]} options are
executed in turn at the start of the session with the Proof
Development System.
Before running these scripts, the current theory will be set
to the theory given by {\tt theoryname} or, if that is omitted,
to the cache theory for the database (which is the theory
{\tt hol} in the case of the system database).

\item[Files]
{\tt `arch`hol.db} --- the conventional name for the system database
\item[See Also]
{\tt hol\_make\_database(1)}
{\tt hol\_list(1)}

\item[Diagnostics]
{\tt hol} prints a message and exits (with the value 1) if
the database cannot be accessed or if the theory specified does
not exist in the database.
\item[Special Considerations]
The behaviour if the database is corrupt is system-dependent.

The command must ensure that the logical kernel (see
\cite{DS/FMU/IED/HLD007}) is caused to load the theory hierarchy
stored in the database. This and all other initialisation activities
(except for the Reader/Writer) should be carried out before
running the initialisation scripts.
\end{description}

\newpage
\subsubsection{{\tt hol\_make\_database}}\label{holmakedatabase}

\begin{description}

\item[Name]\ 

{\tt hol\_make\_database} --- make a new HOL theory database

\item[Synopsis]\ 

{\tt hol\_make\_database [-f] [-p parentdatabase[\#parenttheory]]\\
 newdatabase[\#cachetheory]}
 
\item[Description]\ 

{\tt hol\_make\_database}
makes a new database to contain HOL theories. The new database initially
contains a single theory, called the {\em cache theory}
for the database,  with name given by {\it cachetheory}
(which is used by
certain system functions to cache various definitions and theorems and
which is used as the initial current theory when the database
is used by the {\tt hol(1)} command).
If {\it cachetheory} is omitted then the database name is taken to be the same
as the name of the new database.
It is an error
if the name {\it cachetheory} clashes with the name of a theory in the
parent database.

The {\it -p} option may be used to indicate
the database which is to be the parent of the new database
and to indicate which theory in it is to be the parent of the theory
{\it cachetheory}.
The parent theory is taken to be the cache theory for the parent
database if it is not given explicitly.

If the {\it -p}
option is not supplied then the database supplied with the system is used
as the parent database, and the parent theory is the theory {\it hol}.

The file in which the database named {\it name}, is held
in a file called {\tt `arch`}{\it name}{\tt.db}. The architecture
and {\tt.db} extension may either or both be given explicitly,
if desired.

In interactive use, {\tt hol\_make\_database}
will normally ask for confirmation before overwriting the database if it
already exists. The {\tt -f} (force) option may be used to suppress
the request for confirmation before overwriting an existing database.

\item[Files]
{\tt .../`arch`hol.db} --- the system database
\item[See Also]
{\tt hol(1)}
{\tt hol\_list(1)}
\item[Diagnostics]\ 

{\tt hol\_make\_database} prints a message and
exits (with value 1) if the parent database or theory does not exist,
if the new database cannot be created or if either of the
database names has an inappropriate architecture prefix.

Some systems impose a limit on the depth of nesting of the
database hierarchy and the command will print an error message and
exit(with value 1) if this limit would be exceeded.

\item[Special Considerations]\ 

The behaviour if the parent database is corrupt is system-dependent.

The name is long because it is not anticipated that users will
do this very often.

The command must arrange things so that the {\it hol} command
can identify the theory hierarchy stored in the new database and
so cause the logical kernel to load it. Similarly for the cache
theory in the database (whose name is not always the same as that
of that of the database).
\end{description}


\subsubsection{{\tt hol\_list}}

\begin{description}
\item[Name]
{\tt hol\_list} --- generate listings from a HOL database
\item[Synopsis]
{\tt hol\_list [-i script] [-d database[\#theory]] theory ...} \par
{\tt hol\_list [-i script] [-d database[\#theory]]}
\item[Description]
{\tt hol\_list} is used to obtain selected information from
a HOL database.

In the first form, where a list 
of one or more theory names is specified,
{\tt hol\_list} uses the HOL system to generate on its standard output
listings of the indicated HOL theories held in the
database given by the {\it -d} option in a form suitable
for inclusion in a \LaTeX\ document. If no {\it -d} option
is given then the database supplied with the system is used.

In the second form, with no list of theory names, {\tt hol\_list}
lists the names of all the theories in the database one
per line on its standard error channel. The output with this
form is not normally directly suited for use in a \LaTeX\ document.

In either form,
the files identified by any {\tt [-i script]} options are
executed in turn with the Proof
Development System before the commands which list the theory
or theory names.
Before running these scripts, the current theory will be set
to the theory given by {\tt theory} or, if that is omitted,
to the cache theory for the database (which is the theory
{\tt hol} in the case of the system database).
Each theory is made current when it is listed.
\item[See Also]
{\tt hol(1)}
{\tt hol\_make\_database(1)}
\item[Diagnostics]
{\tt hol\_list} prints a message and exits (with the value 1)
if the database or any of the theories does not exist.
\item[Special Considerations]
The behaviour is system dependent if the database involved is
corrupt.
\end{description}

\subsection{Operations on Theories}
\label{Operations on Theories}
The functions summarised below are used to create and manipulate the theories in a database.
See the Reference manual for further information.

\begin{table}
\center
\begin{tabular}{|l|l|l|}
	\hline
	Function&Type&Description \\\hline
	\hline
	open\_theory&$string -> unit$&Make an existing theory the current theory \\\hline
	delete\_theory&$string -> unit$&Remove a theory \\\hline
	new\_theory&$string -> unit$&Create an empty theory \\\hline
	new\_parent&$string -> unit$&Make named theory a parent of the current theory \\\hline
	lock\_theory&$string -> unit$&Protect theory from further change \\\hline
	unlock\_theory&$string -> unit$&Allow changes to a theory \\\hline
	duplicate\_theory&$string * string -> unit$&Copy a theory \\\hline
\end{tabular}
\caption{Operations on Theories}\label{TheoryOperations}
\end{table}

\subsection{Operations on Theorems}
\label{Operations on Theorems}
The following functions are provided for manipulating theorems:

\begin{table}
\center
\begin{tabular}{|l|l|}
	\hline
	Function&Description \\\hline
	\hline
=INLINEFT
 =|-
=TEX
	&Strict equality of theorems \\\hline
=INLINEFT
 ~=|-
=TEX
	&Weak equality\footnotemark of theorems \\\hline
=INLINEFT
 =#
=TEX
	&Strict equality of sequents \\\hline
=INLINEFT
 ~=#
=TEX
	&Weak equality\addtocounter{footnote}{-1}\footnotemark of sequents \\\hline
	dest\_thm&Gives the sequent representation of a theorem \\\hline
	asms&Returns the list of assumptions of a theorem \\\hline
	concl&Returns the conclusion of a theorem \\\hline
	thm\_theory&The theory in which a theorem was proven \\\hline
\end{tabular}
\caption{Operations on Theorems}\label{TheoremOperations}
\end{table}

\footnotetext{Here, weak equality means equality up to $Á$-convertibility and order of hypotheses}

\subsection{Operations on Theory Contents}
\label{Operations on Theory Contents}
A number of functions are provided, which allow direct manipulation of the contents of a theory.
Most of these are only required if a theory is being developed axiomatically;
the more usual method uses the definitional interface described in section \ref{Definitional Mechanisms for Theories}.

\begin{table}[h]
\center
\begin{tabular}{|l|l|}
	\hline
	Function&Type \\\hline
	\hline
	save\_thm&$string * THM -> THM$ \\\hline
	list\_save\_thm&$string\ list * THM -> THM$ \\\hline
	delete\_thm&$string -> THM$ \\\hline
	new\_type&$string * int -> TYPE$ \\\hline
	delete\_type&$string -> unit$ \\\hline
	new\_axiom&$string\ list * TERM -> THM$ \\\hline
	delete\_axiom&$string -> unit$ \\\hline
	new\_const&$string * TYPE -> TERM$ \\\hline
	delete\_const&$TERM -> unit$ \\\hline
	set\_user\_datum&$string * USER\_DATUM -> unit$ \\\hline
	get\_user\_datum&$string -> string -> USER\_DATUM$ \\\hline
\end{tabular}
\caption{Operations on Theory Contents}\label{TheoryContentOperations}
\end{table}

Note that deleting an item results in the deletion of all items which could depend on it.
This is performed automatically, but only after the user has been asked to confirm his intension.

\subsection{Definitional Mechanisms for Theories}
\label{Definitional Mechanisms for Theories}

The following functions provide the basic mechanism for conservative extension of theories.
A more useful set of specification tools are described elsewhere.

\begin{description}
\item [simple\_new\_defn : string list * string * TERM {\tt ->} THM]\ 

Introduces and defines a new constant
\item [new\_spec : string list * int * THM {\tt ->} THM]\ 

Introduces and defines a number of new constants
\item [new\_type\_defn : string list * string * string list * THM {\tt ->} THM]\ 

Introduces and defines a new type
\end{description}

%\begin{tabular}{|l|l|l|}
%	\hline
%	Function&Type&Description \\\hline
%	\hline
%	simple\_new\_defn&$string\ list * string * TERM -> THM$&	Introduces and defines a new constant \\\hline
%	new\_spec&$string\ list * int * THM -> THM$&	Introduces and defines a number of new constants \\\hline
%	new\_type\_defn&$string\ list * string * string list * THM -> THM$&	Introduces and defines a new type \\\hline
%\end{tabular}

\subsection{Theory Access Functions}
\label{Theory Access Functions}
The following functions return items from a theory in a fairly self explanatory way.
For further details see the Reference Manual.

\begin{table}[h]
\center
\begin{tabular}{|l|l|}
	\hline
	Function&Type \\\hline
	\hline
	get\_defn&$string -> string -> THM$ \\\hline
	get\_axiom&$string -> string -> THM$ \\\hline
	get\_thm&$string -> string -> THM$ \\\hline
	get\_const\_type&$string -> TYPE OPT$ \\\hline
	get\_type\_arity&$string -> int OPT$ \\\hline
	get\_current\_theory\_name&$unit -> string$ \\\hline
	get\_theory\_names&$unit -> string\ list$ \\\hline
	get\_ancestors&$string -> string\ list$ \\\hline
	is\_theory\_ancestor&$string -> string -> bool$ \\\hline
	get\_parents&$string -> string\ list$ \\\hline
	get\_children&$string -> string\ list$ \\\hline
	get\_descendants&$string -> string\ list$ \\\hline
	get\_defns&$string -> (string\ list * THM)\ list$ \\\hline
	get\_axioms&$string -> (string\ list * THM)\ list$ \\\hline
	get\_thms&$string -> (string\ list * THM)\ list$ \\\hline
	get\_consts&$string -> TERM\ list$ \\\hline
	get\_types&$string -> TYPE\ list$ \\\hline
	get\_current\_theory\_status&$unit -> THEORY\_STATUS$ \\\hline
	get\_theory\_status&$string -> THEORY\_STATUS$ \\\hline
\end{tabular}
\caption{Theory Access Functions}\label{TheoryAccessFunctions}
\end{table}

