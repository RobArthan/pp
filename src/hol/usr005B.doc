% usr005B.doc   %Z% $Date$ $Revision$ $RCSfile$
=TEX
\section{Types}
All HOL terms are ``typed'', by associating them with an object of type $TYPE$.
A type may be either a type variable or a compound type derived by applying a type constructor to zero or more types.
\subsection{Simple Types}
There are two primitive type constructors for type variables and compound types, each equipped with a metalanguage datatype constructor (which simplifies type analysis via pattern matching), a constructor, a destructor and a discriminator (the latter are obtained by replacing the $mk\_$ in the constructor name by $dest\_$ or $is\_$ respectively).
In addition, there are two ``derived'' constructors (with corresponding destructors and discriminators) for the special cases of function space and cartesian product types.
These are summarised, with the associated concrete syntax, in the table below.

The function $dest\_simple\_type$ will split any type into the appropriate datatype constructor applied to the components from which the type was built.

\vspace{2ex}
\begin{tabular}{|l|l|l|} \hline
	Datatype Constructor	& Concrete Syntax	& Type Constructor	\\ \hline \hline
	$Vartype$		& $¬:'a®$		& $mk\_vartype("'a")$	\\
	$Ctype$			& $¬:(ty‰1,ty‰2,ty‰3)ty®$	& $mk\_ctype("ty",[¬ty‰1®,¬ty‰2®,¬ty‰3®])$ \\  \hline
				& $¬:ty‰1 ­ ty‰2®$	& $mk\_ctype("­",[¬:ty‰1®,¬:ty‰2®)$	\\ \hline
				& $¬:ty‰1 ¸ ty‰2®$	& $mk\_ctype("¸",[¬:ty‰1®,¬:ty‰2®)$	\\ \hline
\end{tabular}

The function space constructor also has iterated constructor and destructor functions (made by replacing $mk\_$ by $list\_mk\_$ and $strip\_$ respectively) which unfolds the basic form over a list of arguments.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Terms}
Well-formed HOL terms are objects of ML type $TERM$ and are manipulated by the constructor, destructor and recogniser functions summarised below.
\subsubsection{Simple Terms}
\label{Simple Terms}
There are four primitive term constructors in HOL for making variables, constants, function applications and Ì-abstractions respectively.
These, together with the corresponding concrete syntax are summarised below.
The function $dest\_simple\_term$ returns the appropriate top level value constructor of any well-formed term, together with the name, type and/or sub-terms from which it is built.

Although it is possible to manipulate any term using only these primitives, it is usually more convenient to use the derived forms given is section \ref{Derived Terms}.

\vspace{2ex}
\begin{tabular}{|l|l|l|p{2in}|} \hline
	Datatype Constructor	& Concrete Syntax	& Term Constructor	& Notes \\ \hline \hline
	$Var$			& $¬x :ty®$		& $mk\_var$		& The variable $x$ of type $ty$. \\ \hline
	$Const$			& $¬c :ty®$		& $mk\_const$		& The constant $c$ of type $ty$. \\ \hline
	$App$			& $¬f t®$		& $mk\_app$		& The application of function $f$ to term $t$. \\ \hline
	$SimpleÌ$		& $¬Ì x· t®$		& $mk\_simple\_Ì$	& The abstraction of variable $x$ over term $t$. \\ \hline
\end{tabular}

where x represents a variable, c a previously introduced constant, f a term having function type and t an arbitrary term.

Type assignments (e.g. $¬x :ty®$) may be used with any term, but are always optional; when omitted, the type inference system assigns the most general type.
This can be seen from the following dialogue:
=GFT ML Session
:> ¬f t®;
val it = ¬f t® : TERM   
:> dest_simple_term it;
val it = App (¬f®, ¬t®) : DEST_SIMPLE_TERM   
:> val App(f,t) = it;
val f = ¬f® : TERM   val t = ¬t® : TERM   
:> dest_simple_term t;
val it = Var ("t", ”'b®) : DEST_SIMPLE_TERM   
:> dest_simple_term f;
val it = Var ("f", ”'b ­ 'a®) : DEST_SIMPLE_TERM   

=TEX
where $t$ is assigned a variable type and $f$ the most general corresponding function type.

%--------------------------------------------------------------------
\subsection{Derived Terms}
\label{Derived Terms}
The function $dest\_term$ returns the appropriate top level value constructor of any well-formed term, together with the name, type and/or sub-terms from which it is built.
Note that the primitive constructors of section \ref{Simple Terms} also appear in this list, because they are also recognised by $dest\_term$ (but in this case the value constructor is prefixed with $D$).
Thus this table gives a complete account of the abstract syntax for terms in HOL.


\vspace{2ex}
\begin{tabular}{|l|l|l|l|} \hline
	Value Constructor	& Concrete Syntax	& Iterated Constructor	& Notes	\\ \hline \hline
	$DVar$			& $¬x®$			& No			&	\\  \hline
	$DConst$		& $¬c®$			& No			&	\\ \hline
	$DApp$			& $¬f t®$		& Yes			& 	\\ \hline
	$DÌ$			& $¬Ì vs· t®$		& Yes			& 	\\ \hline
	$DEq$			& $¬t1 = t2®$		& No			& 	\\ \hline
	$D´$			& $¬p1 ´ p2®$		& Yes			& 	\\ \hline
	$DT$			& $¬T®$			& No			& 	\\ \hline
	$DF$			& $¬F®$			& No			& 	\\ \hline
	$D³$			& $¬³p®$		& No			& 	\\ \hline
	$DPair$			& $¬(t1,t2)®$		& No			& 	\\ \hline
	$D±$			& $¬p1 ± p2®$		& Yes			& 	\\ \hline
	$D²$			& $¬p1 ² p2®$		& Yes			& 	\\ \hline
	$D¤$			& $¬p1 ¤ p2®$		& No			& 	\\ \hline
	$DLet$			& $¬let x = t1 and y = t2 in t3®$	& Yes			& 	\\ \hline
	$DEnumSet$		& $¬{t1; t2; t3}®$	& No			& 	\\ \hline
	$Dš$			& $¬{}®$		& No			& 	\\ \hline
	$DSetComp$		& $¬{vs|p}®$		& No			& 	\\ \hline
	$DList$			& $¬[t1; t2; t3]®$	& No			& 	\\ \hline
	$DEmptyList$		& $¬[]®$		& No			& 	\\ \hline
	$Dµ$			& $¬µ vs· p®$		& Yes			& 	\\ \hline
	$D¶$			& $¬¶ vs· p®$		& Yes			& 	\\ \hline
	$D¶‰1$			& $¬¶‰1 vs· p®$		& Yes			& 	\\ \hline
	$DÅ$			& $¬Å vs· p®$		& Yes			& 	\\ \hline
	$DIf$			& $¬if p then t1 else t2®$	& No			& 	\\ \hline
	$Dî$			& $¬157®$		& No			& 	\\ \hline
	$DChar$			& $¬`c`®$		& No			& 	\\ \hline
	$DString$		& $¬"abcd"®$		& No			& 	\\ \hline
\end{tabular}

We can compare the primitive and derived syntax using a simple example of an enumerated set:
=GFT ML Session
:> ¬{a;b;c}®;
val it = ¬{a; b; c}® : TERM   
:> dest_term it;
val it = DEnumSet [¬a®, ¬b®, ¬c®] : DEST_TERM   
=TEX
Now using $dest\_simple\_term$, we see that this is ``really'' a function application:
=GFT ML Session
:> ¬{a;b;c}®;
val it = ¬{a; b; c}® : TERM   
:> dest_simple_term it;
val it = App (¬Insert a®, ¬{b; c}®) : DEST_SIMPLE_TERM
=TEX
%--------------------------------------------------------------------
\subsection{Library and User Extensions}
The functions described in \ref{Derived Terms} implement the basic abstract syntax of ICL~HOL, but
an important feature of the language is user extenbsibility.
Thus, by the introduction of new constants (with their logical and lexicographic properties),
the user can extend the syntax of the language as he chooses.
In fact, such extensions are made in library theories delivered as part of the basic system.
The following example is taken from the theory $î$.
=GFT ML Session
:> ¬5 + 7®;
val it = ¬5 + 7® : TERM   
:> dest_term it;
val it = DApp (¬$+ 5®, ¬7®) : DEST_TERM   
:> val DApp(it,_) = it;
val it = ¬$+ 5® : TERM   
:> dest_term it;
val it = DApp (¬$+®, ¬5®) : DEST_TERM   
:> val DApp(it,_) = it;
val it = ¬$+® : TERM   
:> dest_term it;
val it = DConst ("+", ¬:î ­ î ­ î®) : DEST_TERM   
=TEX
Note that the parser and pretty printer can handle this term quite smoothly, it is only when we delve into the 
abstract syntax that we notice a difference.
This should not normally be a problem, since we usually interact with the system through the concrete syntax, but 
we can give the effect of an extension to the abstract syntax by simply defining shorthand meta-language functions
which look like abstract syntax constructors etc.
This is, in fact, always done in ICL supplied library theories.
=GFT ML Session
:> mk_plus(¬5®,¬7®);
val it = ¬5 + 7® : TERM   
:> dest_plus it;
val it = (¬5®, ¬7®) : TERM * TERM   
=TEX

\section{Declarations}
In the kernel interface module, 
there are the primitive tools for introducing new types and constants.
However, the user will want more advanced interfaces 
which allow consistency proofs to be deferred, or performed automatically,
and which have results that have a pleasant printed form.
In particular, the HOL/Z option, \cite{DS/FMU/IED/HLD015},
will require tools to support the processing of Z schema definitions, etc.

These tools support:
\begin{itemize}
\item
The specification of constants with the proof obligation deferred.
As a result of the specification the user should be able
to get a defining theorem, whose conclusion is
the predicate of the specification, by a function whose only argument is one of the constants specified.
\item
The introduction of a labelled product type.
\item
The introduction of an unlabelled product type.
\item
The provision of a general purpose theory cache mechanism.
\end{itemize}
In addition to these requirements, we also want to be able to automatically prove
a subset of the possible proof obligations during the processing of a specification.
In this case the proof obligation will be an existentially quantified term,
so we are calling for an automated existence prover.
If the proof obligation cannot be proven then this
will be indicated to the user by returning a defining theorem with
a proof obligation assumption expressing the required proof.

\subsection{Constant Specification}

This module provides the actual constant specification tool.
It also gives a function providing convenient access to the defining theorem
%, as discussed in section \ref{UserInterface}
.
This function is further supported by a method to push a proof obligation onto the subgoal package
and another to save the result in the correct place to be accessed.
The user interface to the constant specification tool processes source text that is printed in the form:
¹HOLCONST 
	decls
÷
	pred
°
The processing of this source text requires treatment of ``extended Standard ML text'' as described in \cite{DS/FMU/IED/HLD008}.

\subsubsection{$const\_spec$}
$const\_spec$ $(keys$, $varstructs$, $predicate)$
declares constants matching the names and types of those in $varstructs$, with the property that, if $predicate$
holds for some list of values, then it holds for the constants
in question,
with the definition saved under each of $keys$.
In addition, if the existence prover held in the current proof context, and accessed by $current\_cs\_¶\_conv$, can
prove the predicate is satisfied for some witness
(i.e. $¤\ T$), the
specification will instead be made without the caveat.
In more detail, if the list of free variables in $varstructs$ is
$c_1$ $...$ $c_n$, and the predicate is of the form $P[$ $c_1$ $...$ $c_n$ $]:BOOL$, then the specification of constants $c_1$ $...$ $c_n$
(with same names and types as the variables)
will be:
=GFT
ô ConstSpec (Ì (x_1, ..., x_n) · P[x1,...,xn]) (c1,...,cn)
=TEX

where each $x_i$ is a variant (see $list\_variant$) of $c_i$, not present in the original list of variables, or the predicate,
and the $c_i$ become constants.

However, if we can automatically prove:
=INLINEFT
¶ c1 ... cn · P[c1,...,cn]
=TEX

Then instead the specification will be:
=INLINEFT
ô P [c1,...,cn]
=TEX

There are a number of caveats on the production of the specification:
there must be no duplicates in $varstructs$;
all the constant's types must have the same set of type variables;
there must be no type variables in the body of $predicate$ other
than those already in the constant's types;
and there must be at least one key.

\subsubsection{$get\_spec$}

$get\_spec$ $const$ will find the (first) definition in scope
stored under key $const$, in the theory in which the in-scope constant named $const$ was defined.
If ICL conventions have been followed, then such a definition should be the definition of the constant named $const$.
In addition, there can only be one definition of a particular constant in scope (though the conventional key might be used elsewhere, or not at all).
If there is no such constant in scope, or no definition with the given key, then the function fails.

If the definitional theorem is not of the form:
=GFT
ô ConstSpec p c
=TEX

then the theorem is returned un-processed - if properly saved then it either comes from
$(simple\_)$ $new\-\_defn$ , $new\-\_speci\-fication$, or predicate $p$ was automatically proven
consistent by $const\-\_spec$.

Otherwise, the function will seek for a theorem stored with key
$const$ $\verb"^"$ ``$\_consistent$'', starting at the theory in which the definition was found, and working ``out'' to the current theory.
If conventions have been followed this theorem should be of the form:
=GFT
‡ ô Consistent p
=TEX

(Ideally there should be no assumptions in the theorem, but
the function caters for their presence.)
If a theorem of this form is found then the function returns:
=GFT
%beta%_rule `‡ ô p c`
=TEX

If not, then the function returns a theorem of the form:
=GFT
%beta%_rule `Consistent p ô p c`
=TEX

\subsubsection{$push\_consistency\_goal$}
$push\_consistency\_goal$ $const$ will 
first determine the specification theorem of $nm$,
by executing $get\_spec$.
If this theorem has an assumption,
it will then push that specification assumption onto the stack of subgoals (using $push\_subgoal$, q.v.), as a goal with no assumptions.
By how $get\_spec$ is designed, this (single) assumption
will be of the form
=GFT
¬Consistent (Ì vs[x1,...,xn]·p[x1,...,xn])®
=TEX

or the consistency has already been proven, and saved, under some assumptions.
Only in the former case will the function continue:
it will apply a tactic (that may be undone by $undo$) which
rewrites the goal to precisely:
=GFT
([], ¬¶ vs[x1,...,xn]·p[x1,...,xn]®)
=TEX

If not, the function fails.

\subsubsection{$save\_consistency\_thm$}
$save\_consistency\_thm$ $nm$ $thm$ expects $thm$ to be of the form
=GFT
‡ ô Consistent (Ì vs[x1,...,xn]·p[x1,...,xn])
=TEX

where $vs$ forms a varstruct from the simple variables $x_i$.
The predicate proven consistent is then expected to be the same
as predicate in the $const\_spec$ definition of $nm$.
If so, the theorem will be saved under the keys
$c1\_consistent$, ..., $cn\_consistent$,
where the $c_i$ are the names of all the constants defined in the 
definition in question.

Ideally there should be no assumptions in the theorem, but
the function caters for their presence.

\subsubsection{Counter Examples}
The conditions imposed by the primitive
conservative extension mechanisms.
lead to restrictions on the forms of predicates
allowed in constant specifications. Examples showing the need for these
restrictions are given here.

The restrictions which are imposed on constant
specifications are that no types appear in the predicate
which do not appear in the type of each new constant
and that the predicate contains no free variables other
than those corresponding to the new constants (this latter
restriction being taken to mean that the universal
closure over any such variables is used if necessary).

To understand the restrictions on the types consider
the following:
=GFT Example of Restriction on Types in Constant Specification
	c : BOOL,
÷
	c ¤ (¶x y:'a·³(x = y)
°

If this were allowed, then there would be no
difficulty in proving the consistency proposition and
the defining theorem resulting would be:
=GFT Example Defining Theorem
ô	c ¤ (¶x y:'a·³(x = y)

=TEX
By instantiating ``$:'a$'' to the one element type ``$:ONE$'
and the two element type ``$:BOOL$'', we could
could infer the following theorems
=GFT Example Theorems
ô	c ¤ (¶x y:ONE·³(x = y)
ô	c ¤ F
ô	³c
=TEX
and 
=GFT Example Theorems
ô	c ¤ (¶x y:BOOL·³(x = y)
ô	c ¤ T
ô	c
=TEX
Thus the resulting theory is inconsistent.

To understand the restrictions on the free variables consider
the following:
=GFT Example of Restriction on Types in Constant Specification
	d : BOOL,
÷
	d ¤ x
°

(where x is a variable). Again the consistency
proposition would be easy to prove and this would lead to the following
defining theorem:
=GFT Example Defining Theorem
ô	d ¤ x
=TEX
By instantiating $x$ here to $T$ and then $F$ we may
derive the contradictory theorems:
=GFT Example Theorems
ô	d
ô	³d
=TEX
and again we have an inconsistent theory.

\subsection{Existence Proofs}
This module provides various methods of proving or simplifying some existentially quantified terms.
In particular it provides an inference rule for proving a subset
of the possible proof obligations arising during the specification of constants.

\subsubsection{$prove\_\exists\_conv$}
This conversion uses its internal mechanisms, and material stored in the current proof context, to attempt to prove a ``simpler'' term
equal to its argument, which must be of the
form $¬¶ ...®$.
It will simplify by:
\begin{itemize}
\item
Converting paired existential quantifiers into simple ones (see $all\-\_¶\-\_uncurry\-\_conv$).
\item
Removing existential and universal quantifiers not used in the body of their
quantification.
\item
Distributing existential quantifiers over $±$ and $²$ as far
as it is able (see $simple\_¶\_±\_conv$ and $simple\_¶\_²\_conv$).
\item
Eliminating an existential quantifier that is equated to 
a term within the body of the quantification.
Implicit equations (e.g. an implicit $¤\ T$ or by $³$) are also handled
(see $simple\_¶\-\_equation\-\_conv$ for caveats).
\item
``Pulling out'' universal quantifiers through existential
quantifiers if the existential is a function applied in all its instances
to the universally quantified variables
(see $simple\-\_¶\-\_µ\-\_conv1$), or variable structures
formed by data constructors accessed by $current\-\_ad\-\_¶\-\_vs\-\_thms$ in the current proof context.
Redistribution of universals and data constructions may be done to allow this simplification to apply
(see $µ\-\_±\-\_conv$).
\item
Uncurrying existential quantifiers that are curried functions.
\item
Simplifying existential quantifiers that match the pattern of
use of recursive functions held by $current\-\_ad\-\_¶\_cd\_thms$ in the current proof context.
\item
Traversing subterms reached from the outside of the term through (perhaps paired)
existential and universal quantifiers, and $±$ or $²$ operators.
\end{itemize}
It will repeat its simplification attempts until it can go no further.
=FRULE 1 Conversion
prove_¶_conv
¬¶ decls· pred®
÷
÷
ô (¶ decls· pred) ¤ simpler
°
=TEX

\subsubsection{$prove\_\exists\_rule$}
This will attempt to simplify its argument to $T$, by using 
$prove\_¶\_conv$ (q.v.).
If it succeeds, it returns the theorem with $¤\ T$ stripped off.
=FRULE 1 Rule
prove_¶_rule
¬¶ decls· pred®
÷
÷
ô ¶ decls· pred
°
=TEX

\subsubsection{$prove\_\exists\_tac$}
This will attempt to prove its goal, by using 
$prove\_¶\_conv$ (q.v.).
If $prove\_¶\_conv$ fails, or only partially succeeds,
then the tactic will fail.
=FRULE 2 Tactic
prove_¶_tac
÷
{ ‡ } ¶ decls· pred
÷
°
=TEX

\subsection{Product Types}


This module provides two functions to introduce labelled and unlabelled product types respectively.
These are each supported by theorem caches
%, that may be directly initialised (i.e given a starting set of theorems)
.
The theorems in the caches will not be directly of interest to the user, they only speed up the production of the declarations.
The caches may be distributed over various theories by further utility functions provided in the module%, as discussed in section \ref{DataStorage}
.
These utility functions allow a list of cache theories to be nominated and accessed,
and each individual cache will be drawn from entries in a subset of these theories.
These utility functions are of broader use than in handling product types, for they can be used for any function that caches
material into theories, and their purpose is to limit the number of theories searched for cached information.

The user interface to the labelled product tool processes source text that is printed in the form:
¹HOLLABPROD TYPENAME
	label1 : TYPE1;
	label2 : TYPE2;
	... : ...
°
which is created as follows:
=GFT
 ¹HOLLABPROD TYPENAME
	label1 : TYPE1;
	label2 : TYPE2;
	... : ...
°
=TEX
The user interface makes an appropriate call on the underlying function $labelled\_product\_spec$, which is described in section \ref{labelled_product_spec} below.
There is no corresponding interface for unlabelled products, which must be made using $unlabelled\_product\_spec$ (section \ref{unlabelled_product_spec}) directly.

\subsubsection{$labelled\_product\_spec$}
\label{labelled_product_spec}
This function
introduces a labelled product type, and its constructor and projection functions.
Its argument's fields are:

\hspace{0.5in}
\begin{minipage}[t]{5in}
\begin{tabular}{ll}
tyname&
\parbox[t]{4in}{The name of the new type.} \\
tykey&
\parbox[t]{4in}{The key under which the defining theorem for the type will be saved.} \\
conname&
\parbox[t]{4in}{The name of the single constructor of the new type.
It will be a curried function, from each of the label types, in turn, to the new type.} \\
constkeys&
\parbox[t]{4in}{The keys under which the defining theorem for the 
constructor $conname$ and projection functions will be saved.} \\
labels&
\parbox[t]{4in}{The list of the names and types of the labelled fields in the new type. 
A projection function will be defined for each label,
a single defining theorem for all will be saved under the keys $constkeys$.
It is this defining theorem that is the result of the function call.} \\
tyvars&
\parbox[t]{4in}{If this field is $Nil$ then the type variables in the new type will be ordered as their occurrence in $labels$, otherwise as stated by this parameter.} \\
\end{tabular}
\end{minipage}
If the appropriate tuple theorem is not already in scope a call of $cached\-\_labelled\-\_product\-\_rule$ $(length$ $labels)$ will also be made as a side effect.
=EXAMPLE
:> labelled_product_spec {tyname="PAIR", tykey="PAIR", conname="Comma",
	constkeys=["Comma","First","Second","pair_ops_def"], 
		labels=[("First",¬:'f®),("Second",¬:'s®)], tyvars=Value[¬:'s®,¬:'f®]};
=TEX
will cause
=GFT
ô ¶ f : ('s, 'f) PAIR ­ ('f ¸ 's) · TypeDefn (Ì x · T) f
=TEX
to be saved under the key "PAIR", and the following
=GFT
ô µ t · µ (x1:'f) (x2:'s)· (
	First(Comma x1 x2) = x1 ± 
	Second(Comma x1 x2) = x2 ± 
	Comma (First t) (Second t) = t)
=TEX
under keys "Comma", "First", "Second" and "pair\_ops\_def", and returned as the result.
=TEX
\subsubsection{$unlabelled\_product\_spec$}
\label{unlabelled_product_spec}
This function introduces an unlabelled product type
Its argument's fields are:

\hspace{0.5in}
\begin{minipage}[t]{5in}
\begin{tabular}{ll}
tyname&
\parbox[t]{4in}{The name of the new type.} \\
tykey&
\parbox[t]{4in}{The key under which the defining theorem for the type will be saved.} \\
conname&
\parbox[t]{4in}{The name of the single constructor of the new type.
It will be a curried function, from each of the types $tyi$, in turn, to the new type.} \\
conkeys&
\parbox[t]{4in}{The keys under which the defining theorem for the 
constructor $conname$ will be saved.} \\
tyi&
\parbox[t]{4in}{The list of the types of the fields in the new type.} \\
tyvars&
\parbox[t]{4in}{If this field is $Nil$ then the type variables in the new type will be ordered as their occurrence in $labels$, otherwise as stated by this parameter.} \\
\end{tabular}
\end{minipage}

If the appropriate tuple theorem is not already in scope a call of $cached\-\_unlabelled\-\_product\-\_rule$ $(length$ $tyi)$ will also be made as a side effect.
This is as part of the speeding up of introducing the new type.
=EXAMPLE
:> unlabelled_product_spec {tyname="UPAIR", tykey="UPAIR", conname="UComma",
	conkeys=["UComma","ucomma_def"], tyi=[¬:'f®, ¬:'s®], tyvars=Nil};
=TEX
will cause
=GFT
ô ¶ f : ('f, 's) UPAIR ­ ('f ¸ 's) · TypeDefn (Ì x · T) f
=TEX
to be saved under the key "UPAIR", and
=GFT
ô (µ (x1:'f) (x2:'s)· µ y1 y2·
	(UComma x1 x2 = UComma y1 y2) ¤ (x1 = y1) ± (x2 = y2))
	±
	(µ t · ¶ x1 x2 · t = UComma x1 x2)
=TEX
to be saved under the keys "UComma" and "ucomma\_def", and returned as the result.
=TEX
