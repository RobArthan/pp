=IGN
********************************************************************************
dtd096.doc: this file is part of the PPHol system

Copyright (c) 2016 Lemma 1 Ltd.

See the file LICENSE for your rights to use and change this file.

Contact: Rob Arthan < rda@lemma-one.com >
********************************************************************************
=TEX
\documentclass[a4paper,12pt]{article}

%%%%% YOU CAN ADD OTHER PACKAGES AS NEEDED BELOW:
\usepackage{A4}
\usepackage{Lemma1}
\usepackage{ProofPower}
\usepackage{epsf}
\makeindex

\def\Title{Detailed Design for sieve and findfile utilities}

\def\Abstract{\begin{center}
{\bf Abstract}\par\parbox{0.7\hsize}
{\small This document gives the detailed design for the sieve and finfile utilities.}
\end{center}}

\def\Reference{LEMMA1/HOL/DTD096}

\def\Author{R.B.~Jones}

\def\EMail{{\tt rbj@rbjones.com}}

%%%%% YOU MAY WANT TO CHANGE THE FOLLOWING TO GET A NICE FRONT PAGE:
\def\FrontPageTitle{ {\huge \Title } }
\def\FrontPageHeader{\raisebox{16ex}{\begin{tabular}[t]{c}
\bf Copyright \copyright\ : Lemma 1 Ltd \number\year\\\strut\\
\end{tabular}}}
\begin{centering}



\end{centering}

%%%%% THE FOLLOWING DEFAULTS WILL GENERALLY BE RIGHT:

\def\Version{\VCVersion}
\def\Date{\FormatDate{\VCDate}}

%%%%% NOW BEGIN THE DOCUMENT AND MAKE THE FRONT PAGE

\begin{document}
\headsep=0mm
\FrontPage
\headsep=10mm

%%%%% STANDARD RED-TAPE SECTIONS (MAY WANT TO INTERLEAVE SOME \newpage COMMANDS IN THESE)

%%%%% CONTENTS:

\subsection{Contents}

\tableofcontents

%%%%% REFERENCES:

\newpage
\subsection{References}

\bibliographystyle{fmu}

%%%%% CHANGE THE FOLLOWING AS NECESSARY (E.G., TO PICK UP daz.bib):
{\raggedright
\bibliography{fmu}
}
%%%%% CHANGES HISTORY:
\subsection{Changes History}
\begin{description}
\item[2016/08/27]
First working draft (as dtd123) arising from port of pputf8 contrib into pptex.
\item[2016/12/]
Conversion to dtd096 as imp123 is incorporated into imp096, providing a first cut implementation of pputf8 and utf8pp in {\Product} 

%%%% END OF CHANGES HISTORY %%%%
\end{description}

%%%%%  CHANGES FORECAST:

\subsection{Changes Forecast}

None.

%%%%% DISTRIBUTION LIST

\subsection{Distribution}

Lemma 1 build system.

\newpage

\section{Introduction}
\subsection{Scope}
This document is the detailed design document for the sieve and findfile utilities in {\Product}.

However, its scope is limited, the principal documentation for these utilities being USR001.
It primarily covers the changes to {\Product} for the support of utf8, and initial drafts will be simple copies of the principal correspondence discussing how this should be done.

\subsection{Purpose and Background}
See \cite{DS/FMU/IED/HLD011}.

This document is now being used as top level documentation for the proposed implementation of utf8 support in \Product{}, since the main action is in {\tt sieve}.

\section{Support for utf8 UNICODE in {\Product}}

\subsection{Goals}

The PPTex package is to support UTF-8 encoded Unicode mark-up in ProofPower documents.
It will continue to support the ProofPower 8-bit encoded extended character set (hereafter referred
to as EXT), with some qualification in relation to the distributed concatenation operator, which is being phased out.
It will continue to support the ProofPower ASCII encoding.
It will support conversion to and from all three formats.
The ASCII encoding can be used in documents that also use the EXT encoding and it will be supported in documents that use the UTF-8 encoding.
There is no requirement to support documents involving a mixture of UTF-8 and EXT.
The full UNICODE code set is supported in all document types, in the ASCII format through the use of percent keywords, either giving the UNICODE code point, or a keyword which has been declared in a {\tt sievekeyword} file to be synonymous with some code point.
A reconciliation will be undertaken between the keywords at present used in \Product{} and those in the set nominated in the MathML standard, and a {\tt sievekeyword} file will be supplied containing the resulting keyword definitions.

The PPXpp package is to support UTF-8 encoded Unicode mark-up as far as is possible with
the OpenMotif GUI technology.
This will be done by translation from the chosen file encoding to the \Product{} extended character set supplemented as required by percent keywords as names or for code points for which no name has been declared, as codes.


\subsubsection{Observations}

The use of a Byte-Order-Marker to identify a file as using UTF-8 encodings seems to
be deprecated.

The long term goal is for UTF-8 to supersede EXT.

MathML defines XML entity names for a lot of the symbols we need (and many more).
Adopting these names will give a user-friendly alternative to numeric code points.

Assumption: the distribution concatenation symbol can be removed and everywhere replaced
by its two character equivalent. 
The conversions from extended character set files will continue to accept the distributed concatenation code, but the conversion to the extended character set will not make use of the character, and the \Product{} Reader/Writer will expand it on input, but not compress on output.

At Phil Clayton‚Äôs (nice) suggestion, the ProofPower mapping currently maps the greek
letters to the corresponding code points for Mathematical Alphanumeric Symbols in the range
1D400‚Äì1D7FF. The MathML entities use the code points for Greek in the range 0370‚Äì03FF.
The Mathematical Greek Symbols do look nice, but to gain compatibility with MathML,
we would like to revert to using the code points for Greek in the range 0370-03FF.
This will also allow you to enter Greek by switching to a  standard Greek keyboard mapping.
In passing we will also use the right symbol for $\phi$ (the current mapping uses what LaTeX
calls ``\\varphi'' rather than ``\\phi'').

\subsubsection{Background}

The contrib package PPUtf8 defines a mapping from EXT and UTF-8 and provides filters
to convert between the two formats.

The PPHol packages provide support for input and output using either EXT or UTF-8.

The PPTex package provides a program called sieve which supports conversion
between EXT and ASCII encodings and projection onto SML, TeX and other formats
for further processing.

\subsubsection{Approach}

Removal of distributed concatenation character: remove uses of this character from PPZed.
Rationalise UTF-8 support in PPHol (module 122) as EXT characters now map to a single Unicode code point and not a list.

[Not convinced by this, it seems to me to raise difficulties on the transition, which are best avoided by continuing to expand the extended character.]

\subsubsection{sieve}

Sieve will be enhanced so that keywords of the form %#xXXXXXX% and %#NNNNNN%
are predefined (where XXXXXX and NNNNNN represent case-insensitive (?) hexadecimal
and decimal representations of a valid Unicode code point).
The optional numeric encoding of a code for a glyph in the sieve keyword file entries will now be interpreted as a Unicode code point.

A fixed mapping from extended characters to UNICODE code points will be used, rather than including this in the {\tt sievekeyword} file.

Using the existing sameas mechanism, we can then implement the MathML entity names.
This involves a certain amount of reconciliation in the handful of cases where existing
ProofPower entity names conflict with MathML. Some adjustments to the existing mapping
from EXT to UTF-8 might be needed (e.g., it was a nice idea to change to using
the mathematical greek characters, but it might be better to revert for conformance with MathML).

Module 122 from PPHol and the modules from PPDev that it depends on will
be moved into PPTex and replaced by links in PPHol and/or PPDev. They will
be used in a build-time script to generate the part of the sieve keyword file
that identifies Unicode code points with their EXT encoding. [Alternatively,
this could just be extracted with a sed or perl script. Or [RDA preference] we could do it the other
way round and generate the table in imp122.doc from a file of extchar entries in the PPTex
source.

sieve will have command line options to select between UTF-8 and EXT on inputs and
outputs (independently so all 4 directions of conversion are possible). The driver
scripts (doctex etc.) will define a new file name extension for UTF-8 encoded
documents. We need to think through the options for the outputs of these scripts
on case-by-case basis. E.g., would it be prudent for docsml to output ASCII only?

\subsection{Unicode Mapping for ProofPower}

The version documented in this subsection is the mapping for the original extended codes in which one of these codes maps to a sequence of two UNICODE code points.
It is now intended to eliminate this anomoly as part of the UNICODE support transition.

The mapping is defined in terms of a basic translation table, which,
subject to some additional rules, defines a translation
from ProofPower to Unicode or from Unicode to ProofPower.
There are some notes giving the rationale for the mapping.

\subsubsection{Basic Translation Table}

The following table gives a one-to-one mapping from a subset of
the ProofPower extended character set to the Unicode
character set.
The range of the mapping includes all the ProofPower extended characters
with the exception of the byte 0x8B.

The LaTeX column contains GIFs showing the typeset form of each character
(produced using dvipng). The GIFs should display properly in any browser
without any Unicode support.  The Unicode column shows the corresponding
Unicode glyph as rendered by your web browser.

\subsubsection{ProofPower to Unicode}

Translating ProofPower into Unicode converts a stream of bytes into a stream of Unicode code points.
An ASCII string of the form ''%x\emph{HHHHHH}%", where \emph{HHHHHH}
is a string of 6 upper-case hexadecimal digits representing a value in the range
0x000100 to 0x10FFFF, is translated into the Unicode code point with that value.
Strings of this form are identified reading from left to right.
Any byte in the range 0x00 to 0x7F not appearing in
such a string is translated into the Unicode code point with the same numeric value.

A byte in the range 0x80 to 0xFF other than 0x8B is translated
into the Unicode code point identified in the basic translation table above.
0x8B was previously translated into two characters but is now withdrawn and may be reassigned.

\subsubsection{Unicode to ProofPower}

Translating Unicode converts a stream of code points into a stream of bytes.

A Unicode code point in the range 0x000000 to 0x00007F is
translated into the byte with the same numeric value.
A Unicode code point listed in the Code Point column in the basic translation table is translated into the byte with the numeric value given in the Byte column.
A Unicode code point in the range 0x000080 to 0x10FFFF that is not listed in the basic translation table
is translated into the ASCII string "%x\emph{HHHHHH}%", where \emph{HHHHHH} represents the value of the code
point as 6 upper-case hexadecimal digits.

\subsubsection{Rationale}

The mapping for Z symbols (other than paragraph mark-up) follows the ISO Z
Standard Unicode mark-up.  An exception is that the ASCII minus sign is
translated unchanged while the unary minus sign 0xF8 is translated into SMALL
HYPHEN-MINUS. Unfortunately, SMALL HYPHEN-MINUS often seems to be rendered
bigger than HYPHEN-MINUS.

Unicode does not provide any single glyphs that resemble
the decorated Quine corners provided in the ProofPower character set
for quoting HOL types, ML and Z. Squared letters T, M and Z have been
used as a convenient single character translation for these.

The %x\emph{HHHHHH}% format allows any code point to be used in a ProofPower identifier.
Strings of this form are highly unlikely to occur in existing scripts and so there is no requirement for a string of this form to be translated into Unicode as 9 ASCII characters.

\section{CONVERSION TABLES}

Two conversion tables are required .

The first is the mapping of \Product{} extended codes to unicode code points.
This is a fixed mapping, having one definitive version as an SML definition, which is used to generate other versions as required, and incorporated into the \Product{} build as required by inclusion from other parts of the build.
This is done for the structure Unicode, which makes the \Product{} to utf8 mapping in an SML structure in \Product{}, and may also be imported into the Reader/Writer.
The table is also used to generate C header files used by sieve to implement {\tt pputf8} and {\tt utf8pp}.

I had originally naively supposed the SML table could be included with a DUMP directive in imp096, but the dump would have to be done by {\tt sieve} so there is a chicken and egg problem here, so the following two little sections need to be reconsidered.

\subsection{C Header Files}

This module creates two C header files ppunicodetab.h and unicodepptab.h containing tables defining the mapping between \Product{} extended character codes and unicode points.

The header files are available for use by any other programs which might undertake similar translations, the programs are supplied as a part of \Product{} release.

=SML
structure PPUtf8 = struct
local
structure €W› = Word;
structure €C› = SML97BasisLibrary.Char;
structure €S› = SML97BasisLibrary.String;
in
(*
=TEX
The following reconstructs the basic translation table using the Unicode structure from imp122.
=SML
*)

=IGN
	use"dtd108.sml"; use"imp108.sml"; 
	use"dtd002.sml"; use"imp002.sml"; 
	use"dtd001.sml"; use"imp001.sml";
	use"dtd122.sml"; use"imp122.sml";
	use"dtd096.sml";
=SML

val pp_to_unicode_basic_translation = List.tabulate (128,
    fn x:int => let val c = C.chr(x+128)
       	    in ((c, hd(PPUnicode.pp_to_unicode c)))
	    end);
(*
=TEX
Now we sort the table to give a table suitable for translation from UNICODE to extended pp characters.
=SML
*)
fun €pad_string› (width : int)  (s : string) : string = (
	let	fun zeroes i = if i <= 0 then "" else "0" ^ zeroes (i-1);
	in	zeroes (width - size s) ^ s
	end
);

val char_order : char ORDER = (fn c1 => fn c2 => C.ord c1 - C.ord c2);

val byte_string_order : string ORDER = (fn s1 => fn s2 =>
	lexicographic char_order (S.explode s1) (S.explode s2)
);

val unicode_order:UNICODE ORDER = fn u1 => fn u2 => byte_string_order
    (pad_string 6 (PPUnicode.unicode_to_hex_string u1))
    (pad_string 6 (PPUnicode.unicode_to_hex_string u2));

val €unicode_to_pp_ordered_tab› : (UNICODE * char) list = 
	(sort (pair_order unicode_order char_order) o map swap) 
		pp_to_unicode_basic_translation;
(*
=TEX
The rest of the code outputs the two C header files: ppunicodetab.h and unicodepptab.h
=SML
*)

fun €word_to_string› (width : int)  (w : word) : string =
    	pad_string width (Word.toString w);

fun €c_hex_string_of_char› (c : char) : string = (
	"\\x" ^ (word_to_string 2 o W.fromInt o C.ord) c
);

fun €c_hex_string_of_string› (s : string) : string = (
	implode(map c_hex_string_of_char(S.explode s))
);

fun €c_pp_to_unicode› (outfile : string) : unit = (
	let	val strm = open_out outfile;
		fun say s = output(strm, s);
		fun aux i = (
			let	val s = PPUnicode.unicode_to_hex_string
				    (hd(PPUnicode.pp_to_unicode (C.chr i)));
				val text = "0x" ^ (pad_string 6 s);
			in	say "\t\"";
				say text;
				(if	i < 255
				then	(say "\",\n";
					aux (i+1))
				else	say "\"\n")
			end
		);
	in	say (
"/*\n * " ^
 outfile ^ ": automatically generated by dtd096.ML.\n * " ^
 Date.toString (Date.fromTimeLocal(Time.now())) ^ "\n" ^
" * Conversion from ProofPower characters to utf8 strings is done\n" ^
" * by obtaining the unicode code point using an indexed lookup in the following array:\n" ^
" */\n");
		say "static const char *pp_to_unicode [128] = {\n";
		aux 128;
		say "};\n";
		close_out strm
	end
);


fun €c_unicode_to_pp› (outfile : string) : unit = (
	let	val strm = open_out outfile;
		fun say s = output(strm, s);
		fun aux ((u, c) :: more) = (
			let	val text1 = "0x" ^ (pad_string 6 (unicode_to_hex_string u));
				val text2 = c_hex_string_of_char c;
			in	say "\t{";
				say text1;
				say ", \"";
				say text2;
				(case more of
				 _ :: _	=> 	(
					say "\"},\n";
					aux more
				) | _	=>	say "\"}\n")
			end
		) | aux [] = ();
	in	say (
"/*\n * " ^
 outfile ^ ": automatically generated by utf8.ML.\n * " ^
  Date.toString (Date.fromTimeLocal(Time.now())) ^ "\n" ^
" * Conversion from UTF-8 encoded character to a string of 1 or more\n" ^
" * ProofPower extended characters is done by an associative lookup\n" ^
" * in the following sorted array of records:\n" ^
" */\n" ^
"typedef int unicode;\n" ^
"typedef struct {\n" ^
"\tunicode code_point;\n" ^
"\tconst char *pp_string;} utf8_to_pp_entry;\n");
		say "#define UNICODE_TO_PP_LEN ";
		say(string_of_int (length unicode_to_pp_ordered_tab));
		say "\nstatic unicode_to_pp_entry unicode_to_pp [UNICODE_TO_PP_LEN] = {\n";
		aux unicode_to_pp_ordered_tab;
		say "};\n";
		close_out strm
	end
);

val _ =
(*	if length utf8_to_pp_tab <> length pp_to_utf8_tab
	then	diag_line "WARNING: duplicate entries lost from utf8_to_pp_tab"
	else *)	();

val _ = c_pp_to_unicode "ppunicodetab.h";
val _ = c_unicode_to_pp "unicodepptab.h";

end (* of local ... in ... end *);
end (* of structure PPUtf8 *);
=TEX

\section{PLAN}

Very crude at this point:

\begin{itemize}
\item[First]
get the SML table and the {\tt .h} files in place to define the correspondence between the \Product{} extended characters and UNICODE code points.
Also generate a {\tt sievekeyword} file from the mathml entities {\tt .json}.

\item[Then], possibly concurrently:

\begin{itemize}
\item do the changes to {\tt sieve}.
\item do the changes to xpp
\item change reader/writer
\end{itemize}
\end{itemize}




\section{TEST POLICY}
There are no special module test requirements.
\twocolumn[\section{INDEX}]
\small
\printindex

\end{document}







