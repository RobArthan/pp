% imp501.doc   %Z% $Date$ $Revision$ $RCSfile$
=TEX
\documentstyle[hol1,11pt,TQ]{article}
\ftlinepenalty=9999
\def\Hide#1{}
\def\Bool{``$\it{:}bool\,$''}
\makeindex
\TPPproject{DAZ PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Implementation: Compliance Notation Lexical Analyser}  %% Mandatory field
\TPPref{ISS/HAT/DAZ/IMP501}  %% Mandatory field
\def\SCCSversion{$Revision$%
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date$%
}}
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{Specification}
\TPPkeywords{HOL}
\TPPauthor{D.J.~King & WIN01}  %% Mandatory field
%\TPPauthors{Name 1&location 1\\Name 2&location 2\\Name 3&location 3}
\TPPauthorisation{D.J.~King & DAZ Team Leader}
\TPPabstract{
This document contains the implementation for the CN 
parser.}
%\TPPabstractB{}
%\TPPabstractC{}
%\TPPabstractD{}
%\TPPabstractE{}
%\TPPabstractF{}
\TPPdistribution{\parbox[t]{4.0in}{%
	Library}}

%\TPPclass{CLASSIFICATION}
%\def\TPPheadlhs{}
%\def\TPPheadcentre{}
%def\TPPheadrhs{}
%\def\TPPfootlhs{}
%\def\TPPfootcentre{}
%\def\TPPfootrhs{}

\begin{document}
\TPPsetsizes
\makeTPPfrontpage

\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}

\newpage
\section{DOCUMENT CONTROL}
\subsection{Contents List}
\tableofcontents
\subsection{Document Cross References}
\bibliographystyle{fmu}
\bibliography{fmu,daz}

\subsection{Changes History}  % to get section number `0.3'
\begin{description}

\item[Issues 1.1-1.28] Initial Versions.
\item[Issue 1.29-1.31] Annotations and pragmas enhancements.

\end{description}
\subsection{Changes Forecast}
\pagebreak
\section{GENERAL}
\subsection{Scope}
This document contains the implementation for the lexical analyser and the
lexis for CN.
The detailed design for this material is in \cite{ISS/HAT/DAZ/DTD501}.

\subsection{Introduction}

\subsection{Purpose and Background}

\subsection{Algorithms}

\subsection{Dependencies}

\subsection{Known Deficencies}

\subsection{Possible Enhancements}

\section{CASE INDEPENDENCE}
=SML
structure €CaseIndependence› : CaseIndependence = struct
=TEX
=SML
val ordA = ord "A";
val orda = ord "a";
val ordQ = 81 (* explicit because R/Writer converts Qs. *);
=TEX
=SML
fun €to_lower› (s : string) : string = (
let	fun aux1 (all as (c1::c2::c3::rest)) = (
		if ord c1 = ordQ andalso ord c2 = ordQ andalso ord c3 = ordQ
		then
			("q", rest)
		else
			("", all)
	) | aux1 other = ("", other);
	fun aux (c::rest) = (
		if ord c = ordQ then 
			let	val (c', rest') = aux1 rest;
			in
				c'::aux rest'
			end
		else
		if c >= "A" andalso c <= "Z"
		then
			(chr(ord c - ordA + orda))::aux rest
		else
			c::aux rest
	) | aux _ = [];
in
	(implode o aux o explode) s
end);
=TEX
=SML
fun €to_upper› (s : string) : string = (
	let fun aux ch = (
		if ch = "q" then "Q"
		else
		if ch >= "a" andalso ch <= "z"
		then chr(ord ch - orda + ordA)
		else ch
		);
	in implode (map aux (explode s))
	end
);
=TEX
=SML
val €name_cache› : string E_DICT ref = ref initial_e_dict;
=TEX
=SML
fun €get_internal_name› (n : string) : string = (
	let	val ln = to_upper n;
		val side = case e_lookup ln (!name_cache) of
				Nil => name_cache := e_enter ln n (!name_cache)
				| Value ns =>
					if n = ns then ()
					else comment "CN-Parser" 501100
					[fn()=>n,fn()=>ns];
	in
		ln
	end
);
=TEX
=IGN
get_internal_name "thing";
get_internal_name "Thing";
get_internal_name "ThIng";

=SML
fun €get_external_name› (n : string) : string = (
	let	val ln = to_upper n;
	in
		case e_lookup ln (!name_cache) of
		Nil => n
		| Value ns => ns
	end
);
=TEX

=SML
fun €reset_names› () : unit = (
	name_cache := initial_e_dict
);
=TEX
=IGN
get_external_name"thing";
get_external_name"thINg";
get_external_name"FReD";
=TEX
=SML
end; (* of structure CaseIndependence *)
=TEX

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{LEXICAL ANALYSER}
=SML
structure €CNLex› : CNLex = struct
	open CNTypes CaseIndependence Lex ZLex;
=TEX
The main lexical analysis algorithm is exception-driven
using the following local exception:
=SML
exception €Unrecognised›;
=TEX
A state, $LEX\_STATE$, is used by most of the lexical analysis
functions. The state is in two parts: first, the characters not yet tokenised,
actually a list of strings of single characters produced by exploding
the input text; second, the token immediately preceeding the first
part.  The token may not be recognised (yet) so the token part of the
state carries a success indicator.  On entry to an analysis function
the state will be ``$(chars, (Unknown, \hbox{``''}))$''.
=SML
datatype €SUCCESS› = €Known› of string | €Unknown›;

type €LEX_STATE›  = (string list) * SUCCESS;
=TEX
\subsection{Utilities}
$collect$ adds the first character of the untokenised input text into the current token.
=SML
fun €collect› ( cstk : LEX_STATE ) : LEX_STATE = (
	case cstk of
		(c :: cs, Known s) => (cs, Known(s ^ c))
	|	(c :: cs, Unknown) => (cs, Known c)
	|	_ => error "CN-Parser" 15004 []
);
=TEX
We need various character classifying functions:
=SML
=TEX
=SML
val €ord0›	= ord "0";
val €ord9›	= ord "9";
val €orda›	= ord "a";
val €ordA›	= ord "A";
val €ordz›	= ord "z";
val €ordZ›	= ord "Z";
=TEX
=SMLPLAIN
fun €is_percent› (c : string) = c = "%%";
fun €is_prime› (c : string) = c = "'";
fun €is_us› (c : string) = c = "_";
fun €is_e› (c : string) = c = "E" orelse c = "e";
fun €is_plusminus› (c : string) = c = "+" orelse c = "-";
fun €is_dot› (c : string) = c = ".";
fun €is_hash› (c : string) = c = "#";
fun €is_space› c = c <= " ";
fun €is_horiz_space› c = c = " " orelse c = "\t";
=TEX
=SML
fun €is_digit›  (d : string) = (
	let	val ordd = ord d
	in	(ordd >= ord0) andalso (ordd <= ord9)
	end
);
=TEX
=SML
fun €is_alpha›  (c : string) = (
	let	val ordc = ord c
	in		((ordc >= orda) andalso (ordc <= ordz))
		orelse	((ordc >= ordA) andalso (ordc <= ordZ))
	end
);
=TEX
=SML
fun €is_alnum›  (c : string) = (
	is_alpha c orelse is_digit c
);
=TEX
=SML
fun €is_numericliteral› (s : string) = (
	case explode s of
	i::rest =>	is_digit i
	|_ =>		false
);
=TEX
=SML
fun €is_primedid› (s : string) = (
	case explode s of
	"'"::_::_ =>	true
	|_ =>		false
);
=TEX
=SML
fun €is_characterliteral› (s : string) = (
	case explode s of
	"'"::_::"'"::rest =>	true
	|_ =>			false
);
=TEX
=TEX
Note that the following list includes ``.'' but omits the string quotation
character. ``.'' is included so that $is\_delimiter$ may be
used to detect a character which may begin a delimiter symbol.

The algorithms used to access the list $delimiter$
assume that if one delimiter is a leading substring
of another then the longer of the two will appear earlier
in the list; a reverse lexicographical sort achieves
this.
=SML
val €delimiter› : string list list =
	(Sort.sort (switch(Sort.lexicographic Sort.string_order)) o map explode)
["&", "'", "(", ")", "*", "+", ",", "-", ".", "/", ":", ";", "<", "=", 
 ">", "|", "=>", "..", "**", ":=", "/=", ">=", "<=", "<<", ">>", "<>",
 "Ñ", "[", "]", "{","}", "∑", "˚", "˝", "ß","¢", "√", "È", "!È", "--", "--#"];
=TEX
=SML
fun next_is_delimiter (cs : string list) = (
	any delimiter (fn chs => cs to (length chs - 1) = chs)
);
=TEX
=SML
fun €skip_space› (st as (cs as (c :: more), tk) : LEX_STATE) : LEX_STATE = (
	if is_space c
	then skip_space (more, tk)
	else st
) | skip_space (st as ([], _)) = st;
=TEX
=SML
fun €skip_horiz_space› (st as (cs as (c :: more), tk) : LEX_STATE) : LEX_STATE = (
	if is_horiz_space c
	then skip_horiz_space (more, tk)
	else st
) | skip_horiz_space (st as ([], _)) = st;
=TEX
$next$ is used to apply a classifier function such as $is\_digit$
to the first character in the input part of a state. It returns false
if the input part is empty.
=SML
fun €next› (test : string -> bool) ((c :: _, _) : LEX_STATE) = test c
|   next _ ([], _) = false;
=TEX
When a lexeme 
has been recognised, the following material is used to classify the result.
(Note that an annotation may be reclassified as a hidden part depending on what follows the characters ``\verb"--#"''.)
=SML
val €class_table› = list_e_merge initial_e_dict [
	("ABS",		LCAbs),
	("&",		LCAmpersand),
	("--#",		LCAnnotation),
	("AND",		LCAnd),
	("ARRAY",	LCArray),
	("AT",		LCAt),
	("|",		LCBar),
	("BODY",	LCBBody),
	(":=",		LCBecomes),
	("BEGIN",	LCBegin),
	("CASE",	LCCase),
	(":",		LCColon),
	(",",		LCComma),
	("--",		LCComment),
	("CONSTANT",	LCConstant),
	("CON",		LCCon),
	(")",		LCCrd),
	("DELTA",	LCDelta),
	("DIGITS",	LCDigits),
	("/",		LCDiv),
	("..",		LCDotDot),
	(".",		LCDot),
	("ELSE",	LCElse),
	("ELSIF",	LCElsIf),
	("END",		LCEnd),
	("=",		LCEquals),
	("EXIT",	LCExit),
	("∑",		LCFatDot),
	("FOR",		LCFor),
	("FUNCTION",	LCFunction),
	("=>",		LCGoesTo),
	(">=",		LCGreaterEquals),
	(">",		LCGreaterThan),
	("IF",		LCIf),
	("IN",		LCIn),
	("IS",		LCIs),
	("<=",		LCLessEquals),
	("<>",		LCLessGreat),
	("<",		LCLessThan),
	("LIMITED",	LCLimited),
	("LOOP",	LCLoop),
	("-",		LCMinus),
	("MOD",		LCMod),
	("/=",		LCNotEquals),
	("NOT",		LCNot),
	("NULL",	LCNull),
	("OF",		LCOf),
	("(",		LCOrd),
	("OR",		LCOr),
	("OTHERS",	LCOthers),
	("OUT",		LCOut),
	("PACKAGE",	LCPackage),
	("+",		LCPlus),
	("'",		LCPrime),
	("PRAGMA",	LCPragma),
	("PRIVATE",	LCPrivate),
	("PROCEDURE",	LCProcedure),
	("RECORD",	LCRecord),
	("√",		LCRefinedBy),
	("REM",		LCRem),
	("RENAMES",	LCRenames),
	("È",		LCReplacedBy),
	("!È",		LCArbitraryAda),
	("RETURN",	LCReturn),
	("REVERSE",	LCReverse),
	("RANGE",	LCRRange),
	(";",		LCSemi),
	("SEPARATE",	LCSeparate),
	("**",		LCStarStar),
	("*",		LCStar),
	("SUBTYPE",	LCSubType),
	("THEN",	LCThen),
	("TYPE",	LCType),
	("TILL",	LCTill),
	("USE",		LCUse),
	("WHEN",	LCWhen),
	("WHILE",	LCWhile),
	("WITH",	LCWith),
	("XOR",		LCXor),
	("Ñ",		LCGrkDelta),
	("[",		LCLSqBrack),
	("]",		LCRSqBrack),
	("{",		LCLBrace),
	("}",		LCRBrace),
	("˚",		LCLStrachey),
	("˝",		LCRStrachey),
	("ß",		LCLChevron),
	("¢",		LCRChevron),
	("AUXILIARY",	LCAuxiliary),
	("USING",	LCUsing),
	("IMPLEMENT",	LCImplement),
	("BY",		LCBy)
			];

=TEX
=SML
fun €classify› (use_get_internal : bool) (what : string) : CN_LEX_ITEM = (
let	val convert = if use_get_internal	then get_internal_name
						else to_upper;
	val WHAT = convert what;
in
	(case e_lookup WHAT class_table of
		Value cl => cl
		|	Nil	=> (
				if	is_numericliteral what
				then	LCNumericLiteral
				else if is_characterliteral what
				then	LCCharacterLiteral
				else if is_primedid what
				then	LCPrimedIdentifier
				else	LCIdentifier
			),
		CNText WHAT)
end
);
=TEX
\subsection{Recognition of Delimiters}
=SML
fun €get_next_delimiter› (cs : string list) : string = (
	implode (find delimiter (fn chs => cs to (length chs - 1) = chs))
	handle ex => fail "CN-Parser" 501002 [fn()=>"invalid call of get_next_delimiter"]
);
=TEX
$rec\_delimiter$ returns an appropriately updated state if the input
begins with a delimiter symbol, if not it raises $Unrecognised$.
=SML
fun  €rec_delimiter› ( (cs, _) : LEX_STATE ) : LEX_STATE = (
	if next_is_delimiter cs
	then	let	val tk = get_next_delimiter cs;
        	in	(cs from size tk, Known tk)
		end
	else	raise Unrecognised
);
=TEX
\subsection{Recognition of Identifiers}

=SML
fun €rec_identifier_aux› (st : LEX_STATE) : LEX_STATE = (
	let	fun aux st = (
			if next is_alnum st orelse next is_us st
			then aux (collect st)
			else st
		);
	in	if next is_alnum st orelse next is_us st
		then aux (collect st)
		else raise Unrecognised
	end
);
=TEX
=SML
fun €rec_identifier› (st : LEX_STATE) : LEX_STATE = (
	if next is_alpha st
	then	let	val (st', flag) = (rec_identifier_aux st, true)
				handle Unrecognised => (st, false);
		in	if flag
			then st'
			else raise Unrecognised
		end
	else raise Unrecognised
);
=TEX
\subsection{Recognition of Numbers}
=TEX
=SML
fun €rec_gen_integer› (f : string -> bool) (st : LEX_STATE) : LEX_STATE = (
	let	fun aux1 st = (
			if	next f (collect st)
			then	aux (collect st)
			else	raise Unrecognised
		)
		and aux st = (
			if	next f st
			then	aux (collect st)
			else if	next is_us st
			then	aux1 st
			else	st
		);
	in	if next f st
		then aux (collect st)
		else raise Unrecognised
	end
);
=TEX
=SML
val €rec_integer› = rec_gen_integer is_digit;
val €rec_based_integer› = rec_gen_integer is_alnum;
=TEX
=SML
fun €rec_exponent› (st : LEX_STATE) : LEX_STATE = (
	if	next is_e st
	then	let val st' = collect st;
		in
			if	next is_plusminus st'
			then	rec_integer (collect st')
			else	rec_integer st'
		end
	else	st
);
=TEX
=SML
fun €rec_based› (st : LEX_STATE) : LEX_STATE = (
let	val st' = rec_based_integer st;
	fun aux st =
		if	next is_hash st
		then	rec_exponent (collect st)
		else	raise Unrecognised;
in
	if	next is_dot st'
	then	((aux o rec_based_integer) (collect st')
			handle _ => st')
	else 	aux st'
end);
=TEX
=SML
fun €rec_numeric› (st : LEX_STATE) : LEX_STATE = (
let	val st' = rec_integer st;
	fun aux st =
		if	next is_hash st
		then	rec_exponent (collect st)
		else	raise Unrecognised;
in
	if	next is_dot st'
	then	((rec_exponent o rec_integer) (collect st')
			handle _ => st')
	else if	next is_e st'
	then	rec_exponent st'
	else if	next is_hash st'
	then	rec_based (collect st')
	else	st'
end);
=TEX
\subsection{Recognition of Keywords}
=SML
fun €rec_keyword› (st : LEX_STATE) : LEX_STATE = (
        let     fun aux (([], _) : LEX_STATE) = (
                        raise Unrecognised
                ) | aux st = (
                        if next is_percent st
                        then (collect st)
                        else aux (collect st)
                );
        in      if next is_percent st
                then aux (collect st)
                else raise Unrecognised
        end
);
=TEX
\subsection{Recognition of Character Literals}
=SML
fun €rec_characterliteral› (st : LEX_STATE) : LEX_STATE = (
	if next is_prime st
	then	let	val st' = collect (collect st);
		in
			if next is_prime st'
			then
				collect st'
			else
				raise Unrecognised
		end
	else
		raise Unrecognised
);
=TEX

\subsection{Recognition of Primed Identifiers}
=SML
fun €rec_primedid› (st : LEX_STATE) : LEX_STATE = (
	if next is_prime st
	then
		rec_identifier (collect st)
	else
		raise Unrecognised
);
=TEX

\subsection{Recognition of Lexemes}
Function $rec\_next\_token$ picks off the next token from the input
using the other recognisers.
=SML
fun €rec_next_token› (st : LEX_STATE) : LEX_STATE = (
	let	val st' = skip_space st;
	in	
		(((((((rec_identifier st))
		handle Unrecognised =>
			(rec_characterliteral st))
		handle Unrecognised =>
			(rec_primedid st))
		handle Unrecognised =>
			(rec_delimiter st))
		handle Unrecognised =>
			(rec_numeric st))
		handle Unrecognised =>
			(rec_keyword st))
		handle Unrecognised =>
			(fst st, Unknown)
	end
);
=TEX
\section{LEXICAL ANALYSER}
The following constitute some essential requirements of this lexical analyser.
The function $rec\_next\_token$ allows us to recognise the next lexeme
in an input stream according to the SPARK (and Compliance Notation) lexis.
We must now put this to use in constructing the overall lexical analyser.
To do this we must handle embedded Z and also annotations, comments and pragmas.
To handle embedded Z we need to be able to recognise the end of the Z fragment while using the Z lexical analyser to process the Z lexemes.
To handle comments and annotations is just a question of scanning to the end of line (or in the case of the hide annotation to the end marker for the annotation).
Similarly, we take a pragma to be any text after the pragma keyword up to a semi-colon.

\subsection{Comments}
In the following, we often have a list of strings which is the exploded form of the unread part of the current $INPUT$ fragment, and a list of subsequent unread $INPUT$s.
The function $ignore\_comment$ assumes a comment start symbol has just been read
and skips on in the two lists to the end of a line.
=SML
fun €ignore_comment› (slist : string list) (rest : INPUT list)
	: (string list * INPUT list)  = (
	case slist of 
		("\n" :: more) => (more, rest)
	|	(_ :: more) => ignore_comment more rest
	|	[] => (
		case rest of
			Lex.Text s :: inputs => ignore_comment (explode s) inputs
		|	_ :: inputs => ignore_comment [] inputs
		|	[] => ([], [])
	)
);
=TEX
\subsection{Annotations}
The function $spark\_annotation$ assumes an annotation symbol has just been read.
It returns a $CN\_LEX\_ITEM$ containing the text of the annotation (including the \verb"--#" but without the final new-line together with
two lists giving the unread part of the input (cf. $ignore\_comment$).
=SML
fun €spark_annotation_aux› (acc : string)
		(slist : string list) (rest : INPUT list)
	: (CN_LEX_ITEM * string list * INPUT list)  = (
	case slist of 
		("\n" :: more) => ((LCAnnotation, (CNText acc)), more, rest)
	|	(ch :: more) => spark_annotation_aux (acc ^ ch) more rest
	|	[] => (
		case rest of
			Lex.Text s :: inputs =>
				spark_annotation_aux acc (explode s) inputs
		|	Lex.String s :: inputs =>
				spark_annotation_aux (acc ^ "\"" ^ s ^ "\"") [] inputs
		|	_ :: inputs => ((LCAnnotation, (CNText acc)), [], rest)
		|	[] => ((LCAnnotation, (CNText acc)), [], [])
	)
);
=TEX
=SML
fun €spark_annotation› 
		(slist : string list) (rest : INPUT list)
	: (CN_LEX_ITEM * string list * INPUT list)  = (
	spark_annotation_aux "--#" slist rest
);
=TEX
\subsection{Arbitrary Ada}
The function $spark\_arbitrary$ assumes the symbol introducing an arbitrary Ada insert has just been read.
It returns a $CN\_LEX\_ITEM$ containing the text of the insert (without the introducing symbol) together with
two lists giving the unread part of the input (cf. $ignore\_comment$).
In fact, everything should have been read here, and the $spark\_lex$ will eventually complain if something like a HOL type is encountered.
=SML
fun €spark_arbitrary_aux› (acc : string)
		(rest : INPUT list)
	: (CN_LEX_ITEM * string list * INPUT list)  = (
	case rest of 
		Lex.Text s :: more =>
				spark_arbitrary_aux (acc ^ s) more
	|	Lex.String s :: more =>
			spark_arbitrary_aux (acc ^ "\"" ^ s ^ "\"") more
	|	_  => ((LCArbitraryAda, (CNText acc)), [], rest)
);
=TEX
=SML
fun €spark_arbitrary› 
		(slist : string list) (rest : INPUT list)
	: (CN_LEX_ITEM * string list * INPUT list)  = (
	spark_arbitrary_aux (implode slist) rest
);
=TEX
\subsection{Z Fragments}
First we define a table showing the symbols which can delimit a Z fragment.
The table gives each symbol which can begin a Z fragment together with each symbol which can mark the end of a fragment begun by that symbol.
=SML
val €z_delimiters› = [
	(LCGrkDelta, [LCLSqBrack, LCLBrace]),
	(LCLBrace, [LCRBrace]),
	(LCLSqBrack, [LCRSqBrack]),
	(LCLStrachey, [LCRStrachey]),
	(LCCon, [LCFatDot]),
	(LCLChevron, [LCRChevron]),
	(LCAuxiliary, [LCSemi]),
	(LCImplement, [LCBy]),
	(LCBy, [LCSemi])];
=TEX
Some of the above symbols can also be used in Z, so we need tables showing the brackets used in Z.
=SML
val €z_open_brackets› = ["(", "ß", "[", "{"];
val €z_close_brackets› = [")", "¢", "]", "}"];
=TEX
The algorithm for finding the Z fragments is a little complicated by
the structure of the as stream (as a list of $INPUT$s, some of which
are themselves text-strings to be processed character by character).
The following type is used to communicate between the functions which
search for the end marker.
=SML
type €INPUT_HANDLE› = {
	left_input : Lex.INPUT list,
	left_text : string list,
	right_text : string list,
	right_input : Lex.INPUT list,
	bracket_depth : int
	};
=TEX
$find\_in\_text$ looks for an end marker in a text-string in the input
and keeps track of bracket nesting in case the actual end-marker is in
one of the later $INPUT$s.
=SML
fun €find_in_text› (terml : CN_LEX_CLASS list)
	({left_input, left_text, right_text, right_input, bracket_depth}
		: INPUT_HANDLE)
		: (bool * INPUT_HANDLE) = (
	let	fun aux (brk, sold, snew as (c::srest)) = (
		let	val (c', srest') =
				(case rec_identifier (snew, Unknown) of
					(srest'', Known c'') =>
						(c'', srest'')
				|	(_, _) => (c, srest)
				)
				handle Unrecognised =>
						(c, srest);
			val terminate_now = (fst o (classify false)) c' mem terml
							andalso brk = 0;
			val (id, rest) =
				if terminate_now
				then	(c', srest')
				else	(c, srest);
		in
				if terminate_now
				then
					(true, brk, sold, (explode id)@rest)
				else if id mem z_open_brackets
				then
					aux (brk + 1, sold@[id], rest)
				else if id mem z_close_brackets
				then
					aux (brk - 1, sold@[id], rest)
				else
					aux (brk, sold@[id], rest)
		end
		) | aux (brk, sold, []) = (false, brk, sold, []);
		val (flg, brk, sold, snew) =
				aux (bracket_depth, left_text, right_text);
	in
		(flg, {left_input=left_input,
			left_text=sold,
			right_text=snew,
			right_input=right_input,
			bracket_depth=brk})
	end
);
=TEX
Assuming $find\_in\_text$ hasn't found the end marker, $find\_in\_input$ continues the search in the next $INPUT$ in the list.
=SML
fun €find_in_input› (terml : CN_LEX_CLASS list)
	(ih as {left_input, left_text, right_text, right_input, bracket_depth}
		: INPUT_HANDLE)
		: (bool * INPUT_HANDLE) = (

	case find_in_text terml ih of
	(true, ih') => (true, ih')
	| (false, ih') =>
		let	val lt = #left_text ih';
			val li = case lt of
					[] => #left_input ih'
					|_ => (#left_input ih') 
						@[(Lex.Text o implode) lt];
		in
			case #right_input ih' of
			Lex.Text txt::more => (
				find_in_input terml
					{	left_input=li,
						left_text=[],
						right_text=explode txt,
						right_input=more,
						bracket_depth= #bracket_depth ih'
					}
			) | other::more => (
				find_in_input terml
					{	left_input= li @ [other],
						left_text=[],
						right_text=[],
						right_input=more,
						bracket_depth= #bracket_depth ih'
					}
			) | [] => (
				(false,{	left_input= li,
						left_text=[],
						right_text=[],
						right_input=[],
						bracket_depth= #bracket_depth ih'
					})
			)
		end
);

=TEX
$read\_until$ give the interface to the previous functions.
It extracts a single Z fragment from the input stream (say an
auxiliary expression) and then recursively invokes lexical analysis
of the remaining input.
=SML
fun €read_until› (classification : CN_LEX_CLASS,
				cn_fun : Lex.INPUT list -> CN_TOKEN)
			(terml : CN_LEX_CLASS list) (iplist : INPUT list)			 
		: CN_LEX_ITEM list = (
let	val (found, ih') = find_in_input terml
			{	left_input=[],
				left_text=[],
				right_text=[],
				right_input=iplist,
				bracket_depth = 0};
	val lt = #left_text ih';
	val li = case lt of
			[] => #left_input ih'
			| lt' => (#left_input ih')@[(Lex.Text o implode) lt];
	val rt = #right_text ih';
	val ri = #right_input ih';
	val left_cxt = case li of
				[] => []
				| li' => [(classification,
						cn_fun li)];
	val right_inp = case rt of
				[] => ri
				| rt' => (Lex.Text o implode) rt::ri;
in
	if found
	then
		left_cxt@spark_lex right_inp

	else
		left_cxt
end)
=TEX
$spark\_xtext$ acts a dispatcher for the earlier functions which apply when
a text string in the input is being processed, it analyses the
next spark token in the input and takes action accordingly.
=SML
and €spark_xtext› (slist : string list) (rest : INPUT list) : CN_LEX_ITEM list  = (
let	val st = skip_space (slist, Unknown);
in
	case skip_space st of
	([], _) => spark_lex rest
	| other => (
	let	val unskipped = rec_next_token other;
	in
		case skip_space unskipped of
		st' as (srest, Known s) => (
			let	val res as (class, _) = classify true s;
			in case (class, lassoc5 z_delimiters class) of
				(LCLChevron, Value terml) => (
					res
					::(read_until (LCKSlot, CNKSlot) terml
						(Lex.Text (implode srest)::rest)
							)
				)|(_, Value terml) => (
					res
					::(read_until (LCZ, CNZ o ZLex.z_lex)terml
						(Lex.Text (implode srest)::rest)
							)
				)|(LCCharacterLiteral, Nil) => (
					(class, (CNString o implode o tl
							o rev o tl o explode) s)
					::spark_xtext srest rest
				)|(LCComment, Nil) => (
					let val (srest', rest') =
						ignore_comment srest rest;
					in	spark_xtext srest' rest'
					end
				)|(LCAnnotation, Nil) => (
					let val (tok, srest', rest') =
						spark_annotation (fst unskipped)rest;
					in	tok :: spark_xtext srest' rest'
					end
				)|(LCArbitraryAda, Nil) => (
					let val (tok, srest', rest') =
						spark_arbitrary (fst unskipped)rest;
					in	tok :: spark_xtext srest' rest'
					end
				)|(_, Nil) => 	
					res::spark_xtext srest rest
			end
		)| (_, Unknown) =>
			fail "CN-Parser" 501001 [fn() => implode slist]
	end)
end)
=TEX
$spark\_lex$ is the dispatcher for an arbitrary $INPUT$.
=SML
and €spark_lex› ((ip::more) : INPUT list) : CN_LEX_ITEM list = (
	case ip of
		Lex.Text s => (
			spark_xtext (explode s) more
	) |	Lex.String s => (
			(LCStringLiteral, CNString s)::spark_lex more
	) |	Lex.Char s => (
			fail "CN-Parser" 501001  [fn () => "`"^s^"`"]
	) |	Lex.Type ty => (
			fail "CN-Parser" 501001  [fn () => string_of_type ty]
	) |	Lex.Term tm => (
			fail "CN-Parser" 501001  [fn () => "antiquotation"]
	) |	Lex.Separator s => (
			fail "CN-Parser" 501001  [fn () => s]
	) |	Lex.Error n => (fail "CN-Parser (Lexer)" 501003 [fn () => string_of_int n])
) | spark_lex _ = [];
=TEX
Finally $cn\_lex$ is the external interface for the lexical analyser:
=SML
fun €cn_lex› (classify_label : CN_LEX_ITEM list -> CN_LEX_ITEM list) (inp : INPUT list) 
		: CN_LEX_ITEM list = (
	(classify_label o spark_lex) inp
);
=TEX
\section{EPILOGUE}
=SML
end (* of structure CNLex *);
=TEX
\small
\twocolumn[\section{INDEX}]
\printindex
\end{document}
=IGN
fun mk_ih s =
	{left_input=[],left_text=[],right_text=explode s, right_input=[],
		bracket_depth=0} : INPUT_HANDLE;

val terml = [LCIdentifier, LCRSqBrack];
val c'="hihgjghj";
val {left_input, left_text, right_text, right_input, bracket_depth}=
	(mk_ih "bc[de∑f]gIDENTIFIER,hi]kjm");

find_in_text [LCFatDot, LCRSqBrack] (mk_ih "x");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "xdfdf]");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "abc∑");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "abc∑def");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "abc[def]ghi]");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "bc[de∑f]ghi]kjm");
find_in_text [LCBy] (mk_ih "==,BY],hihgjghj]IdentifierRkjm");
find_in_text [LCImplement]
	(mk_ih "==,[IMPLEMENT],hihgjghj Implement Rkjm");
=IGN
fun mk_ih s =
	{left_input=[],left_text=[],right_text=explode s, right_input=[],
		bracket_depth=0} : INPUT_HANDLE;

val terml = [LCIdentifier, LCRSqBrack];
val c'="hihgjghj";
val {left_input, left_text, right_text, right_input, bracket_depth}=
	(mk_ih "bc[de∑f]gIDENTIFIER,hi]kjm");

find_in_text [LCFatDot, LCRSqBrack] (mk_ih "x");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "xdfdf]");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "abc∑");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "abc∑def");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "abc[def]ghi]");
find_in_text [LCFatDot, LCRSqBrack] (mk_ih "bc[de∑f]ghi]kjm");
find_in_text [LCBy] (mk_ih "==,BY],hihgjghj]IdentifierRkjm");
find_in_text [LCImplement]
	(mk_ih "==,[IMPLEMENT],hihgjghj Implement Rkjm");
=IGN
read_until [LCFatDot, LCRSqBrack] [Lex.Text "abc]"];
read_until [LCFatDot, LCRSqBrack] [Lex.Text "ab(c∑",Lex.String"x",
				Lex.Text "de∑f)]g"];
read_until [LCFatDot, LCRSqBrack] [Lex.Text "abc"];
read_until ["]"] [Lex.Text "pre, post]"];
read_until [LCFatDot, LCRSqBrack] [Lex.Text "abc]"];
read_until [LCFatDot, LCRSqBrack] [Lex.Text "abc]"];
read_until [LCFatDot, LCRSqBrack] [Lex.Text "abc]"];
read_until [LCFatDot, LCRSqBrack] [Lex.Text "abc]"];
=IGN
val spark_lex = CNLex.cn_lex (Combinators.I);
spark_lex [Lex.Text "abcd def (12)"];
spark_lex [Lex.Text "-- abcd def (12) \n xyz (10);"];
spark_lex [Lex.Text "foo(); \n -- abcd def (12) \n xyz (10);"];
spark_lex [Lex.Text "foo(); \n -- abcd def (12)", Lex.String "str",
	Lex.Text "def", Lex.Text"ghi \n xyz (10);"];
spark_lex [Lex.Text "--#       X"];
spark_lex [Lex.Text "--#\tX"];
spark_lex [Lex.Text "--#\nX"];
spark_lex [Lex.Text "--# abcdef", Lex.String "boo"];
spark_lex [Lex.Text "--# abcdef", Lex.String "boo", Lex.Text"def\n\n\nf();"];
spark_lex [Lex.String "a\"\"bcd"];
spark_lex [Lex.Text "pragma foo ; "];
spark_lex [Lex.Text "pragma foo -- \n-- (( 9   ; "];
spark_lex [Lex.Text "(1) !È any \n", Lex.Text " old ", Lex.String "rubbish"];
