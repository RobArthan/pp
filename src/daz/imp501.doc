% imp501.doc   %Z% $Date$ $Revision$ $RCSfile$
=TEX
\documentstyle[hol1,11pt,TQ]{article}
\ftlinepenalty=9999
\def\Hide#1{}
\def\Bool{``$\it{:}bool\,$''}
\makeindex
\TPPproject{DAZ PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Implementation: Compliance Notation Lexical Analyser}  %% Mandatory field
\TPPref{ISS/HAT/DAZ/IMP501}  %% Mandatory field
\def\SCCSversion{$Revision$%
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date$%
}}
\TPPstatus{Draft}			%% Mandatory field
\TPPtype{Specification}
\TPPkeywords{HOL}
\TPPauthor{D.J.~King & WIN01}  %% Mandatory field
%\TPPauthors{Name 1&location 1\\Name 2&location 2\\Name 3&location 3}
\TPPauthorisation{D.J.~King & DAZ Team Leader}
\TPPabstract{
This document contains the implementation for the SPARK 
parser.}
%\TPPabstractB{}
%\TPPabstractC{}
%\TPPabstractD{}
%\TPPabstractE{}
%\TPPabstractF{}
\TPPdistribution{\parbox[t]{4.0in}{%
	Library}}

%\TPPclass{CLASSIFICATION}
%\def\TPPheadlhs{}
%\def\TPPheadcentre{}
%def\TPPheadrhs{}
%\def\TPPfootlhs{}
%\def\TPPfootcentre{}
%\def\TPPfootrhs{}

\begin{document}
\TPPsetsizes
\makeTPPfrontpage

\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}

\newpage
\section{DOCUMENT CONTROL}
\subsection{Contents List}
\tableofcontents
\subsection{Document Cross References}
\bibliographystyle{fmu}
\bibliography{fmu}

\subsection{Changes History}  % to get section number `0.3'
\begin{description}

\item[Issue \SCCSversion, \FormatDate{$Date$%
} ] Initial Draft.

\end{description}
\subsection{Changes Forecast}
\pagebreak
\section{GENERAL}
\subsection{Scope}
This document contains the implementation for the lexical analyser and the
lexis for SPARK.
The detailed design for this material is in \cite{ISS/HAT/DAZ/DTD501}.

\subsection{Introduction}

\subsection{Purpose and Background}

\subsection{Algorithms}

\subsection{Dependencies}

\subsection{Known Deficencies}

\subsection{Possible Enhancements}

\section{CASE INDEPENDENCE}
=SML
structure €CaseIndependence› : CaseIndependence = struct
=TEX
=SML
val ordA = ord "A";
val orda = ord "a";
=TEX
=SML
fun to_lower s = (
	let fun aux ch = (
		if ch >= "A" andalso ch <= "Z"
		then chr(ord ch - ordA + orda)
		else ch
		);
	in implode (map aux (explode s))
	end
);
=TEX
=SML
fun to_upper s = (
	let fun aux ch = (
		if ch >= "a" andalso ch <= "z"
		then chr(ord ch - orda + ordA)
		else ch
		);
	in implode (map aux (explode s))
	end
);
=TEX
=SML
val €name_cache› : string list E_DICT ref = ref initial_e_dict;
=TEX
=SML
fun €cache_name› (n : string) : unit = (
	let	val ln = to_upper n;
	in	case e_lookup ln (!name_cache) of
			Nil => name_cache := e_enter ln [n] (!name_cache)
		|	Value ns => name_cache := e_enter ln (n::ns) (!name_cache)
	end
);
=TEX
=SML
fun €cache_const› (c : TERM) : unit = (
	let	val (n, _) = dest_const c;
	in	cache_name n
	end	handle Fail _ => error "cache_const" 501100 []
);
=TEX
=SML
fun €uncache_const› (c : TERM) : unit = (
	let	val (n, _) = dest_const c;
		val ln = to_upper n;
	in	case e_lookup ln (!name_cache) of
			Nil => ()
		|	Value ns => name_cache := e_enter ln (ns less n) (!name_cache)
	end
);
=TEX
=SML
fun €cache_theory› (thy : string) : unit = (
	map cache_const (get_consts thy); ()
);
=TEX
=SML
fun €cache_ancestry› (thy : string) : unit = (
	name_cache := initial_e_dict;
	map cache_theory (get_ancestors thy); ()
);
=TEX
=SML
fun €ci_get_const_names› (n : string) : string list = (
	case e_lookup n (!name_cache) of
		Nil => []
	|	Value ns => ns
);
=TEX
=SML
val _ = on_kernel_state_change
	(fn	OpenTheory (current, (_, _)) => cache_ancestry current
	|	NewParent _ => cache_ancestry(get_current_theory_name())
	|	NewConst (c, _) => cache_name c
	|	SimpleNewDefn ((_, c, _), _) => cache_name c
	|	NewSpec ((_, i, thm), _) => (
			map cache_name(map(fst o dest_var)
			((fst(strip_∂((snd o dest_thm) thm))) to (i-1))); ()
	)  |	DeleteConst c => uncache_const c
	|	_ => ()
);
=TEX

=SML
end; (* of structure CaseIndependence *)
=TEX
\section{DATA TYPES}
=SML
structure €CNLex› : CNLex = struct
=TEX
=SML
local

open CaseIndependence;
open Lex ZLex ZParser ZUserInterfaceSupport;

in
=TEX
\subsection{Types for Lexical Analysis}
The following data type represents the lexical classes which are the
terminals of the grammar:
=SML
datatype €SPARK_LEX_CLASS›
			=	€AbstractExpression›
			|	€Abs›
			|	€Ampersand›
			|	€And›
			|	€Array›
			|	€At›
			|	€Bar›
			|	€BBody›
			|	€Becomes›
			|	€Begin›
			|	€Case›
			|	€CharacterLiteral›
			|	€Colon›
			|	€Comma›
			|	€CompLabel›
			|	€Constant›
			|	€Con›
			|	€Crd›
			|	€DecLabel›
			|	€Delta›
			|	€Digits›
			|	€Div›
			|	€DotDot›
			|	€Dot›
			|	€Else›
			|	€ElsIf›
			|	€End›
			|	€Equals›
			|	€Exit›
			|	€FatDot›
			|	€For›
			|	€FunctionName›
			|	€Function›
			|	€GoesTo›
			|	€GreaterEquals›
			|	€GreaterThan›
			|	€Identifier›
			|	€If›
			|	€In›
			|	€Is›
			|	€KSlot›
			|	€LessEquals›
			|	€LessGreat›
			|	€LessThan›
			|	€Limited›
			|	€Loop›
			|	€Minus›
			|	€Mod›
			|	€Na›
			|	€NotEquals›
			|	€Not›
			|	€Null›
			|	€NumericLiteral›
			|	€Of›
			|	€Ord›
			|	€Or›
			|	€Others›
			|	€Out›
			|	€Package›
			|	€Plus›
			|	€PPartLabel›
			|	€Prime›
			|	€Private›
			|	€ProcedureName›
			|	€Procedure›
			|	€Record›
			|	€RefinedBy›
			|	€Rem›
			|	€Renames›
			|	€ReplacedBy›
			|	€Return›
			|	€Reverse›
			|	€RRange›
			|	€Semi›
			|	€Separate›
			|	€SpecLabel›
			|	€StarStar›
			|	€Star›
			|	€StmtLabel›
			|	€StringLiteral›
			|	€SubType›
			|	€Then›
			|	€TypeMark›
			|	€Type›
			|	€Till›
			|	€Use›
			|	€VPartLabel›
			|	€WhenOthers›
			|	€When›
			|	€While›
			|	€With›
			|	€Xor›
			|	€ZDecl›
			|	€Eos›
			|	€Z›
=TEX
$SpecificationStatement$ is not a terminal and the syntax of a specification statement is part of the grammar. The Z predicates for pre- and post-condition are terminals and are captured by the $Z$ type constructor. Other terminals required are:
=SML
			|	€GrkDelta›
			|	€LSqBrack›
			|	€RSqBrack›
			|	€LBrace›
			|	€RBrace›
			|	€PrimedIdentifier›;
=TEX
The following is used in the type of the tokens produced by the SAL lexical analyser.
=SML
datatype €SPARK_TOKEN›	=	€SPARKZ› of ZLex.Z_TOKEN list
			|	€SPARKText› of string
			|	€SPARKString› of string
			|	€SPARKEos›;
=TEX
The actual tokens returned by $SPARK\_lex$ are of the following type:
=SML
type €LEX_ITEM› = SPARK_LEX_CLASS * SPARK_TOKEN;
=TEX
\section{LEXICAL ANALYSER}
The main lexical analysis algorithm is exception-driven
using the following local exception:
=SML
exception €Unrecognised›;
=TEX
A state, $LEX\_STATE$, is used by most of the lexical analysis
functions. The state is in two parts: first, the characters not yet tokenised,
actually a list of strings of single characters produced by exploding
the input text; second, the token immediately preceeding the first
part.  The token may not be recognised (yet) so the token part of the
state carries a success indicator.  On entry to an analysis function
the state will be ``$(chars, (Unknown, \hbox{``''}))$''.
=SML
datatype €SUCCESS› = €Known› of string | €Unknown›;

type €LEX_STATE›  = (string list) * SUCCESS;
=TEX
\subsection{Utilities}
$collect$ adds the first character of the untokenised input text into the current token.
=SML
fun €collect› ( cstk : LEX_STATE ) : LEX_STATE = (
	case cstk of
		(c :: cs, Known s) => (cs, Known(s ^ c))
	|	(c :: cs, Unknown) => (cs, Known c)
	|	_ => error "CN-Parser" 15004 []
);
=TEX
We need various character classifying functions:
=SML
=TEX
=SML
val €ord0›	= ord "0";
val €ord9›	= ord "9";
val €orda›	= ord "a";
val €ordA›	= ord "A";
val €ordz›	= ord "z";
val €ordZ›	= ord "Z";
=TEX
=SML
fun €is_digit›  (d : string) = (
	let	val ordd = ord d
	in	(ordd >= ord0) andalso (ordd <= ord9)
	end
);
=TEX
=SML
fun €is_alpha›  (c : string) = (
	let	val ordc = ord c
	in		((ordc >= orda) andalso (ordc <= ordz))
		orelse	((ordc >= ordA) andalso (ordc <= ordZ))
	end
);
=TEX
=SML
fun €is_alnum›  (c : string) = (
	is_alpha c orelse is_digit c
);
=TEX
=SML
fun €is_orb› (c : string) = (
	c = "("
);
fun €is_crb› (c : string) = (
	c = ")"
);
fun €is_prime› (c : string) = (
	c = "'"
);
=TEX
Note that the following list includes ``.'' but omits the string quotation
character. ``.'' is included so that $is\_delimiter$ may be
used to detect a character which may begin a delimiter symbol.

The algorithms used to access the list $delimiter$
assume that if one delimiter is a leading substring
of another then the longer of the two will appear earlier
in the list; a reverse lexicographical sort achieves
this.
=SML
val €delimiter› : string list list =
	(Sort.sort (switch(Sort.lexicographic Sort.string_order)) o map explode)
	["&", "'", "(", ")", "*", "+", ",", "-", ".", "/", ":", ";", "<", "=", 
	">", "|", "=>", "..", "**", ":=", "/=", ">=", "<=", "<<", ">>", "<>",
	"Ñ", "[", "]", "{","}"];
=TEX
=SML
fun next_is_delimiter (cs : string list) = (
	any delimiter (fn chs => cs to (length chs - 1) = chs)
);
=TEX
=SML
fun €is_space› c = c <= " ";
=TEX
=SML
fun €is_us› c = c = "_";
=TEX
=SML
fun €skip_space› (st as (cs as (c :: more), tk) : LEX_STATE) : LEX_STATE = (
	if is_space c
	then skip_space (more, tk)
	else st
) | skip_space (st as ([], _)) = st;
=TEX
$next$ is used to apply a classifier function such as $is\_digit$
to the first character in the input part of a state. It returns false
if the input part is empty.
=SML
fun €next› (test : string -> bool) ((c :: _, _) : LEX_STATE) = test c
|   next _ ([], _) = false;
=TEX
When a lexeme 
has been recognised, the following material is used to classify the result.
=SML
val €class_table› = list_e_merge initial_e_dict [
	("ABS",		Abs),
	("&",		Ampersand),
	("AND",		And),
	("ARRAY",	Array),
	("AT",		At),
	("|",		Bar),
	("BODY",	BBody),
	(":=",		Becomes),
	("BEGIN",	Begin),
	("CASE",	Case),
	(":",		Colon),
	(",",		Comma),
	("CONSTANT",	Constant),
	("CON",		Con),
	(")",		Crd),
	("DELTA",	Delta),
	("DIGITS",	Digits),
	("/",		Div),
	("..",		DotDot),
	(".",		Dot),
	("ELSE",	Else),
	("ELSIF",	ElsIf),
	("END",		End),
	("=",		Equals),
	("EXIT",	Exit),
	("∑",		FatDot),
	("FOR",		For),
	("FUNCTION",	Function),
	("=>",		GoesTo),
	(">=",		GreaterEquals),
	(">",		GreaterThan),
	("IF",		If),
	("IN",		In),
	("IS",		Is),
	("<=",		LessEquals),
	("<>",		LessGreat),
	("<",		LessThan),
	("LIMITED",	Limited),
	("LOOP",	Loop),
	("-",		Minus),
	("MOD",		Mod),
	("/=",		NotEquals),
	("NOT",		Not),
	("NULL",	Null),
	("OF",		Of),
	("(",		Ord),
	("OR",		Or),
	("OTHERS",	Others),
	("OUT",		Out),
	("PACKAGE",	Package),
	("+",		Plus),
	("'",		Prime),
	("PRIVATE",	Private),
	("PROCEDURE",	Procedure),
	("RECORD",	Record),
	("%sqsubseteq%",RefinedBy),
	("REM",		Rem),
	("RENAMES",	Renames),
	("REPLACEDBY",	ReplacedBy),
	("RETURN",	Return),
	("REVERSE",	Reverse),
	("RANGE",	RRange),
	(";",		Semi),
	("SEPARATE",	Separate),
	("**",		StarStar),
	("*",		Star),
	("SUBTYPE",	SubType),
	("THEN",	Then),
	("TYPE",	Type),
	("TILL",	Till),
	("USE",		Use),
	("WHENOTHERS",	WhenOthers),
	("WHEN",	When),
	("WHILE",	While),
	("WITH",	With),
	("XOR",		Xor),
=TEX
The following are to support the Specification Statement
=SML
	("Ñ",		GrkDelta),
	("[",		LSqBrack),
	("]",		RSqBrack),
	("{",		LBrace),
	("}",		RBrace)
			];

=TEX
=SML
fun €is_label› (s :string) = (
let	val xs = explode s;
in
	case xs of
	"("::rest => (
		case (rev rest) of
		")"::n::rest' => true
		|_ => false
		)
	|_ => false
end);
=TEX
=SML
fun €classify_label› (what : string) = (
let	val xs = explode what;
in
	case xs of
	"("::rest => (
		case (rev rest) of
		")"::(digits as (n::rest')) => (
			case ((nat_of_string o implode o rev) digits) div 10 of
			0 => CompLabel
			|1 => PPartLabel
			|2 => VPartLabel
			|3 => DecLabel
			|4 => StmtLabel
			|_ => SpecLabel
			)
		|_ => fail "" 0  []
		)
	|_ => fail "" 0 []
end);
=TEX
=SML
fun €is_primedid› (s : string) = (
let	val xs = explode s;
in
	case xs of
	"'"::_::rest => (
		 true
	) |_ => false
end);
=SML
fun €classify› (what : string) : SPARK_LEX_CLASS = (
	case e_lookup what class_table of
		Value cl => cl
		|	Nil	=> (
				if	is_all_decimal what
				then	NumericLiteral
				else if is_primedid what
				then	PrimedIdentifier
				else if is_label what
				then	classify_label what
				else	Identifier
			)
);
=TEX
\subsection{Recognition of Delimiters}
=SML
fun €get_next_delimiter› (cs : string list) : string = (
	implode (find delimiter (fn chs => cs to (length chs - 1) = chs))
	handle ex => fail "CN-Parser" 501201 [fn()=>"invalid call of get_next_delimiter"]
);
=TEX
$rec\_delimiter$ returns an appropriately updated state if the input
begins with a delimiter symbol, if not it raises $Unrecognised$.
=SML
fun  €rec_delimiter› ( (cs, _) : LEX_STATE ) : LEX_STATE = (
	if next_is_delimiter cs
	then	let	val tk = get_next_delimiter cs;
        	in	(cs from size tk, Known tk)
		end
	else	raise Unrecognised
);
=TEX
\subsection{Recognition of Identifiers}

\subsection{Recognition of Alphanumeric Sequences}
=SML
fun €rec_identifier_aux› (st : LEX_STATE) : LEX_STATE = (
	let	fun aux st = (
			if next is_alnum st orelse next is_us st
			then aux (collect st)
			else st
		);
	in	if next is_alnum st orelse next is_us st
		then aux (collect st)
		else raise Unrecognised
	end
);
=TEX
=SML
fun €rec_identifier› (st : LEX_STATE) : LEX_STATE = (
	if next is_alpha st
	then	let	val (st', flag) = (rec_identifier_aux st, true)
				handle Unrecognised => (st, false);
		in	if flag
			then	(* if next is_tilde st'
				then (collect st')
				else if next is_dot st'
				then rec_identifier_aux (collect st')
				else *) st'
			else raise Unrecognised
		end
	else raise Unrecognised
);
=TEX
\subsection{Recognition of Numbers}
=TEX
The following is a simplification of numbers used in SPARK and will be
updated later.
=SML
fun €rec_number› (st : LEX_STATE) : LEX_STATE = (
	let	fun aux st = (
			if next is_digit st
			then aux (collect st)
			else st
		);
	in	if next is_digit st
		then aux (collect st)
		else raise Unrecognised
	end
);
=TEX
\subsection{Recognition of Labels}
=SML
fun €rec_label› (st : LEX_STATE) : LEX_STATE = (
let	fun aux1 st = (
	let	fun auxaux st = (
			if next is_digit st
			then auxaux (collect st)
			else st
		);
	in	if next is_digit st
		then auxaux (collect st)
		else raise Unrecognised
	end);
	fun aux2 func st = (
		if next func st
		then
			collect st
		else
			raise Unrecognised
	);
in
	aux2 is_crb (aux1 (aux2 is_orb st))
end
);
=TEX
\subsection{Recognition of Primed Identifiers}
=SML
fun €rec_primedid› (st : LEX_STATE) : LEX_STATE = (
	if next is_prime st
	then
		rec_identifier (collect st)
	else
		raise Unrecognised
);

=TEX

\subsection{Recognition of Lexemes}
Function $rec\_next\_token$ picks off the next token from the input
using the other recognisers.
=SML
fun €rec_next_token› (st : LEX_STATE) : LEX_STATE = (
	let	val st' = skip_space st;
	in	
		((((((rec_label st))
		handle Unrecognised =>
			(rec_primedid st))
		handle Unrecognised =>
			(rec_delimiter st))
		handle Unrecognised =>
			(rec_identifier st))
		handle Unrecognised =>
			(rec_number st))
		handle Unrecognised =>
			(fst st, Unknown)
	end
);
=TEX
\subsection{Lexical Analyser for Strings}
=SML
=TEX
$lex\_string$ converts an input string into a list of tokens.
=SML
fun €lex_string› (ip : string list) : LEX_ITEM list  = (
	let			val st = skip_space (ip, Unknown);
		fun   recur ct more = (
			let	val cts = lex_string more;
			in	ct :: cts
			end
		);
	in	case skip_space st of
			([], _) => []
		|	other => (
			case skip_space(rec_next_token other) of
				st' as (ip', Known s) => (recur (classify s, SPARKText s) ip'
			) |	st' as (ip', Unknown) => (
					fail
					"CN-Parser"
					501011
					[fn()=>	implode ip]
			)
		)
	end
);
=TEX
=SML
fun €spark_lex› (ip : INPUT list) : LEX_ITEM list = (
	case ip of
		Lex.Text s :: more => (
			lex_string (explode (to_upper s)) @
			spark_lex more
	) |	Lex.String s :: more => (
			(StringLiteral, SPARKString s) :: spark_lex more
	) |	Lex.Char s :: more => (
			fail "CN-Parser" 501011  [fn () => s]
	) |	Lex.Type ty :: more => (
			fail "CN-Parser" 501011  [fn () => string_of_type ty]
	) |	Lex.Term tm :: more => (
			fail "CN-Parser" 501011  [fn () =>
				"Antiquotation"]
	) |	Lex.Separator s :: _ => (
			fail "CN-Parser" 501011  [fn () => s]
	) |	Lex.Error n :: more => (fail "lexical analyser" 15006 [fn () => string_of_int n]
	) |	[] => []
);
=TEX
\subsection{Pre-Processor for Compliance Notation}
=SML
fun €srch_symbol› (syms : string list) (old : string list, new:string list)
	: (string list * string * string list) OPT = (
let	fun aux (s, next::rest) = (
	let	val s' = s@[next];
	in
		if next mem syms
		then
			Value (s, next, rest)
		else
			aux (s', rest)
	end)
	  | aux (s, [])	= Nil;
in
	aux (old, new)
end);
=TEX
=SML
fun €srch_matching› (left : string, right : string, old : string list, new : string list)
		: (string list * string list) OPT = (
let	fun €aux› (count, old, s1::rest) = (
	let	val s' = old@[s1];
	in
		if s1 = left
		then
			aux (count+1, s', rest)
		else if s1 = right
		then
			if count = 0
			then
				Value (old, s1::rest)
			else
				aux (count-1, s', rest)
		else
			aux (count, s', rest)
	end
	)| aux (_, _, []) = Nil;
in
	aux (0, old, new)
end);
=TEX
=SML
datatype €CN_INPUT› =	€SparkInput› of INPUT list
		|	€ZInput› of INPUT list;
=TEX
=SML
fun €do_upto_matching_rbrack› (brk : string) (ipl : INPUT list) : CN_INPUT list = (
let	fun close s = (
		if s = "[" then "]"
		else "}");
	fun aux (ip::rest) = (
		case ip of
		Lex.Text s => (
			case srch_matching (brk, close brk, [], explode s) of
			Value (left, right) => (
				ZInput [Lex.Text (implode left)]
					::do_upto_Ñ (Text (implode right)::rest)
			)| Nil => (ZInput[Lex.Text s])::aux rest
		) |other => (ZInput [other])::aux rest
	) | aux []  = [];
in
	aux ipl
end)
=TEX
=SML
and €do_upto_lbrack› ((ip::rest) : INPUT list) : CN_INPUT list = (
	case ip of
	Lex.Text s => (
		case srch_symbol ["[", "{"] ([], explode s) of
		Value (left, sym, right) => (
			(ZInput [Lex.Text (implode left)]::SparkInput [Lex.Text sym]
				::do_upto_matching_rbrack sym (Text (implode right)::rest)
			)
		)| Nil => (SparkInput[Lex.Text s])::do_upto_lbrack rest
	) |other => (SparkInput [other])::do_upto_lbrack rest
)
  | do_upto_lbrack []  = []
=TEX
=SML
and €do_upto_Ñ› ((ip::rest) : INPUT list) : CN_INPUT list = (
	case ip of
	Lex.Text s => (
		case srch_symbol ["Ñ"] ([], explode s) of
		Value (left, sym, right) => (
			(SparkInput [Lex.Text ((implode left)^sym)]
				::do_upto_lbrack (Text (implode right)::rest)
			)
		)| Nil => (SparkInput[Lex.Text s])::do_upto_Ñ rest
	) |other => (SparkInput [other])::do_upto_Ñ rest
)
  | do_upto_Ñ []  = [];
=TEX
=SML
fun €classify_inputs› (ips : INPUT list) : CN_INPUT list = (
let	val classified = do_upto_Ñ ips;
	fun sort ((SparkInput i1)::(SparkInput i2)::rest) = (
		(SparkInput (i1@i2))::sort rest
	) | sort ((ZInput i1)::(ZInput i2)::rest) = (
		(ZInput (i1@i2))::sort rest
	) | sort other = other;
in
	sort classified
end);
=TEX
=SML
fun €choose_lexer› (lex_items : CN_INPUT list) : LEX_ITEM list = (
let	fun aux (ip::more) = (
		case ip of
		SparkInput ip' => (spark_lex ip')@aux more
		|ZInput ip' => (Z,SPARKZ (z_lex ip'))::aux more
	) | aux [] = [];
in
	(aux lex_items)@[(Eos, SPARKEos)]
end);
=TEX
=SML
val €cn_lex› : INPUT list -> LEX_ITEM list =
	(choose_lexer o classify_inputs);
=TEX

\subsection{Miscellanea}
=SML
fun €format_lex_item›  ((_, tok) : LEX_ITEM) : string = (
	case tok of
		SPARKZ _	=> "Ò ... Æ"
	|	SPARKText s	=> s
	|	SPARKString s	=> s
	|	SPARKEos		=> "<end-of-input>"
);
=TEX
\section{EPILOGUE}
=SML
end (* of local ... in *);
=TEX
=SML
end (* of structure CNLex *);
=TEX
\small
\twocolumn[\section{INDEX}]
\printindex
\end{document}
