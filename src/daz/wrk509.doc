% %Z% $Date$ $Revision$ $RCSfile$
=TEX
% TQtemplate.tex
% use_file "wrk509";
% doctex wrk509x[0-9][0-9].th
% docdvi wrk509
\documentstyle[hol1,11pt,TQ,hyperbasics]{article}
\ftlinepenalty=9999
\def\Hide#1{}
\def\Bool{``$\it{:}bool\,$''}
\makeindex
\TPPproject{DAZ PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Analysis of Declarations}  %% Mandatory field
\TPPref{ISS/HAT/DAZ/WRK509}  %% Mandatory field
\def\SCCSversion{$Revision$%
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date$%
}}  %% Mandatory field (with sensible default)
\TPPstatus{Draft}
%\TPPstatus{Informal}
\TPPtype{Technical}
%\TPPkeywords{HOL}
\TPPauthor{K.~Blackburn & WIN01}  %% Mandatory field
%\TPPauthors{Name 1&location 1\\Name 2&location 2\\Name 3&location 3}
\TPPauthorisation{R.D.~Arthan & HAT Team}
\TPPabstract{%
As part of the requirements analysis for proof tools for the Compliance Notation, the generation of Z paragraphs has been analysed for basic declarations.
This paper reports on that analysis.}
%\TPPabstractB{}
%\TPPabstractC{}
%\TPPabstractD{}
%\TPPabstractE{}
%\TPPabstractF{}
\TPPdistribution{\parbox[t]{4.0in}{%
      Library}}

%\TPPclass{CLASSIFICATION}
\newfont{\icllogo}{icllogo50}
\def\TPPheadlhs{$\vcenter{\halign{##\cr\icllogo ICL\cr}}$}
%\def\TPPheadlhs{}
%\def\TPPheadcentre{}
%def\TPPheadrhs{}
%\def\TPPfootlhs{}
%\def\TPPfootcentre{}
%\def\TPPfootrhs{}

\begin{document}
\TPPsetsizes
\makeTPPfrontpage

\vfill
\begin{centering}

\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}

\newpage
\section{DOCUMENT CONTROL}
\subsection{Contents List}
\tableofcontents
%\subsection{Document Cross References}
\bibliographystyle{fmu}
\bibliography{fmu,daz}
\subsection{Changes History}  % to get section number `0.3'
\begin{description}

\item[Issue 1.1-1.2] Initial Drafts.
\item[Issue 1.3]
Added thoughts on possible usage.
\item[Issue 1.4-1.6]
Extensive changes after RDA comments.
\end{description}
\subsection{Changes Forecast}
As called for by peer review.
\pagebreak
\section{GENERAL}
\subsection{Scope}
This document reports on a study called for in \cite{ISS/HAT/DAZ/PLN010,ISS/HAT/DAZ/PLN012}.
\subsection{Introduction}
As part of the requirements analysis for proof tools for the Compliance Notation, the generation of Z paragraphs has been analysed for basic declarations.
This paper reports on that analysis.

The approach we take is to consider the different categories of basic declaration syntax
on a case by case basis, and then draw together these results.
This follows the categories given in \cite{DRA/CIS/CSE3/TR/94/27/2.1}.

Thus this document is organised as follows: 
\begin{itemize}
\item
in section \ref{prelim} we consider some issues that pervade the following analysis;
\item
in section \ref{categ} we analyse each of the forms of basic declaration by category;
\item
in section \ref{summary} we summarise the findings of the previous section, and consider the possible contexts when using the analysis;
\item
and in \ref{recomm} we recommend what approaches should be taken to provide proof support
for this area of Compliance Tools Notation processing.
\end{itemize}

\section{PRELIMINARY NOTES}\label{prelim}

\subsection{Pseudo-Z}
In the following discussions we use $name$ to indicate the name of a Z constant, such
as a type name or an enumerated item, subscripting $name$ if necessary to remove ambiguity.
We use $integer\_literal$ to indicate an integer literal, perhaps generated from
static evaluation of an expression.
We use the Compliance Notation $\_\_$ connective to indicate the attributes of a type name,
by connecting $name$ to the attribute suffix.

The results of this are sometimes not Z, but are meant to highlight the structure of theorems, etc., for the purpose of discussing the usefulness of the items for rewriting.

\subsection{A Hierarchy of Usefulness}
The definitions and axioms generated during the processing of Compliance Tool Notation 
will presumably all play a part in a proof concerning the items defined or axiomatised.
However, it would be very slow, and potentially likely to ``explode'' goals into being unmanagably large if we always rewrote with all of these theorems.
What would be useful, therefore, is a way of categorising theorems as to when we should use them
for rewriting.

Having seen the need for such categorisation, we can generalise the concept, to consider not just rewriting with theorems, but the application of any conversion to a term (where
the application of a rewriting conversion using a theorem is just one possibility).

One can do the categorisation based on a specific application. 
For instance, if one was concerned with determining the Z type of function applications, then
only rewrites of interest would be ones dealing with function arrows or function applications.
Alternatively, categorisation can be based on the complexity of the of the result of the conversion (or of the rewriting), and this could be done as follows:

A conversion can be categorised as to its likely usefulness by its complexity as follows.
\begin{description}
\item[Class 1]
Appropriate to be a conversion for the default rewrite rules, etc., in a straightforward proof context in the appropriate theory.

Such a conversion should simplify the term it is applied to, and not lengthen it (by count of tokens). 
Appropriate conversions for this class would for example be ones that replace constants by literals.

It is still possible that a user will not want the conversion applied in all cases, but only with the sort of frequency that, for instance pure rewriting is chosen over rewriting with the current proof context rewrite rules.

\item[Class 2]
Appropriate to be a conversion used within a straightforward automatic proof procedure (e.g. the one for $prove\_tac$ in a straightforward proof context), but not one that should ``always'' be applied.
A user would probably want easy access to such a conversion.

Such a conversion should simplify (in some sense) the term it is applied to, but may lengthen it to some extent.
Appropriate conversions would be ones that move the proof into a ``lower'' theory, 
such as rewriting a Compliance Notation expression into a term only using operators from the theory of relations, when reasoning about the Compliance Notation form of the term is unlikely to progress any other way.

\item[Class 3]
Appropriate only to automatic proof tools that take a ``brutal'' approach to
a proof, for instance,  conversion that simplifies, but greatly lengthens, a term, whose output is not intended to be human readable.
Such a conversion will not often be of use in a manual proof.

Some of the extensionality conversions would fit in this class.

\item[Class 4]
A conversion that is has no appropriate use except for careful manual use.

This includes many recursive definitions and conversions that reverse the effect of 
conversions from other classes.
\end{description}

\subsection{Static Expressions}
Various expression slots in declarations must be given static expressions in SPARK. 
It should be noted that this does not necessarily mean that they can be evaluated 
within \ProductZ.
This is for a variety of reasons, such as an inability to reason about
real numbers in \ProductZ\ to the same extent as SPARK.
Such reasons normally manifest by some constituent of the formal expansion of such a 
value being axiomatically introduced without an actual definition (i.e. as how a real number would be handled).
However, any expression that is meant to be statically evaluated to a $ú$ value
is assumed to be a good candidate for a ``once and for all'' attempt at
evaluation in \ProductZ, rather than being left for repeated attempts during
individual proofs.

The may also be problems handling predecessor and successor functions in static evaluations
carried out under \ProductZ.

\subsection{Other Z Paragraph Generating Parts of the Compliance Notation}
Some of the conclusions reached below, from considering all the possibilities for 
Basic Declarations, can be applied to the other areas of the Compliance Notation that 
cause Z paragraphs to be generated (we are not interested in Z embedded in the Notation
by the user).
The only significant instance of generating paragraphs is the case of subprogram declarations.

\subsection{Ranges Versus Set Displays}
The reasoning we are proposing takes place in a context where we have access to some
moderately powerful linear arithmetic tools.
In particular these tools are capable of reasoning about the inequalities that can be
derived from a range expression, but might well have difficulties using the results of
expanding ranges into set displays (which will give predicates of the form $x = n ² x = n+1 ² ...$).
This suggests that, in our area of particular interest, range expressions are preferable even to a two element set display of numbers.

\subsection{Type Marks}
Note that the specification of SPARK uses ``type mark'' for ``type name or subtype name'',
and this wording is used in this document.
In SPARK all syntax (other than type definitions) that requires a type demands a type mark,
i.e. a name that will be associated with a definition.
That is, SPARK does not allow anonymous types. 
This simplifies the variety of possible syntax to be considered.

\section{CATEGORIES OF BASIC DECLARATIONS}\label{categ}

\subsection{Variables}
Variable declarations do not directly cause the introduction of Z
paragraphs, and are therefore not further considered in this document.

\subsection{Constants}
¹CN
name : constant name_type := exp;
°
The SPARK specification and the actual \ProductZ\ implementation allows multiple constant identifiers to be 
introduced in one statement, but this is not covered in the Compliance Notation
specifications (they are implicitly handled as multiple individual declarations).
$exp$ must be a static expression in SPARK.

A declaration of a constant will either introduce a global definition or an axiom, depending on whether the constant's expression can be translated into Z.

These Z paragraphs are either of the form:
¹Z
name == exp
°
or:
¹Z
name : name_type
°

A theorem providing the rewrite of the name to the best available evaluation of the expression in the first case 
would of use (for it must be a static expression, so evaluation within \ProductZ\ is at least possible).
Such a theorem would be in Class 1 if the expression can be evaluated to a literal or other previously defined constant, and otherwise would probably fall in class 2 (and the worst cases in Class 3), and would make the original
global definition of no further use.

There is no obvious processing for the second case, but the axiom (used as a membership statement of the form $name  type ¤ true$, perhaps normalised with other Class 1  conversions) is in Class 1.

\subsection{Enumeration Types}\label{enumerate}
¹CN
type name is (name0, ..., namen)
°
There must be at least 2 enumeration literals.

The introduction of an enumeration type introduces generic definitions of the enumeration literals, the type itself, and the type's attributes.
In more detail:

There will be one global definition per enumeration literal, of the form:
¹Z
name == integer_literal
°
Such theorems are in class 1.

The global definition of the type is of the form:
¹Z
name == name0 .. namen
°
This can be rewritten to:
¹Z
ô name = 0 .. integer_literal
°
or various other obvious forms, e.g. involving inequalities, or simplifications
if there are few enumerated elements.
The integer literal will be one less than the number of enumerated items.
This rewritten theorem belongs in Class 2, and would make the original
global definition of no further use.

The attributes are as follows:

¹Z
name__FIRST == name0
name__LAST == namen
°
which can be rewritten to:
¹Z
ô name__FIRST = 0
ô name__LAST = integer_literal
°
These rewritten theorems belong in Class 1, and would make the original
global definitions of no further use.
The integer literal will be one less than the number of enumerated items.

¹Z
name__SUCC == (name \ {name__LAST}) ò succ
°
This has a variety of possible rewrites. The two extremes might be:
¹Z
ô name__SUCC == (0 .. integer_literal) ò succ
ô name__SUCC == {(0,1), ..., (integer_literaln, integer_literalèn+1ê)}
°
In general, the first belongs in Class 2, the second in Class 3. 
However, if the enumerated type is small (2, maybe 3, elements), then 
then simplifications can be made to the first rewritten theorem, and the results moved up the classes.
Any of these would make the original
global definition of no further use.
Some rewriting use may be made of the fact that $succ$ is already domain restricted to $î$.

We perhaps more usefully could introduce the theorem:
¹Z
ô µ i : 0 .. integer_literal · name__SUCC i = i + 1
°
where $integer_literal$ was the number of enumerated items minus 2.

¹Z
name__PRED == ((name \ {name__LAST}) ò succ)~
°
This has a variety of possible rewrites. The two extremes might be:
¹Z
ô name__PRED == (1 .. integer_literal) ò (succ ~)
ô name__PRED == {(1,0), ..., (integer_literaln, integer_literalèn-1ê)}
°
In general, the first belongs in Class 2, the second in Class 3. 
However, if the enumerated type is small (2, maybe 3, elements), then 
then simplifications can be made to the first rewritten theorem, and both the rewritten theorem and the second global definition moved up the classes.
Any of these would make the original
global definition of no further use.
Some rewriting use may be made of the fact that the range of $succ$ is restricted to $î1$.

We perhaps more usefully could introduce the theorem:
¹Z
ô µ i : 1 .. integer_literal · name__PRED i = i - 1
°
where $integer_literal$ was the number of enumerated items minus 1.

¹Z
name__POS == id name
name__VAL == name__POS~
°
The second can be rewritten to:
¹Z
ô name__VAL = name__POS
°
The rewritten theorem should probably be in Class 1, the first global definition should be in Class 2 (it is too expansive, given the follow-on rewrite of $name$, to be in Class 1), and would make the original
global definition of no further use.
A rewrite theorem of the following form might be put in Class 3 if the type is small (if very small, perhaps even in Class 2):
¹Z
ô name__POS = {(0,0),...(integer_literaln, integer_literaln)}
°

We perhaps more usefully could introduce the theorems:
¹Z
ô µ i : 0 .. integer_literal · name__POS i = i
ô µ i : 0 .. integer_literal · name__VAL i = i
°
where $integer_literal$ was the number of enumerated items minus 1.

\subsection{Array Types}
Constrained array type declarations are of the form:
¹CN
type name is array (index1, ..., indexn) of comp;
°
The indexes must be type marks for discrete, and thus static, ranges. 

The introduction of a constrained array type with component type mark $comp$ will introduce global definitions for the type itself and, if only 1-dimensional, its attributes.

¹Z
name == index1 ¸ ... ¸ indexn ­ comp
°
This definition is in Class 2 or maybe even 3, depending on the number and character of the index types.

For 1-dimensional arrays the attribute definitions are:
¹Z
name__FIRST == index1__FIRST
name__LAST == index1__LAST
name__LENGTH == # index1
name__RANGE == index1
°
All but the 3rd of these are in Class 1, the 3rd one being in Class 2.
It is possible that $\# index1$ can be rewritten to a simpler value, maybe even an
integer literal (for instance $\# (n .. m)$, assuming a likely form of the underlying index type, could be rewritten to $m + 1 - n$). 
This may move the rewritten theorem to Class 1, and would make the original
global definition of no further use.

Unconstrained array type declarations are of the form:
¹CN
type name is array (index1 range <>, ..., indexn range <>) of comp;
°
The indexes are arbitrary type marks, apparently, and in particular do not
appear to need to be static in SPARK.

The introduction of an unconstrained array type only introduces an axiom of the form:
¹Z
name : ð (index1 ¸ ... ¸ indexn ß comp)
°
This axiom, used as a membership statement, perhaps normalised by applying other applicable Class 1 conversions, is probably in Class 1, and could also be used in 
resolution proof attempts.

\subsection{Record Types}
¹CN
type name is 
record
	lab1 : ltype1;
	...
	labn : ltypen;
end record;
°
The Compliance Notation seems to address the issue of multiple
identifiers in a single component declaration by treating them as multiple declarations(?).
The $ltype$s are all type marks.

The introduction of a record type will introduce the following style of schema:
ÿ name üüüüüüüüüüü
Ü lab1 : ltype1
Ü ...
Ü labn : ltypen
üüüüüüüüüüüüüü
but as a horizontal schema, i.e.
¹Z
name == [lab1 : ltype; ...; labn : ltypen]
°
This equation of itself is probably in Class 2 or 3.
It is also something that perhaps ought to be rewritten with in some circumstances, 
regardless of the size of the horizontal schema, as it is crucial for progress.
It can also be used to generate various type membership theorems for the projections, that might be
useful (and thus perhaps even in Class 1 due to their simple nature).

\subsection{Integer Types}
¹CN
type name is exp1 .. exp2
°
(range attributes are valid SPARC range constraints, but are not handled formally)

Integer type declarations are types with the range constraint being statically determinable. 
Their introduction causes the introduction of a global definition of themselves and either global definitions or axioms for their attributes.

¹Z
name == exp1 .. exp2
°
This is a Class 2 theorem, and there may be possible rewrites of it, as
the two expressions should be static.

¹Z
name__FIRST == exp1
name__LAST == exp2
°
Rewritten theorems based on the evaluation of the expressions should be in Class 1 if the results are integer literals or other constants, and Class 2 otherwise, and would make the original
global definitions of no further use.

¹Z
name__SUCC : ú ß ú
name__PRED : ú ß ú
name__POS : ú ß ú
name__VAL : ú ß ú
°
These, taken as membership statements are in Class 1.
Sadly, the translation of the Compliance Notation does not give the obvious definitions for
these constants, only axioms.
This is to do with worries about overflows.

\subsection{Real Types}
¹CN
type name is delta ...
type name is digits ...
°

The introduction of a real type introduces the type as a given set:
¹Z
[ name ]
°
This may be used to rewrite any predicate of the form $r  name$ to $true$
(i.e. U-elimination). 

\subsection{Subtypes}
¹CN
subtype name is master constraint
°
The constraint can be range, floating point, fixed point or index, and, from SPARK, must
be statically determinable.

There are various possibilities for subtypes, being whether or not they are subtypes of types that are translated into $ú$, and on the nature of their constraint (e.g. can it be translated into a range constraint).

\subsubsection{Case 1}
If the master type, $master$, can be translated to $ú$ and the constraint can be translated to a $ú$ range constraint $exp1 .. exp2$ global definitions are introduced for the type and its attributes:
¹Z
name == exp1 .. exp2
°
The expressions must be static, and thus we can hope to be able to 
rewrite this to something of the form:
¹Z
ô name = integer_literal1 .. integer_literal2
°
Such a theorem is in Class 2, but if the expressions cannot be rewritten to 
integer literals it may be more appropriate to place the result in Class 3, and would make the original
global definition of no further use.

The attributes for this are as follows:
¹Z
name__FIRST == exp1
name__LAST == exp2
°
The expressions in these may be rewritable to integer literals, giving the
theorems:
¹Z
ô name__FIRST == integer_literal1
ô name__LAST == integer_literal2
°
or similar theorems.
These theorems should be in the same class, being 1 if both expressions evaluate
to integer literals, and class 2 or 3 otherwise, and would make the original
global definitions of no further use.

The other attributes are just copies of the master type (which will be a type mark, as anonymous types are not allowed in SPARK), so the global definitions are:
¹Z
name__SUCC == master__SUCC
name_PRED == master__PRED
name__POS == master__POS
name__VAL == master__VAL
°
All of these should be in Class 1, perhaps first rewriting them with Class 1 rules for type $master$.
Notice that the domains of these attributes are those of the master types attributes.

\subsubsection{Case 2}
For 1-dimensional index constraints, noting that the constraint must be a type mark in SPARK ($index$ below), the declaration introduces global definitions for the type and some attributes:
¹Z
name == {u : master | dom u = index}
°
Note that $master$ must be an unconstrained array. 

Possible rewrites exist, such as:
¹Z
name = (index ­ comp) ¡ master
°

The attributes are:
¹Z
name__FIRST == index__FIRST
name__LAST == index__LAST
name__RANGE == index
°
These are in Class 1, perhaps after having been rewritten by Class 1 theorems for $index$.

¹Z
name__LENGTH == # index
°
This is a Class 2 theorem, and it is possible that $\# index$ can be rewritten
to a simpler form introducing a 
more appropriate Class 2 theorem  (for instance $\# (n .. m)$, assuming a likely form of the underlying index type, could be rewritten to $m + 1 - n$) or even Class 1 if $\# index$ can be rewritten to an integer literal, and would make the original
global definition of no further use.

\subsubsection{Case 3}
For 2+-dimensional index constraints only a global definition of the type
is given:
¹Z
name == {u : master | dom u = index1 ¸ ... ¸ indexn }
°
$u$ is an introduced bound variable, $master$ the original array type. This is in Class 2 (bordering on Class 3).
Note that $master$ must be an unconstrained array. 

This has a possible rewrite of:
¹Z
name = (index1 ¸ ... ¸ indexn) ­ comp ¡ master
°

\subsubsection{Case 4}
When either the constraint is not a range constraint that can be translated into $ú$, or the master type is not $ú$, or any other case not covered in the above, then
the following axiom is introduced:
¹Z
name : ð master
°
This, as a membership statement, is in Class 1, perhaps normalised by other applicable Class 1 conversions and could also be used in 
resolution proof attempts.

\section{SUMMARY OF OBSERVATIONS}\label{summary}
\subsection{Conclusions of Analysis}
Almost all of the potentially useful theorems that are introduced by
a declaration are global definition paragraphs of the form:
¹Z
name == expression
°
The only potentially useful things that can be done with the global definitions at the point of declaration is:
\begin{itemize}
\item
to attempt to evaluate the expressions within \ProductZ\ and keep the resulting derived equations;
\item
add to these derived theorems any additional theorems generated from the successor or predecessor
type attribute definitions (see, e.g. the treatment of $name\_\_SUCC$ in section \ref{enumerate});
\item
make the derived theorems available to the user (e.g. save them in the theory).
Some derived theorems could be rejected here, due to categorisation, but it would 
be easier to explain the user interface if it was ``all or nothing'';
\item
to categorise the original or derived theorems and create one or more proof contexts, or
values contributing towards creating proof contexts.
\end{itemize}
The evaluation attempts could be guided by knowledge specific to the Compliance
Notation, such as the possible forms of the sub-expressions (e.g. must be 
result in ranges), or the starting
structure of the expression (e.g. one case starts as $\# typemark$).
In principle, the attempts could be guided by the name of the defined constant, but this
is vulnerable to certain (presumed rare) user actions.

The only other useful theorems introduced by global definitions
come from membership axioms that can be used in the
form:
¹Z
ô name  expression ¤ true
°
which may again be used in the manners described above, or possibly as 
theorems to resolve or chain against.

\subsection{Possible Usage}
One conceivable way to apply the above analysis is to combine the pre-existing
processing of the compliance notation with building proof rules.
This is not, however, an appropriate option.
This is for the following reasons:
\begin{itemize}
\item
It interferes with the purity of critical code, that for instance must be carefully cross
checked against the specifications of the Compliance Notation specifications.
\item
The current approach of the processing is to defer introducing new Z paragraphs
until a block of compliance notation has been fully checked. 
This would make it difficult to reason about the newly introduced paragraphs
until the end of processing a block of notation, as they would not formally
exist.
\item
Forcing the mixture of specification and proof work provides a poor user interface.
\end{itemize}
 
Immediately after processing some Compliance Notation considerable additional 
contextual information is available. 
However, this information would not be available if, for instance, a user 
in a new session generated the Z paragraphs from the Z document produced by
processing some compliance notation.

This suggests that any automated support for proof work using Z paragraphs
generated as a side effect from processing the compliance notation should
be able to run purely from information in the current theory.
Furthermore, such support should correctly function even when some material was introduced
directly by the user, and should cope with previous attempts to provide support in the theory (if the support saves theorems in the database).
One particular case of user introduced material is from Z material embedded in the same
Compliance Notation script as generated the Z paragraphs we are really interested in.
The support will thus not be able to rely on determining which Z paragraphs
originate in compliance notation processing of basic declarations, nor even necessarily what sort of
compliance notation was being processed (e.g. the paragraph is from
an enumerated type declaration).

It does not seem appropriate to prevent the postulated support tools from acting
on paragraphs that are clearly not from Compliance Notation processing, but 
which can be usefully processed any provided support tools.

\section{RECOMMENDATIONS}\label{recomm}
The recommended approach to developing the ideas above and determining their usefulness is as follows:
\begin{enumerate}
\item
Create a tool (or various front ends and a single tool) that takes as input a list of axioms and definitions (or just extracts them from a nominated theory or theories) and saves theorems that are the best rewrite theorems that
can be derived using knowledge of Compliance Notation forms, as discussed in section
\ref{categ} above.
The theorems should be saved in the current theory (the user may wish to use $new\_theory$ first).
It should also bind all the derived theorems to ML value names, and produce one or more
ML bindings of lists of theorems (most importantly, all generated theorems).

This will not expand out the definitions of any constants, even those linked by apparently being generated from the same
basic declaration.

The new theorems should be sufficient that the original axioms and definitions need no longer be used 
(this ability to hide the original items is the only reason for processing axioms, as the
only relevant axioms are of the form $name : type$ which has little processing that
can be done).

\item
Explore whether any precalculated rewrites would usefully improve the overall speed of proof.
This would include considering precalculating static expressions.
This would be done in the context of the SHOLIS example material.

\item
Experiment and research to find out what, if any, forms of automatically built proof context
(or analogous automatic gathering of theorems) would be useful.
Possibilities include: 
\begin{enumerate}
\item
build only from items that concern items of type $ú$ or $ð ú$; 
\item
build only from items that concern function application or function arrows;
\item
build by Class categorisation; 
\end{enumerate}
\end{enumerate}
\end{document}
